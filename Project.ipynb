{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1555ea8-7363-4110-9247-7aff919bf9ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:16:39.078880Z",
     "start_time": "2025-08-08T07:16:39.069755Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "#             PATH SETUP\n",
    "########################################\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\".\"))\n",
    "\n",
    "########################################\n",
    "#             LIBRERIES SETUP\n",
    "########################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections.abc import Iterable\n",
    "from typing import Dict\n",
    "import seaborn as sns\n",
    "import math, re\n",
    "########################################\n",
    "#             SIMULATION LIBRARIES\n",
    "########################################\n",
    "from lemer.rngs import MultiStreamRNG\n",
    "from lemer.rvms import *\n",
    "from typing import List, Optional, Tuple\n",
    "from simulator.simulation import Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils\n",
    "_TCRIT_95 = {\n",
    "    1: 12.706, 2: 4.303, 3: 3.182, 4: 2.776, 5: 2.571, 6: 2.447, 7: 2.365, 8: 2.306, 9: 2.262,\n",
    "    10: 2.228, 11: 2.201, 12: 2.179, 13: 2.160, 14: 2.145, 15: 2.131, 16: 2.120, 17: 2.110,\n",
    "    18: 2.101, 19: 2.093, 20: 2.086, 21: 2.080, 22: 2.074, 23: 2.069, 24: 2.064, 25: 2.060,\n",
    "    26: 2.056, 27: 2.052, 28: 2.048, 29: 2.045, 30: 2.042\n",
    "}\n",
    "def _tcrit(df: int) -> float:\n",
    "    return _TCRIT_95.get(df, 1.96) if df > 0 else float(\"nan\")\n",
    "\n",
    "# --- aggregatore generico mean ± CI95% per metrica y raggruppata per x ---\n",
    "def agg_ci(df: pd.DataFrame, x: str, y: str) -> pd.DataFrame:\n",
    "    # NOTE: usa _tcrit(...) già definita UNA VOLTA nel tuo blocco utils\n",
    "    g = df.groupby(x)[y].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
    "    n = g[\"count\"].to_numpy(dtype=float)\n",
    "    t = np.where(n > 30, 1.96, np.array([_tcrit(int(max(1, k-1))) for k in n]))\n",
    "    sem = g[\"std\"].fillna(0.0).to_numpy() / np.sqrt(np.maximum(n, 1.0))\n",
    "    ci = t * sem\n",
    "    g[\"ci_lo\"] = g[\"mean\"] - ci\n",
    "    g[\"ci_hi\"] = g[\"mean\"] + ci\n",
    "    g[\"n\"] = n\n",
    "    return g.sort_values(x).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def mean_ci(series: pd.Series) -> Tuple[float, float, float, int]:\n",
    "    x = pd.to_numeric(series, errors=\"coerce\").dropna().values\n",
    "    n = len(x)\n",
    "    if n == 0: return np.nan, np.nan, np.nan, 0\n",
    "    m = float(np.mean(x))\n",
    "    if n == 1: return m, np.nan, np.nan, 1\n",
    "    s = float(np.std(x, ddof=1))\n",
    "    half = _tcrit(n-1) * s / math.sqrt(n)\n",
    "    return m, m-half, m+half, n\n",
    "\n",
    "\n",
    "\n",
    "def _node_order(scopes: list[str]) -> list[str]:\n",
    "    \"\"\"Ordina alfabeticamente i NODE_* (A,B,C,...) per avere pannelli stabili.\"\"\"\n",
    "    nodes = [s for s in scopes if isinstance(s, str) and s.startswith(\"NODE_\")]\n",
    "    return sorted(nodes, key=lambda s: s.replace(\"NODE_\", \"\"))\n",
    "\n",
    "\n",
    "def _node_label(scope: str) -> str:\n",
    "    \"\"\"Etichetta leggibile per un NODE_*.\"\"\"\n",
    "    name = scope.replace(\"NODE_\", \"\")\n",
    "    mapping = {\"A\":\"Server A\", \"B\":\"Server B\", \"C\":\"Server C\", \"P\":\"Server P\"}\n",
    "    return mapping.get(name, f\"Server {name}\")\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (7.4, 5.0),\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"grid.alpha\": 0.35,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.titlelocation\": \"left\",\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"xtick.direction\": \"out\",\n",
    "    \"ytick.direction\": \"out\",\n",
    "    \"legend.frameon\": False,\n",
    "    \"lines.linewidth\": 2.0,\n",
    "    \"lines.markersize\": 5.5,\n",
    "})\n",
    "PALETTE = {\n",
    "    \"THEORY\": \"#1f77b4\",   # blu per teoria\n",
    "    \"SIM\":    \"#ff7f0e\",   # arancio per simulazione\n",
    "    \"A\":      \"#2ca02c\",   # verde\n",
    "    \"B\":      \"#d62728\",   # rosso\n",
    "    \"C\":      \"#000000\",   # rosso\n",
    "    \"P\":      \"#9467bd\",   # viola\n",
    "}\n",
    "\n",
    "MARKER_POOL = [\"o\", \"s\", \"^\", \"D\", \"v\", \"P\", \"X\", \"*\"]  # aggiungi se vuoi\n",
    "def marker_style_for(index: int, color: str):\n",
    "    m = MARKER_POOL[index % len(MARKER_POOL)]\n",
    "    # ogni “giro” della lista alterna pieno/vuoto per aumentare la varietà\n",
    "    hollow = (index // len(MARKER_POOL)) % 2 == 1\n",
    "    return dict(\n",
    "        marker=m, markersize=6.5,\n",
    "        markerfacecolor=(\"white\" if hollow else color),\n",
    "        markeredgecolor=color, markeredgewidth=1.8,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "BASE_DIR = \".output_simulation\"\n",
    "\n",
    "# configurazione all'inizio del notebook\n",
    "OBJ = 3   # scegli 1, 2 o 3\n",
    "\n",
    "# costruisco dinamicamente il nome del file\n",
    "config_file = f\"obj{OBJ}.json\"\n",
    "config_path = f\"analytic_sweep_lambda.csv\"\n",
    "TITLE_PREFIX = f\"OBJ{OBJ}\"\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3706e543fd3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:18.210109Z",
     "start_time": "2025-08-08T07:19:18.203440Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ================== DISCOVERY / LOAD ==================\n",
    "\n",
    "def find_csv_for_config(config_path: str, base_dir=BASE_DIR, target=\"results\") -> List[str]:\n",
    "    cfg_name = Path(config_path).stem\n",
    "    pattern  = os.path.join(base_dir, f\"{target}_{cfg_name}*.csv\")\n",
    "    return sorted(glob.glob(pattern))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _parse_lambda_from_filename(fname: str) -> Optional[float]:\n",
    "    base = Path(fname).stem.lower()\n",
    "    m = re.search(r\"(?:lam|lambda|gamma|load)[=_]?([0-9]+(?:\\.[0-9]+)?)\", base)\n",
    "    if m: return float(m.group(1))\n",
    "    # fallback prudente\n",
    "    for tok in re.findall(r\"([0-9]+\\.[0-9]+)\", base):\n",
    "        val = float(tok)\n",
    "        if 0.1 <= val <= 5.0:\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "def load_runs(csv_files: List[str]) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    for i, f in enumerate(csv_files):\n",
    "        df = pd.read_csv(f)\n",
    "        df[\"source\"]  = os.path.basename(f)\n",
    "        df[\"replica\"] = i\n",
    "        if \"arrival_rate\" not in df.columns:\n",
    "            df[\"arrival_rate\"] = _parse_lambda_from_filename(f)\n",
    "        dfs.append(df)\n",
    "    if not dfs:\n",
    "        raise FileNotFoundError(\"Nessun CSV.\")\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    if \"mean_response_time\" not in df.columns:\n",
    "        for alt in (\"response_time_mean\", \"rt_mean\"):\n",
    "            if alt in df.columns:\n",
    "                df = df.rename(columns={alt: \"mean_response_time\"})\n",
    "                break\n",
    "    return df\n",
    "\n",
    "\n",
    "# ================== SCELTA X ==================\n",
    "\n",
    "def choose_overall_x(df_overall: pd.DataFrame) -> Tuple[str, str]:\n",
    "    \"\"\"arrival_rate -> throughput -> replica\"\"\"\n",
    "    if \"arrival_rate\" in df_overall.columns and df_overall[\"arrival_rate\"].notna().sum() >= 2:\n",
    "        return \"arrival_rate\", \"Arrival Rate (λ)\"\n",
    "    if \"throughput\" in df_overall.columns and df_overall[\"throughput\"].nunique() >= 2:\n",
    "        return \"throughput\", \"Throughput (req/s)\"\n",
    "    return \"replica\", \"Replica\"\n",
    "\n",
    "def choose_node_x(df_nodes: pd.DataFrame) -> Tuple[str, str]:\n",
    "    if \"arrival_rate\" in df_nodes.columns and df_nodes[\"arrival_rate\"].notna().sum() >= 2:\n",
    "        return \"arrival_rate\", \"Arrival Rate (λ)\"\n",
    "    if \"utilization\" in df_nodes.columns and df_nodes[\"utilization\"].nunique() >= 2:\n",
    "        return \"utilization\", \"Utilization ρ\"\n",
    "    if \"throughput\" in df_nodes.columns and df_nodes[\"throughput\"].nunique() >= 2:\n",
    "        return \"throughput\", \"Throughput (req/s)\"\n",
    "    return \"replica\", \"Replica\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_files=find_csv_for_config(config_file,target=\"conv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import os, glob, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Trova il CSV analitico a partire dal path della config (come fai per i results)\n",
    "def find_analytic_csv_for_config(config_path: str, base_dir=BASE_DIR) -> str:\n",
    "    cfg_name = Path(config_path).stem\n",
    "    candidates = []\n",
    "    patterns = [\n",
    "        os.path.join(base_dir, f\"analytic_sweep_{cfg_name}*.csv\"),\n",
    "        os.path.join(base_dir, f\"{cfg_name}_analytic*.csv\"),\n",
    "        os.path.join(base_dir, \"analytic_sweep_lambda.csv\"),\n",
    "        os.path.join(Path(base_dir).parent, \"analytic_sweep_lambda.csv\"),\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        candidates += glob.glob(pat)\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Nessun CSV analitico trovato per '{cfg_name}'. \"\n",
    "            f\"Cercati pattern: {patterns}\"\n",
    "        )\n",
    "\n",
    "    candidates.sort(key=lambda p: (len(Path(p).name), p), reverse=True)\n",
    "    return candidates[0]\n",
    "\n",
    "# Carica l’analitico nel formato atteso dal plot (colonne: arrival_rate, mean_response_time, X_max opzionale)\n",
    "def load_analytic_models_for_config(config_path: str, base_dir=BASE_DIR) -> pd.DataFrame:\n",
    "    path = find_analytic_csv_for_config(config_path, base_dir=base_dir)\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # uniforma la colonna lambda → arrival_rate\n",
    "    if \"arrival_rate\" not in df.columns and \"lambda\" in df.columns:\n",
    "        df = df.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "\n",
    "    if \"arrival_rate\" not in df.columns:\n",
    "        raise ValueError(\"Il CSV analitico deve contenere almeno 'arrival_rate' o 'lambda'.\")\n",
    "\n",
    "    # ordina per sicurezza\n",
    "    return df.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# uso\n",
    "analytic_df = load_analytic_models_for_config(config_path, base_dir=BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a68f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## helper per grafici con intervallo confidenza (PULITO)\n",
    "# ============================================================\n",
    "# Overlay simulazione (con CI) + analitico letto dal CSV\n",
    "# Funziona con nodi arbitrari (A,B,P/…).\n",
    "# Richiede nei CSV di simulazione: arrival_rate, mean_population, std_population, scope/vscope.\n",
    "# Richiede nel CSV analitico: almeno ['arrival_rate' o 'lambda', 'mean_population'].\n",
    "# Per i nodi, usa util_A/util_B/... dal CSV analitico e calcola N_i = λ * util_i.\n",
    "# ============================================================\n",
    "\n",
    "import math\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- util base ----------\n",
    "\n",
    "def _z_value(conf: float = 0.95) -> float:\n",
    "    \"\"\"Valore critico z della Normale standard per il livello di confidenza.\"\"\"\n",
    "    if abs(conf - 0.95) < 1e-12:\n",
    "        return 1.959963984540054\n",
    "    lookup = {0.90: 1.6448536269514722, 0.95: 1.959963984540054, 0.975: 2.241402727604947, 0.99: 2.5758293035489004}\n",
    "    return lookup.get(conf, 1.959963984540054)\n",
    "\n",
    "def _pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
    "    \"\"\"Trova la prima colonna disponibile tra i candidati (case-insensitive).\"\"\"\n",
    "    lowmap = {c.lower().strip(): c for c in df.columns}\n",
    "    for name in candidates:\n",
    "        key = name.lower().strip()\n",
    "        if key in lowmap:\n",
    "            return lowmap[key]\n",
    "    return None\n",
    "\n",
    "def _standardize_cols_inplace(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Rende lo schema uniforme (rinomina colonne ai nomi canonici).\"\"\"\n",
    "    scope_col = _pick_col(df, [\"vscope\", \"scope\", \"node\", \"station\", \"component\"])\n",
    "    rate_col  = _pick_col(df, [\"arrival_rate\", \"lambda\", \"lam\", \"arr_rate\"])\n",
    "    mean_col  = _pick_col(df, [\"mean_population\", \"mean_pop\", \"avg_population\", \"population_mean\", \"E[N]\", \"meanN\"])\n",
    "    std_col   = _pick_col(df, [\"std_population\", \"std_pop\", \"population_std\", \"sd_population\", \"sigma_population\"])\n",
    "    util_col  = _pick_col(df, [\"utilization\", \"rho\", \"usage\"])  # opzionale\n",
    "\n",
    "    if scope_col is None: raise ValueError(f\"Colonna di scope non trovata. Presenti: {list(df.columns)}\")\n",
    "    if rate_col  is None: raise ValueError(f\"Colonna 'arrival_rate' non trovata. Presenti: {list(df.columns)}\")\n",
    "    if mean_col  is None: raise ValueError(f\"Colonna 'mean_population' non trovata. Presenti: {list(df.columns)}\")\n",
    "    if std_col   is None: raise ValueError(f\"Colonna 'std_population' non trovata. Presenti: {list(df.columns)}\")\n",
    "\n",
    "    ren = {scope_col: \"vscope\", rate_col: \"arrival_rate\", mean_col: \"mean_population\", std_col: \"std_population\"}\n",
    "    if util_col: ren[util_col] = \"utilization\"\n",
    "    df.rename(columns=ren, inplace=True)\n",
    "\n",
    "def _normalize_scope_values_inplace(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Uniforma i valori di scope a OVERALL e NODE_<X>.\"\"\"\n",
    "    df[\"vscope\"] = df[\"vscope\"].astype(str).str.strip().str.upper()\n",
    "    df[\"vscope\"] = df[\"vscope\"].replace({\"SYSTEM\": \"OVERALL\", \"TOTAL\": \"OVERALL\", \"ALL\": \"OVERALL\"})\n",
    "    df[\"vscope\"] = df[\"vscope\"].str.replace(\"NODE-\", \"NODE_\", regex=False)\n",
    "    mask_letter = df[\"vscope\"].str.fullmatch(r\"[A-Z]\")\n",
    "    df.loc[mask_letter, \"vscope\"] = \"NODE_\" + df.loc[mask_letter, \"vscope\"]\n",
    "\n",
    "def _load_one(x) -> pd.DataFrame:\n",
    "    \"\"\"Carica un DF o un CSV e applica normalizzazioni.\"\"\"\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        df = x.copy()\n",
    "    elif isinstance(x, (str, pathlib.Path)):\n",
    "        df = pd.read_csv(x, na_values=[\"-\", \"-,-\"])\n",
    "    else:\n",
    "        raise TypeError(f\"Tipo non supportato: {type(x)}\")\n",
    "    _standardize_cols_inplace(df)\n",
    "    _normalize_scope_values_inplace(df)\n",
    "    # tipi numerici\n",
    "    for c in [\"arrival_rate\", \"mean_population\", \"std_population\", \"utilization\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _ensure_df(files_or_path) -> pd.DataFrame:\n",
    "    \"\"\"Accetta DF / path / lista/tupla di DF o path e concatena tutto.\"\"\"\n",
    "    if isinstance(files_or_path, (list, tuple)):\n",
    "        parts = [_load_one(it) for it in files_or_path]\n",
    "        df = pd.concat(parts, ignore_index=True, sort=False)\n",
    "    else:\n",
    "        df = _load_one(files_or_path)\n",
    "    return df\n",
    "\n",
    "def _detect_nodes(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Estrae i nomi dei nodi presenti (NODE_<X>).\"\"\"\n",
    "    mask = df[\"vscope\"].str.startswith(\"NODE_\")\n",
    "    return sorted([v.split(\"NODE_\")[1] for v in df.loc[mask, \"vscope\"].unique().tolist()])\n",
    "\n",
    "# ---------- CI dalla simulazione ----------\n",
    "\n",
    "def ci_from_files(files_or_path,\n",
    "                  scope: str,\n",
    "                  n_rep: int,\n",
    "                  conf: float = 0.95,\n",
    "                  ci_design_effect: float = 12.0,\n",
    "                  n_departures_col: str | None = \"num_departures\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Media e semi-ampiezza IC per uno scope (OVERALL o NODE_<X>).\n",
    "    - Se per un λ ci sono >=2 righe (repliche): usa varianza *tra repliche* delle MEDIE.\n",
    "    - Se c'è 1 sola riga: fallback con n_eff = num_departures / ci_design_effect (>=1)\n",
    "      usando la std intra-run (std_population).\n",
    "    Ritorna: [arrival_rate, mean, ci] (dove 'ci' è la semi-ampiezza).\n",
    "    \"\"\"\n",
    "    df = _ensure_df(files_or_path)\n",
    "    sub = df[df[\"vscope\"] == scope].copy()\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"Nessuna riga per scope '{scope}'. Scopes: {sorted(df['vscope'].unique())}\")\n",
    "\n",
    "    # tipizza numerici\n",
    "    for c in [\"arrival_rate\", \"mean_population\", \"std_population\"]:\n",
    "        if c in sub.columns:\n",
    "            sub[c] = pd.to_numeric(sub[c], errors=\"coerce\")\n",
    "    if n_departures_col and n_departures_col in sub.columns:\n",
    "        sub[n_departures_col] = pd.to_numeric(sub[n_departures_col], errors=\"coerce\")\n",
    "\n",
    "    z = _z_value(conf)\n",
    "    out_rows = []\n",
    "    for lam, g in sub.groupby(\"arrival_rate\", sort=True):\n",
    "        vals = pd.to_numeric(g[\"mean_population\"], errors=\"coerce\").dropna()\n",
    "        R = len(vals)\n",
    "\n",
    "        if R >= 2:\n",
    "            # CI tra repliche (sulla mean_population)\n",
    "            m = float(vals.mean())\n",
    "            s = float(vals.std(ddof=1)) if R > 1 else 0.0\n",
    "            half = z * s / math.sqrt(R)\n",
    "        else:\n",
    "            # Fallback su una sola riga\n",
    "            m = float(vals.iloc[0]) if len(vals) else float(\"nan\")\n",
    "            std_intra = float(g[\"std_population\"].iloc[0]) if pd.notna(g[\"std_population\"].iloc[0]) else 0.0\n",
    "            if n_departures_col and n_departures_col in g.columns and pd.notna(g[n_departures_col].iloc[0]):\n",
    "                n_eff = max(1.0, float(g[n_departures_col].iloc[0]) / float(ci_design_effect))\n",
    "            else:\n",
    "                n_eff = 1.0\n",
    "            half = z * std_intra / math.sqrt(n_eff)\n",
    "\n",
    "        out_rows.append({\"arrival_rate\": float(lam), \"mean\": m, \"ci\": max(0.0, half)})\n",
    "\n",
    "    return (pd.DataFrame(out_rows)\n",
    "              .sort_values(\"arrival_rate\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "# ---------- plotting dinamico con overlay (SIM vs ANALYTIC CSV) ----------\n",
    "\n",
    "def plot_finite_population_dynamic(\n",
    "    files_or_path,\n",
    "    analytic_df: pd.DataFrame,     # CSV analitico già caricato con tutte le colonne\n",
    "    *,\n",
    "    n_rep: int,\n",
    "    conf: float = 0.95,\n",
    "    ci_design_effect: float = 12.0,\n",
    "    node_order: list[str] | None = None,\n",
    "    cols: int = 2,\n",
    "    figsize=(12, 9),\n",
    "    savepath: str | None = None,\n",
    "    show_xticks_all: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Pannelli dinamici: SYSTEM + uno per ciascun nodo trovato nei dati.\n",
    "    Mostra sia simulazione (con CI) che modello analitico (dal CSV).\n",
    "    \"\"\"\n",
    "    # --- dati simulazione ---\n",
    "    df = _ensure_df(files_or_path)\n",
    "    detected = _detect_nodes(df)\n",
    "    nodes = (\n",
    "        [n for n in (node_order or []) if n in detected]\n",
    "        + [n for n in detected if (not node_order or n not in node_order)]\n",
    "    )\n",
    "\n",
    "    # CI simulazione\n",
    "    ci_sys = ci_from_files(df, \"OVERALL\", n_rep, conf, ci_design_effect=ci_design_effect)\n",
    "    ci_nodes = {n: ci_from_files(df, f\"NODE_{n}\", n_rep, conf, ci_design_effect=ci_design_effect)\n",
    "                for n in nodes}\n",
    "\n",
    "    # --- modello analitico dal CSV (tutte le colonne tenute come sono) ---\n",
    "    model = analytic_df.copy()\n",
    "    if \"lambda\" in model.columns:\n",
    "        model = model.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "    # SYSTEM: usa direttamente 'mean_population' dal CSV\n",
    "    model = model.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "\n",
    "    # --- layout figure ---\n",
    "    n_panels = 1 + len(nodes)\n",
    "    rows = math.ceil(n_panels / max(1, cols))\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize, sharex=True)\n",
    "    axs = axs.flatten() if isinstance(axs, np.ndarray) else [axs]\n",
    "    fig.suptitle(\"Confidence interval for average population\", y=0.98)\n",
    "\n",
    "    # --- SYSTEM ---\n",
    "    ax = axs[0]\n",
    "    ax.errorbar(ci_sys[\"arrival_rate\"], ci_sys[\"mean\"], yerr=ci_sys[\"ci\"],\n",
    "                fmt=\"o-\", label=\"simulation run\")\n",
    "    if \"mean_population\" in model.columns:\n",
    "        ax.plot(model[\"arrival_rate\"], model[\"mean_population\"], label=\"analytical model\")\n",
    "    ax.set_title(\"SYSTEM average population\")\n",
    "    ax.set_xlabel(\"Lambda\"); ax.set_ylabel(\"Avg population in SYSTEM\")\n",
    "    ax.legend()\n",
    "\n",
    "    # --- NODI ---\n",
    "    for i, n in enumerate(nodes, start=1):\n",
    "        ax = axs[i]\n",
    "        d = ci_nodes[n]\n",
    "        ax.errorbar(d[\"arrival_rate\"], d[\"mean\"], yerr=d[\"ci\"],\n",
    "                    fmt=\"o-\", label=\"simulation run\")\n",
    "\n",
    "        # popolazione per nodo dai campi util_X * λ\n",
    "        col_name = f\"util_{n}\"\n",
    "        if col_name in model.columns:\n",
    "            pop_n = model[\"arrival_rate\"] * model[col_name]  # N_i(λ) = λ * ρ_i(λ)\n",
    "            ax.plot(model[\"arrival_rate\"], pop_n, label=\"analytical model\")\n",
    "\n",
    "        ax.set_title(f\"{n} average population\")\n",
    "        ax.set_xlabel(\"Lambda\"); ax.set_ylabel(f\"Avg population in {n}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # pannelli extra (se grid più grande del necessario)\n",
    "    for j in range(1 + len(nodes), len(axs)):\n",
    "        axs[j].set_visible(False)\n",
    "\n",
    "    if show_xticks_all:\n",
    "        for ax in axs:\n",
    "            ax.tick_params(axis=\"x\", which=\"both\", labelbottom=True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, dpi=160, bbox_inches=\"tight\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utilities mancanti per plot_system_rt ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "def aggregate_sim_overall(df_overall: pd.DataFrame,\n",
    "                          *,\n",
    "                          x_candidates=(\"arrival_rate\", \"throughput\", \"x\"),\n",
    "                          mean_col=\"mean_response_time\",\n",
    "                          # se presenti: colonna id replica e colonna n_departures\n",
    "                          rep_candidates=(\"rep\", \"seed\", \"run\", \"iteration\", \"trial\", \"rep_id\", \"batch\"),\n",
    "                          n_departures_candidates=(\"num_departures\",\"departures\",\"n_departures\"),\n",
    "                          conf=0.95,\n",
    "                          fallback_design_effect=8.0):\n",
    "    \"\"\"\n",
    "    Aggrega OVERALL per λ con media e IC 95%:\n",
    "    - Se ci sono più righe per λ (o una colonna 'rep'), fa IC *tra repliche* (consigliato).\n",
    "    - Se per λ c'è una sola riga (dataset già collassato), evita di usare n_departures in modo ingenuo.\n",
    "      In fallback usa la var tra 'repliche' se presente, altrimenti allarga in modo controllato\n",
    "      con un 'design effect' (>1) sulla std intra-run (esplicita e modificabile).\n",
    "\n",
    "    Ritorna:\n",
    "      agg: DataFrame con colonne [xcol, 'mean', 'ci_lo', 'ci_hi']\n",
    "      xcol: nome della colonna X usata\n",
    "      xlabel: etichetta per asse X\n",
    "    \"\"\"\n",
    "    df = df_overall.copy()\n",
    "\n",
    "    # 1) scegli la X (λ normalmente)\n",
    "    xcol = None\n",
    "    for c in x_candidates:\n",
    "        if c in df.columns:\n",
    "            xcol = c\n",
    "            break\n",
    "    if xcol is None:\n",
    "        raise ValueError(f\"Nessuna colonna X tra {x_candidates} in df_overall.columns={list(df.columns)}\")\n",
    "\n",
    "    # 2) trova colonna id-replica se esiste\n",
    "    rep_col = None\n",
    "    for c in rep_candidates:\n",
    "        if c in df.columns:\n",
    "            rep_col = c\n",
    "            break\n",
    "\n",
    "    # 3) trova colonna n_departures (solo per fallback, NON per IC by-rep)\n",
    "    ndep_col = None\n",
    "    for c in n_departures_candidates:\n",
    "        if c in df.columns:\n",
    "            ndep_col = c\n",
    "            break\n",
    "\n",
    "    records = []\n",
    "    for lam, g in df.groupby(xcol, sort=True):\n",
    "        vals = pd.to_numeric(g[mean_col], errors=\"coerce\").dropna()\n",
    "        R = len(vals) if rep_col or len(g) > 1 else 1\n",
    "\n",
    "        if R > 1:\n",
    "            # >>> IC *tra repliche* (consigliato) <<<\n",
    "            m = float(vals.mean())\n",
    "            s = float(vals.std(ddof=1)) if R > 1 else 0.0\n",
    "            tcrit = float(student_t.ppf(0.5 + conf/2.0, max(R-1, 1)))\n",
    "            half = tcrit * s / math.sqrt(R)\n",
    "            lo, hi = m - half, m + half\n",
    "        else:\n",
    "            # >>> Fallback (dataset già collassato per λ) <<<\n",
    "            # NON usiamo n_departures \"puri\" (correlazione seriale); invece esplicitiamo un design effect.\n",
    "            m = float(vals.iloc[0]) if len(vals) else np.nan\n",
    "            # std intra-run, se c'è\n",
    "            std_run = None\n",
    "            for c in (\"std_response_time\", \"std_rt\", \"std\"):\n",
    "                if c in g.columns and pd.notna(g[c].iloc[0]):\n",
    "                    std_run = float(g[c].iloc[0]); break\n",
    "\n",
    "            if std_run is None:\n",
    "                # non posso costruire un IC credibile -> barra nulla\n",
    "                lo, hi = m, m\n",
    "            else:\n",
    "                # n_eff = n_departures / design_effect (default 8: prudente in presenza di correlazione)\n",
    "                n_eff = None\n",
    "                if ndep_col and pd.notna(g[ndep_col].iloc[0]):\n",
    "                    n_eff = max(1.0, float(g[ndep_col].iloc[0]) / float(fallback_design_effect))\n",
    "                else:\n",
    "                    n_eff = 1.0  # ultra-conservativo\n",
    "                z = _z_value(conf)\n",
    "                half = z * std_run / math.sqrt(n_eff)\n",
    "                lo, hi = m - half, m + half\n",
    "\n",
    "        records.append({xcol: float(lam), \"mean\": m, \"ci_lo\": lo, \"ci_hi\": hi})\n",
    "\n",
    "    agg = pd.DataFrame(records).sort_values(xcol)\n",
    "    xlabel = \"Arrival Rate (λ)\" if xcol == \"arrival_rate\" else xcol\n",
    "    return agg, xcol, xlabel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d448fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############\n",
    "\n",
    "def per_job_covariance(base_dir=BASE_DIR):\n",
    "    files = glob.glob(os.path.join(base_dir, \"per_job_times*.csv\"))\n",
    "    if not files:\n",
    "        print(\"Nessun per_job_times*.csv\")\n",
    "        return\n",
    "\n",
    "    df = pd.concat([pd.read_csv(p) for p in files], ignore_index=True)\n",
    "\n",
    "    # prendi dinamicamente tutte le colonne T_*\n",
    "    cols = [c for c in df.columns if c.startswith(\"T_\")]\n",
    "    if len(cols) < 2:\n",
    "        print(\"per_job_times ha meno di 2 colonne T_*\")\n",
    "        return\n",
    "\n",
    "    # calcola covariance e correlation solo sulle colonne trovate\n",
    "    cov = df[cols].cov()\n",
    "    corr = df[cols].corr()\n",
    "\n",
    "    print(\"Colonne trovate:\", cols)\n",
    "    print(\"\\nCovariance matrix:\\n\", cov.round(5))\n",
    "    print(\"\\nCorrelation matrix:\\n\", corr.round(4))\n",
    "\n",
    "# esempio di chiamata\n",
    "per_job_covariance()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d626421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "files = find_csv_for_config(config_file, base_dir=BASE_DIR)\n",
    "print(\"CSV trovati:\", len(files))\n",
    "for f in files: print(\" -\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_system_rt(df_all: pd.DataFrame,\n",
    "                   analytic_df: pd.DataFrame,   # <--- CSV analitico già caricato\n",
    "                   *,\n",
    "                   width: float = 9.5,\n",
    "                   height: float = 4.8,\n",
    "                   dpi: int = 130,\n",
    "                   show_theory: bool = True,\n",
    "                   zoom_range: tuple[float, float] | None = None,\n",
    "                   x_overview_cap: float = 1.6,\n",
    "                   right_pad_ratio: float = 0.06,\n",
    "                   y_cap_overview: float | None = None,\n",
    "                   y_cap_zoom: float | None = None,\n",
    "                   percentile_cap: float = 95.0,\n",
    "                   ci_conf: float = 0.95,\n",
    "                   ci_design_effect: float = 12.0,\n",
    "                   ci_fill: bool = True,\n",
    "                   min_display_half: float = 0.0\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    SYSTEM: simulazione (media ± CI) + curva teorica letta dal CSV analitico.\n",
    "    - analytic_df deve avere colonne ['arrival_rate','mean_response_time','X_max']\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) prendo X_sat dal CSV analitico ---\n",
    "    X_sat = float(analytic_df[\"X_max\"].iloc[0])\n",
    "\n",
    "    # --- 2) dati OVERALL (simulazione, media + CI) ---\n",
    "    df_overall = df_all[df_all[\"scope\"] == \"OVERALL\"].copy()\n",
    "    if df_overall.empty or \"mean_response_time\" not in df_overall.columns:\n",
    "        print(\"Mancano dati OVERALL/mean_response_time.\")\n",
    "        return\n",
    "    agg, xcol, xlabel = aggregate_sim_overall(\n",
    "        df_overall,\n",
    "        conf=ci_conf,\n",
    "        fallback_design_effect=ci_design_effect\n",
    "    )\n",
    "\n",
    "    # --- helper per la simulazione (invariato) ---\n",
    "    def draw_mean_ci(ax, agg_df, *, color, label_mean=\"Simulazione (mean)\"):\n",
    "        x  = agg_df[xcol].to_numpy(float)\n",
    "        mu = agg_df[\"mean\"].to_numpy(float)\n",
    "        lo = np.where(np.isfinite(agg_df[\"ci_lo\"]), agg_df[\"ci_lo\"].to_numpy(float), mu)\n",
    "        hi = np.where(np.isfinite(agg_df[\"ci_hi\"]), agg_df[\"ci_hi\"].to_numpy(float), mu)\n",
    "\n",
    "        if min_display_half > 0:\n",
    "            half = np.maximum(0.5*(hi - lo), float(min_display_half))\n",
    "            lo, hi = mu - half, mu + half\n",
    "\n",
    "        if ci_fill:\n",
    "            ax.fill_between(x, lo, hi, color=color, alpha=0.18, linewidth=0, zorder=2)\n",
    "\n",
    "        ax.plot(x, mu, \"o-\", color=color, linewidth=2.3, zorder=3, label=label_mean)\n",
    "        yerr = np.vstack([mu - lo, hi - mu])\n",
    "        ax.errorbar(x, mu, yerr=yerr, fmt=\"none\", ecolor=\"black\",\n",
    "                    elinewidth=2.6, capsize=6, zorder=4, label=\"CI 95%\")\n",
    "        return x, mu, lo, hi\n",
    "\n",
    "    # --- 3) range dinamico sugli assi ---\n",
    "    xmin_data, xmax_data = float(np.nanmin(agg[xcol])), float(np.nanmax(agg[xcol]))\n",
    "    x_overview_min = xmin_data if zoom_range is None else min(xmin_data, zoom_range[0])\n",
    "    x_target_max = max(xmax_data, (zoom_range[1] if zoom_range else xmax_data), X_sat * 1.02)\n",
    "    x_overview_max = min(x_target_max * (1.0 + right_pad_ratio), x_overview_cap)\n",
    "\n",
    "    # --- 4) curva teorica dal CSV ---\n",
    "    x_theory = analytic_df[\"arrival_rate\"].to_numpy(float)\n",
    "    y_theory = analytic_df[\"mean_response_time\"].to_numpy(float)\n",
    "\n",
    "    # === CASO A: solo overview ===\n",
    "    if zoom_range is None:\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        if show_theory:\n",
    "            ax.plot(x_theory, y_theory, color=PALETTE[\"THEORY\"],\n",
    "                    label=\"Analytical model\", zorder=0)\n",
    "        _, mu, lo, hi = draw_mean_ci(ax, agg, color=PALETTE[\"SIM\"])\n",
    "\n",
    "        if x_overview_min <= X_sat <= x_overview_max:\n",
    "            ax.axvline(X_sat, linestyle=\"--\", color=PALETTE[\"THEORY\"], alpha=0.85,\n",
    "                       linewidth=2.0, label=f\"X_sat ≈ {X_sat:.3f}\", zorder=5)\n",
    "\n",
    "        if y_cap_overview is None:\n",
    "            pool = [mu, lo, hi, y_theory]\n",
    "            vals = np.hstack([p[np.isfinite(p)] for p in pool if p is not None])\n",
    "            if vals.size:\n",
    "                y_cap_overview = float(np.nanpercentile(vals, percentile_cap) * 1.05)\n",
    "        ax.set_ylim(bottom=0, top=y_cap_overview)\n",
    "\n",
    "        ax.set_xlim(x_overview_min, x_overview_max)\n",
    "        ax.set_xlabel(xlabel); ax.set_ylabel(\"Mean Response Time (s)\")\n",
    "        ax.set_title(\"SYSTEM: teoria vs simulazione\")\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "        ax.legend(loc=\"upper left\")\n",
    "        plt.tight_layout(); plt.show(); return\n",
    "\n",
    "    # === CASO B: overview + zoom ===\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(width, height * 1.35), dpi=dpi,\n",
    "                                   gridspec_kw={\"height_ratios\": [2, 1]})\n",
    "\n",
    "    if show_theory:\n",
    "        ax1.plot(x_theory, y_theory, color=PALETTE[\"THEORY\"],\n",
    "                 label=\"Analytical model\", zorder=0)\n",
    "    _, mu_o, lo_o, hi_o = draw_mean_ci(ax1, agg, color=PALETTE[\"SIM\"])\n",
    "\n",
    "    if x_overview_min <= X_sat <= x_overview_max:\n",
    "        ax1.axvline(X_sat, linestyle=\"--\", color=PALETTE[\"THEORY\"], alpha=0.9,\n",
    "                    linewidth=2.0, label=f\"X_sat ≈ {X_sat:.3f}\", zorder=5)\n",
    "\n",
    "    import matplotlib.patches as patches\n",
    "    y0, y1 = ax1.get_ylim()\n",
    "    rect = patches.Rectangle((zoom_range[0], y0), zoom_range[1]-zoom_range[0],\n",
    "                             (y1 - y0)*0.06, facecolor=\"none\",\n",
    "                             edgecolor=\"gray\", linestyle=\"--\", linewidth=2.0, zorder=6)\n",
    "    ax1.add_patch(rect)\n",
    "\n",
    "    ax1.set_xlim(x_overview_min, x_overview_max)\n",
    "    ax1.set_ylabel(\"Mean Response Time (s)\")\n",
    "    ax1.set_title(\"SYSTEM: overview + zoom\")\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.35); ax1.legend(loc=\"upper left\")\n",
    "\n",
    "    # pannello zoom\n",
    "    x_mask = (x_theory >= zoom_range[0]) & (x_theory <= zoom_range[1])\n",
    "    if show_theory:\n",
    "        ax2.plot(x_theory[x_mask], y_theory[x_mask], color=PALETTE[\"THEORY\"],\n",
    "                 linewidth=2.0, alpha=0.85)\n",
    "    _, mu_z, lo_z, hi_z = draw_mean_ci(ax2, agg, color=PALETTE[\"SIM\"])\n",
    "\n",
    "    if zoom_range[0] <= X_sat <= zoom_range[1]:\n",
    "        ax2.axvline(X_sat, linestyle=\"--\", color=PALETTE[\"THEORY\"], alpha=0.9, linewidth=2.0)\n",
    "\n",
    "    ax2.set_xlim(*zoom_range)\n",
    "    ax2.set_xlabel(xlabel); ax2.set_ylabel(\"Time (s)\")\n",
    "    ax2.set_title(f\"Zoom su {zoom_range[0]:.3g}–{zoom_range[1]:.3g}\")\n",
    "    ax2.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "\n",
    "    if y_cap_overview is None:\n",
    "        pool_o = [mu_o, lo_o, hi_o, y_theory]\n",
    "        vals_o = np.hstack([p[np.isfinite(p)] for p in pool_o if p is not None])\n",
    "        if vals_o.size:\n",
    "            y_cap_overview = float(np.nanpercentile(vals_o, percentile_cap) * 1.05)\n",
    "    if y_cap_zoom is None:\n",
    "        pool_z = [mu_z, lo_z, hi_z, y_theory[x_mask]]\n",
    "        vals_z = np.hstack([p[np.isfinite(p)] for p in pool_z if p is not None])\n",
    "        if vals_z.size:\n",
    "            y_cap_zoom = float(np.nanpercentile(vals_z, percentile_cap) * 1.05)\n",
    "\n",
    "    ax1.set_ylim(bottom=0, top=y_cap_overview)\n",
    "    ax2.set_ylim(bottom=0, top=y_cap_zoom)\n",
    "\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(nbins=6))\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(nbins=8))\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d568af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM con zoom sulla coda verso saturazione\n",
    "df_all = load_runs(files)\n",
    "\n",
    "plot_system_rt(df_all,analytic_df, zoom_range=(0.8, 1.23)) #usare questo per obj1 e 2 \n",
    "#plot_system_rt(df_all, zoom_range=(1.21, 1.43)) #usare questo per obj3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b0c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# POPULATION PLOT (v3) — sim (CI) vs analitico (da CSV)\n",
    "# =======================\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "\n",
    "# ---- palette opzionale (riusa PALETTE se definita altrove) ----\n",
    "def _pal(key, default):\n",
    "    try:\n",
    "        return PALETTE[key]  # noqa: F821\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "# ---- banda+linea+CI per la simulazione ----\n",
    "def _draw_ci_banded(ax, x, mean, half, *, color,\n",
    "                    label_line=\"simulation (mean)\",\n",
    "                    label_band=\"simulation CI band\",\n",
    "                    label_ci=\"CI 95%\",\n",
    "                    min_display_half=0.0, ci_fill=True):\n",
    "    x = np.asarray(x, float); mu = np.asarray(mean, float)\n",
    "    h  = np.maximum(np.asarray(half, float), 0.0)\n",
    "\n",
    "    if min_display_half > 0:\n",
    "        h = np.maximum(h, float(min_display_half))\n",
    "\n",
    "    lo, hi = mu - h, mu + h\n",
    "\n",
    "    band_patch = None\n",
    "    if ci_fill:\n",
    "        ax.fill_between(x, lo, hi, color=color, alpha=0.18, linewidth=0, zorder=2)\n",
    "        band_patch = mpatches.Patch(color=color, alpha=0.18, label=label_band)\n",
    "\n",
    "    (line_handle,) = ax.plot(\n",
    "        x, mu, \"o-\", color=color, linewidth=2.0, zorder=3,\n",
    "        markevery=max(1, len(x)//40), label=label_line\n",
    "    )\n",
    "\n",
    "    yerr = np.vstack([mu - lo, hi - mu])\n",
    "    ax.errorbar(x, mu, yerr=yerr, fmt=\"none\",\n",
    "                ecolor=\"black\", elinewidth=2.4, capsize=6, zorder=4)\n",
    "    ci_proxy = Line2D([0], [0], color=\"black\", linewidth=2.4, label=label_ci)\n",
    "\n",
    "    return (line_handle, band_patch, ci_proxy)\n",
    "\n",
    "# ---- semi-ampiezza CI per OVERALL/NODE_* (usa std intra-run se serve) ----\n",
    "def _ci_half_from_df(\n",
    "    df_scope: pd.DataFrame,\n",
    "    *,\n",
    "    n_rep: int,\n",
    "    conf: float,\n",
    "    ci_design_effect: float,\n",
    "    mean_col: str = \"mean_population\",\n",
    "    std_col: str  = \"std_population\",\n",
    "    n_departures_col: str | None = \"num_departures\",\n",
    ") -> pd.DataFrame:\n",
    "    # z 95% default\n",
    "    def _z_value(c=0.95):\n",
    "        if abs(c-0.95) < 1e-12: return 1.959963984540054\n",
    "        lookup = {0.90: 1.6448536269514722, 0.95: 1.959963984540054, 0.975: 2.241402727604947, 0.99: 2.5758293035489004}\n",
    "        return lookup.get(c, 1.959963984540054)\n",
    "\n",
    "    z = _z_value(conf)\n",
    "    df = df_scope.copy()\n",
    "\n",
    "    for c in [\"arrival_rate\", mean_col, std_col]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    if n_departures_col and n_departures_col in df.columns:\n",
    "        df[n_departures_col] = pd.to_numeric(df[n_departures_col], errors=\"coerce\")\n",
    "\n",
    "    rows_per_lambda = (df.groupby(\"arrival_rate\")[mean_col]\n",
    "                         .count()\n",
    "                         .rename(\"R\")\n",
    "                         .reset_index())\n",
    "\n",
    "    out_rows = []\n",
    "    for lam, g in df.groupby(\"arrival_rate\", sort=True):\n",
    "        R_here = int(rows_per_lambda.loc[rows_per_lambda[\"arrival_rate\"] == lam, \"R\"].values[0])\n",
    "\n",
    "        if R_here >= 2:\n",
    "            m = float(g[mean_col].mean())\n",
    "            s = float(g[mean_col].std(ddof=1)) if R_here > 1 else 0.0\n",
    "            half = z * s / math.sqrt(R_here)\n",
    "        else:\n",
    "            m = float(g[mean_col].iloc[0])\n",
    "            std_intra = float(g[std_col].iloc[0]) if (std_col in g.columns and pd.notna(g[std_col].iloc[0])) else 0.0\n",
    "            if n_departures_col and n_departures_col in g.columns and pd.notna(g[n_departures_col].iloc[0]):\n",
    "                n_eff = max(1.0, float(g[n_departures_col].iloc[0]) / float(ci_design_effect))\n",
    "                half  = z * std_intra / math.sqrt(n_eff)\n",
    "            else:\n",
    "                half  = z * std_intra * math.sqrt(float(ci_design_effect))\n",
    "\n",
    "        out_rows.append({\"arrival_rate\": float(lam), \"mean\": m, \"half\": max(0.0, half)})\n",
    "\n",
    "    return (pd.DataFrame(out_rows)\n",
    "              .sort_values(\"arrival_rate\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "# ---- collasso per λ (una sola barra CI a λ) ----\n",
    "def _collapse_by_lambda(ci_df: pd.DataFrame, how: str = \"mean\") -> pd.DataFrame:\n",
    "    if how == \"mean\":\n",
    "        agg = {\"mean\": \"mean\", \"half\": \"mean\"}\n",
    "    elif how == \"max\":\n",
    "        agg = {\"mean\": \"mean\", \"half\": \"max\"}\n",
    "    elif how == \"min\":\n",
    "        agg = {\"mean\": \"mean\", \"half\": \"min\"}\n",
    "    else:\n",
    "        raise ValueError(\"how must be 'mean'/'max'/'min'\")\n",
    "    return (ci_df.groupby(\"arrival_rate\", as_index=False)\n",
    "                 .agg(agg).sort_values(\"arrival_rate\").reset_index(drop=True))\n",
    "\n",
    "# ---- helper: popolazione analitica per nodo dal CSV ----\n",
    "def _analytic_node_population(model_df: pd.DataFrame, node: str) -> pd.Series | None:\n",
    "    \"\"\"\n",
    "    Restituisce la serie N_node analitica:\n",
    "    - Se esiste 'mean_population_{node}', usa quella.\n",
    "    - Altrimenti se esiste 'util_{node}', calcola N = rho / (1 - rho) con clipping vicino a 1.\n",
    "    - Altrimenti None.\n",
    "    \"\"\"\n",
    "    # 1) popolazione nodo precomputata?\n",
    "    col_pop = f\"mean_population_{node}\"\n",
    "    if col_pop in model_df.columns:\n",
    "        return pd.to_numeric(model_df[col_pop], errors=\"coerce\")\n",
    "\n",
    "    # 2) calcolo da rho (util_node)\n",
    "    col_rho = f\"util_{node}\"\n",
    "    if col_rho in model_df.columns:\n",
    "        rho = pd.to_numeric(model_df[col_rho], errors=\"coerce\").astype(float)\n",
    "        # clipping per stabilità numerica vicino a 1\n",
    "        rho = rho.clip(upper=1.0 - 1e-9)\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            N = rho / (1.0 - rho)\n",
    "        N[~np.isfinite(N)] = np.nan\n",
    "        return N\n",
    "\n",
    "    return None\n",
    "\n",
    "# ---------------- FUNZIONE PRINCIPALE ----------------\n",
    "def plot_finite_population_with_analytic(\n",
    "    files_or_path,\n",
    "    analytic_df: pd.DataFrame,   # CSV analitico già caricato (tutte le colonne)\n",
    "    *,\n",
    "    n_rep: int,\n",
    "    conf: float = 0.95,\n",
    "    ci_design_effect: float = 12.0,\n",
    "    ci_fill: bool = True,\n",
    "    min_display_half: float = 0.0,\n",
    "    node_order: list[str] | None = None,\n",
    "    collapse_how: str = \"mean\",\n",
    "    cols: int = 2,\n",
    "    figsize=(12, 9),\n",
    "    savepath: str | None = None,\n",
    "    title: str = \"Simulation vs Analytical model — Population\",\n",
    "):\n",
    "    \"\"\"\n",
    "    - Simulazione: media ± CI su SYSTEM e su ogni nodo presente.\n",
    "    - Analitico (CSV): **solo SYSTEM** da 'mean_population' (rinominato 'SYS').\n",
    "      Nessun confronto analitico sui singoli nodi.\n",
    "    \"\"\"\n",
    "    # ---- dati simulazione ----\n",
    "    df = _ensure_df(files_or_path)       # definita in una cella precedente\n",
    "    detected = _detect_nodes(df)         # definita in una cella precedente\n",
    "    nodes = ([n for n in (node_order or []) if n in detected] +\n",
    "             [n for n in detected if not node_order or n not in node_order])\n",
    "\n",
    "    sys_df  = df[df[\"vscope\"] == \"OVERALL\"].copy()\n",
    "    node_df = {n: df[df[\"vscope\"] == f\"NODE_{n}\"].copy() for n in nodes}\n",
    "\n",
    "    # CI simulazione\n",
    "    sys_ci  = _ci_half_from_df(sys_df,  n_rep=n_rep, conf=conf, ci_design_effect=ci_design_effect)\n",
    "    node_ci = {n: _ci_half_from_df(node_df[n], n_rep=n_rep, conf=conf, ci_design_effect=ci_design_effect)\n",
    "               for n in nodes}\n",
    "\n",
    "    # collassa per λ\n",
    "    sys_ci  = _collapse_by_lambda(sys_ci,  how=collapse_how)\n",
    "    node_ci = {n: _collapse_by_lambda(d, how=collapse_how) for n, d in node_ci.items()}\n",
    "\n",
    "    # ---- modello analitico dal CSV (solo SYSTEM) ----\n",
    "    model = analytic_df.copy()\n",
    "    if \"lambda\" in model.columns and \"arrival_rate\" not in model.columns:\n",
    "        model = model.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "    if \"mean_population\" in model.columns and \"SYS\" not in model.columns:\n",
    "        model = model.rename(columns={\"mean_population\": \"SYS\"})\n",
    "    model = model.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "\n",
    "    # ---- layout ----\n",
    "    n_panels = 1 + len(nodes)\n",
    "    rows = math.ceil(n_panels / max(1, cols))\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize, sharex=True)\n",
    "    axs = axs.flatten() if isinstance(axs, np.ndarray) else [axs]\n",
    "    fig.suptitle(title, y=0.98)\n",
    "\n",
    "    col_sim = _pal(\"SIM\", \"#ff7f0e\")\n",
    "    col_the = _pal(\"THEORY\", \"#1f77b4\")\n",
    "\n",
    "    # ===== SYSTEM (sim vs analitico) =====\n",
    "    ax = axs[0]\n",
    "    line_h, band_h, ci_h = _draw_ci_banded(\n",
    "        ax,\n",
    "        x=sys_ci[\"arrival_rate\"], mean=sys_ci[\"mean\"], half=sys_ci[\"half\"],\n",
    "        color=col_sim, label_line=\"simulation (mean)\",\n",
    "        label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "        min_display_half=min_display_half, ci_fill=ci_fill\n",
    "    )\n",
    "    handles = [line_h]\n",
    "    if band_h is not None: handles.append(band_h)\n",
    "    handles.append(ci_h)\n",
    "\n",
    "    if \"SYS\" in model.columns:\n",
    "        (h_model,) = ax.plot(\n",
    "            model[\"arrival_rate\"], model[\"SYS\"],\n",
    "            color=col_the, linewidth=2.3, linestyle=\"--\",\n",
    "            marker=\"s\", markersize=4, label=\"analytical model\", zorder=6\n",
    "        )\n",
    "        handles.append(h_model)\n",
    "\n",
    "    # X_max (asintoto) se presente\n",
    "    x_max = None\n",
    "    if \"X_max\" in model.columns and pd.notna(model[\"X_max\"].iloc[0]):\n",
    "        try:\n",
    "            x_max = float(model[\"X_max\"].iloc[0])\n",
    "        except Exception:\n",
    "            x_max = None\n",
    "\n",
    "    if x_max is not None and np.isfinite(x_max):\n",
    "        ax.axvline(x_max, linestyle=\"--\", color=col_the, alpha=0.85, linewidth=1.8)\n",
    "        handles.append(Line2D([0], [0], color=col_the, linestyle=\"--\",\n",
    "                              label=f\"λ* ≈ {x_max:.3g}\"))\n",
    "        ylim_top = ax.get_ylim()[1]\n",
    "        ax.annotate(f\"λ* ≈ {x_max:.3g}\",\n",
    "                    xy=(x_max, ylim_top), xycoords=(\"data\", \"data\"),\n",
    "                    xytext=(5, -5), textcoords=\"offset points\",\n",
    "                    rotation=90, va=\"top\", ha=\"left\",\n",
    "                    fontsize=10, color=col_the,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.75))\n",
    "        ax.set_xticks(np.unique(np.append(ax.get_xticks(), x_max)))\n",
    "\n",
    "    ax.set_title(\"SYSTEM average population\")\n",
    "    ax.set_xlabel(\"Lambda\"); ax.set_ylabel(\"Avg population in SYSTEM\")\n",
    "    #ax.set_yscale(\"log\") #per obiettivo 3\n",
    "    ax.legend(handles=handles, loc=\"upper left\")\n",
    "\n",
    "    # ===== NODI (solo simulazione) =====\n",
    "    for i, n in enumerate(nodes, start=1):\n",
    "        ax = axs[i]\n",
    "        d = node_ci[n]\n",
    "        line_h, band_h, ci_h = _draw_ci_banded(\n",
    "            ax,\n",
    "            x=d[\"arrival_rate\"], mean=d[\"mean\"], half=d[\"half\"],\n",
    "            color=col_sim, label_line=\"simulation (mean)\",\n",
    "            label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "            min_display_half=min_display_half, ci_fill=ci_fill\n",
    "        )\n",
    "        handles = [line_h]\n",
    "        if band_h is not None: handles.append(band_h)\n",
    "        handles.append(ci_h)\n",
    "\n",
    "        # *** NESSUN confronto analitico per i nodi ***\n",
    "        # (rimosso il blocco che calcolava/plot-ava N_node)\n",
    "\n",
    "        ax.set_title(f\"{n} average population\")\n",
    "        ax.set_xlabel(\"Lambda\"); ax.set_ylabel(f\"Avg population in {n}\")\n",
    "        #ax.set_yscale(\"log\") #per obiettivo 3\n",
    "        ax.legend(handles=handles, loc=\"upper left\")\n",
    "\n",
    "    # pannelli extra invisibili\n",
    "    for j in range(1 + len(nodes), len(axs)):\n",
    "        axs[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, dpi=160, bbox_inches=\"tight\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d90813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_finite_population_with_analytic(\n",
    "    files_or_path=files,\n",
    "    analytic_df=analytic_df,      # <-- obbligatorio: usa SEMPRE il CSV analitico che gli passi\n",
    "    n_rep=5,\n",
    "    conf=0.95,\n",
    "    ci_design_effect=12.0,        # fallback solo quando per un λ hai una sola riga\n",
    "    ci_fill=True,                 # False per togliere la banda arancione\n",
    "    min_display_half=0.0,\n",
    "    node_order=[\"A\", \"B\", \"P\"],\n",
    "    collapse_how=\"mean\",          # \"max\" se vuoi CI più conservativi\n",
    "    figsize=(12, 9)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# RESPONSE TIME — nuovo stile (v3) SOLO CSV ANALITICO (SYSTEM)\n",
    "# Usa _pal, _z_value, _ensure_df, _detect_nodes dalle celle precedenti\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "\n",
    "# --- half-width del CI con nomi di colonna configurabili (solo simulazione) ---\n",
    "def _ci_half_from_df_generic(\n",
    "    df_scope: pd.DataFrame,\n",
    "    *,\n",
    "    n_rep: int,\n",
    "    conf: float,\n",
    "    ci_design_effect: float,\n",
    "    mean_col: str,\n",
    "    std_col: str,\n",
    "    n_departures_col: str | None = \"num_departures\",\n",
    "    std_scale: float = 1.0,    # es. 0.001 se std è in ms e la mean in s\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ritorna un DF con colonne: arrival_rate, mean, half.\n",
    "    - Se per un λ ci sono >=2 righe (repliche): usa la varianza *tra repliche* delle MEDIE.\n",
    "    - Se c'è 1 sola riga: fallback con n_eff = departures / ci_design_effect (>=1).\n",
    "    \"\"\"\n",
    "    z = _z_value(conf)  # <-- già definito sopra\n",
    "\n",
    "    df = df_scope.copy()\n",
    "    for c in [mean_col, std_col, \"arrival_rate\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    if n_departures_col and n_departures_col in df.columns:\n",
    "        df[n_departures_col] = pd.to_numeric(df[n_departures_col], errors=\"coerce\")\n",
    "\n",
    "    rows_per_lambda = (df.groupby(\"arrival_rate\")[mean_col]\n",
    "                         .count()\n",
    "                         .rename(\"R\")\n",
    "                         .reset_index())\n",
    "\n",
    "    out_rows = []\n",
    "    for lam, g in df.groupby(\"arrival_rate\", sort=True):\n",
    "        R_here = int(rows_per_lambda.loc[rows_per_lambda[\"arrival_rate\"] == lam, \"R\"].values[0])\n",
    "\n",
    "        if R_here >= 2:\n",
    "            m = float(g[mean_col].mean())\n",
    "            s = float(g[mean_col].std(ddof=1)) if R_here > 1 else 0.0\n",
    "            half = z * s / math.sqrt(R_here)\n",
    "        else:\n",
    "            m = float(g[mean_col].iloc[0])\n",
    "            std_intra = float(g[std_col].iloc[0]) * float(std_scale) if pd.notna(g[std_col].iloc[0]) else 0.0\n",
    "            if n_departures_col and n_departures_col in g.columns and pd.notna(g[n_departures_col].iloc[0]):\n",
    "                n_eff = max(1.0, float(g[n_departures_col].iloc[0]) / float(ci_design_effect))\n",
    "                half = z * std_intra / math.sqrt(n_eff)\n",
    "            else:\n",
    "                half = z * std_intra * math.sqrt(float(ci_design_effect))\n",
    "\n",
    "        out_rows.append({\"arrival_rate\": float(lam), \"mean\": m, \"half\": max(0.0, half)})\n",
    "\n",
    "    return (pd.DataFrame(out_rows)\n",
    "              .sort_values(\"arrival_rate\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "\n",
    "# --- collassa duplicati su λ -> UNA SOLA barra CI per λ ---\n",
    "def _collapse_by_lambda(ci_df: pd.DataFrame, how: str = \"mean\") -> pd.DataFrame:\n",
    "    \"\"\"Accetta [arrival_rate, mean, half] e collassa per λ.\"\"\"\n",
    "    if how == \"mean\":\n",
    "        agg = {\"mean\": \"mean\", \"half\": \"mean\"}\n",
    "    elif how == \"max\":\n",
    "        agg = {\"mean\": \"mean\", \"half\": \"max\"}\n",
    "    elif how == \"min\":\n",
    "        agg = {\"mean\": \"mean\", \"half\": \"min\"}\n",
    "    else:\n",
    "        raise ValueError(\"how must be 'mean'/'max'/'min'\")\n",
    "    return (ci_df.groupby(\"arrival_rate\", as_index=False)\n",
    "                 .agg(agg).sort_values(\"arrival_rate\").reset_index(drop=True))\n",
    "\n",
    "\n",
    "# --- disegno: banda arancione + linea arancione + barre CI nere ---\n",
    "def _draw_ci_banded(ax, x, mean, half, *, color,\n",
    "                    label_line=\"simulation (mean)\",\n",
    "                    label_band=\"simulation CI band\",\n",
    "                    label_ci=\"CI 95%\",\n",
    "                    min_display_half: float = 0.0,\n",
    "                    ci_fill: bool = True):\n",
    "    \"\"\"Ritorna gli handle per la legenda: (line_handle, band_patch, ci_proxy).\"\"\"\n",
    "    x = np.asarray(x, float); mu = np.asarray(mean, float)\n",
    "    h  = np.maximum(np.asarray(half, float), 0.0)\n",
    "    if min_display_half > 0:\n",
    "        h = np.maximum(h, float(min_display_half))\n",
    "    lo, hi = mu - h, mu + h\n",
    "\n",
    "    band_patch = None\n",
    "    if ci_fill:\n",
    "        ax.fill_between(x, lo, hi, color=color, alpha=0.18, linewidth=0, zorder=2)\n",
    "        band_patch = mpatches.Patch(color=color, alpha=0.18, label=label_band)\n",
    "\n",
    "    (line_handle,) = ax.plot(\n",
    "        x, mu, \"o-\", color=color, linewidth=2.0, zorder=3,\n",
    "        markevery=max(1, len(x)//40), label=label_line\n",
    "    )\n",
    "\n",
    "    yerr = np.vstack([mu - lo, hi - mu])\n",
    "    ax.errorbar(x, mu, yerr=yerr, fmt=\"none\",\n",
    "                ecolor=\"black\", elinewidth=2.4, capsize=6, zorder=4)\n",
    "    ci_proxy = Line2D([0], [0], color=\"black\", linewidth=2.4, label=label_ci)\n",
    "    return (line_handle, band_patch, ci_proxy)\n",
    "\n",
    "\n",
    "# --- PLOT: simulazione (CI) + curva analitica del CSV per SYSTEM ---\n",
    "def plot_finite_response_time_banded_v3(\n",
    "    files_or_path,\n",
    "    analytic_df: pd.DataFrame,            # <-- CSV analitico con 'arrival_rate' e 'mean_response_time'\n",
    "    *,\n",
    "    n_rep: int,\n",
    "    conf: float = 0.95,\n",
    "    ci_design_effect: float = 12.0,\n",
    "    ci_fill: bool = True,\n",
    "    min_display_half: float = 0.0,\n",
    "    mean_col: str = \"mean_response_time\",\n",
    "    std_col: str  = \"std_response_time\",\n",
    "    node_order: list[str] | None = None,\n",
    "    collapse_how: str = \"mean\",\n",
    "    cols: int = 2,\n",
    "    figsize=(12, 9),\n",
    "    savepath: str | None = None,\n",
    "    title: str = \"Confidence interval for average response time\",\n",
    "    ylabel_unit: str = \"s\"\n",
    "):\n",
    "    # 1) carica DF di simulazione (usa utilità già definite sopra)\n",
    "    df = _ensure_df(files_or_path)\n",
    "\n",
    "    # 2) nodi presenti\n",
    "    detected = _detect_nodes(df)\n",
    "    nodes = ([n for n in (node_order or []) if n in detected] +\n",
    "             [n for n in detected if (not node_order or n not in node_order)])\n",
    "\n",
    "    # 3) split per scope\n",
    "    df[\"vscope\"] = df[\"vscope\"].astype(str)\n",
    "    sys_df  = df[df[\"vscope\"] == \"OVERALL\"].copy()\n",
    "    node_df = {n: df[df[\"vscope\"] == f\"NODE_{n}\"].copy() for n in nodes}\n",
    "\n",
    "    # 4) CI simulazione (SYSTEM + NODI) e collasso per λ\n",
    "    sys_ci  = _ci_half_from_df_generic(sys_df,  n_rep=n_rep, conf=conf,\n",
    "                                       ci_design_effect=ci_design_effect,\n",
    "                                       mean_col=mean_col, std_col=std_col)\n",
    "    node_ci = {n: _ci_half_from_df_generic(node_df[n], n_rep=n_rep, conf=conf,\n",
    "                                           ci_design_effect=ci_design_effect,\n",
    "                                           mean_col=mean_col, std_col=std_col)\n",
    "               for n in nodes}\n",
    "    sys_ci  = _collapse_by_lambda(sys_ci,  how=collapse_how)\n",
    "    node_ci = {n: _collapse_by_lambda(d, how=collapse_how) for n, d in node_ci.items()}\n",
    "\n",
    "    # 5) modello analitico dal CSV (SOLO SYSTEM)\n",
    "    model = analytic_df.copy()\n",
    "    if \"lambda\" in model.columns:\n",
    "        model = model.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "    if \"mean_response_time\" not in model.columns or \"arrival_rate\" not in model.columns:\n",
    "        raise ValueError(\"analytic_df deve contenere almeno 'arrival_rate' e 'mean_response_time'.\")\n",
    "    model = model.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "\n",
    "    # 6) layout\n",
    "    n_panels = 1 + len(nodes)\n",
    "    rows = math.ceil(n_panels / max(1, cols))\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize, sharex=True)\n",
    "    axs = axs.flatten() if isinstance(axs, np.ndarray) else [axs]\n",
    "    fig.suptitle(title, y=0.98)\n",
    "\n",
    "    col_sim = _pal(\"SIM\",    \"#ff7f0e\")  # <-- definito sopra\n",
    "    col_the = _pal(\"THEORY\", \"#1f77b4\")  # <-- definito sopra\n",
    "\n",
    "    # --- SYSTEM ---\n",
    "    ax = axs[0]\n",
    "    line_h, band_h, ci_h = _draw_ci_banded(\n",
    "        ax,\n",
    "        x=sys_ci[\"arrival_rate\"], mean=sys_ci[\"mean\"], half=sys_ci[\"half\"],\n",
    "        color=col_sim, label_line=\"simulation (mean)\",\n",
    "        label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "        min_display_half=min_display_half, ci_fill=ci_fill\n",
    "    )\n",
    "    handles = [line_h] + ([band_h] if band_h is not None else []) + [ci_h]\n",
    "\n",
    "    (h_model,) = ax.plot(\n",
    "        model[\"arrival_rate\"], model[\"mean_response_time\"],\n",
    "        color=col_the, linewidth=2.3, linestyle=\"--\",\n",
    "        marker=\"s\", markersize=4, label=\"analytical model\", zorder=6\n",
    "    )\n",
    "    handles.append(h_model)\n",
    "\n",
    "    # linea verticale a X_max (se presente)\n",
    "    # --- X_max (asintoto): linea + voce in legenda + etichetta testuale + tacca su asse X\n",
    "    Xsat = None\n",
    "    if \"X_max\" in model.columns and pd.notna(model[\"X_max\"]).any():\n",
    "        try:\n",
    "            Xsat = float(model[\"X_max\"].dropna().iloc[0])\n",
    "        except Exception:\n",
    "            Xsat = None\n",
    "\n",
    "    if Xsat is not None and np.isfinite(Xsat):\n",
    "        # 1) linea verticale sull'asintoto\n",
    "        ax.axvline(Xsat, linestyle=\"--\", color=col_the, alpha=0.85, linewidth=1.8)\n",
    "\n",
    "        # 2) aggiungi una voce alla legenda (proxy handle) nei 'handles' usati sotto\n",
    "        handles.append(Line2D([0], [0], color=col_the, linestyle=\"--\",\n",
    "                            label=f\"λ* ≈ {Xsat:.3g}\"))\n",
    "\n",
    "        # 3) etichetta verticale vicino alla linea\n",
    "        ylim_top = ax.get_ylim()[1]\n",
    "        ax.annotate(f\"λ* ≈ {Xsat:.3g}\",\n",
    "                    xy=(Xsat, ylim_top), xycoords=(\"data\", \"data\"),\n",
    "                    xytext=(5, -5), textcoords=\"offset points\",\n",
    "                    rotation=90, va=\"top\", ha=\"left\",\n",
    "                    fontsize=10, color=col_the,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.75))\n",
    "\n",
    "        # 4) tacca sull’asse X per leggere subito il valore\n",
    "        ax.set_xticks(np.unique(np.append(ax.get_xticks(), Xsat)))\n",
    "\n",
    "        ax.set_title(\"SYSTEM average response time\")\n",
    "        ax.set_xlabel(\"Lambda\"); ax.set_ylabel(f\"Avg response time in SYSTEM [{ylabel_unit}]\")\n",
    "        #ax.set_yscale(\"log\") #per obiettivo 3\n",
    "        ax.legend(handles=handles, loc=\"upper left\")\n",
    "\n",
    "    # --- NODI (solo simulazione) ---\n",
    "    for i, n in enumerate(nodes, start=1):\n",
    "        ax = axs[i]\n",
    "        d = node_ci[n]\n",
    "        line_h, band_h, ci_h = _draw_ci_banded(\n",
    "            ax,\n",
    "            x=d[\"arrival_rate\"], mean=d[\"mean\"], half=d[\"half\"],\n",
    "            color=col_sim, label_line=\"simulation (mean)\",\n",
    "            label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "            min_display_half=min_display_half, ci_fill=ci_fill\n",
    "        )\n",
    "        handles = [line_h] + ([band_h] if band_h is not None else []) + [ci_h]\n",
    "        ax.set_title(f\"{n} average response time\")\n",
    "        ax.set_xlabel(\"Lambda\"); ax.set_ylabel(f\"Avg response time in {n} [{ylabel_unit}]\")\n",
    "        #ax.set_yscale(\"log\") #per obiettivo 3\n",
    "        ax.legend(handles=handles, loc=\"upper left\")\n",
    "\n",
    "    # pannelli extra\n",
    "    for j in range(1 + len(nodes), len(axs)):\n",
    "        axs[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, dpi=160, bbox_inches=\"tight\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df di simulazione -> 'files' (lista di CSV) o un singolo CSV/DF\n",
    "# analytic_df -> il CSV analitico già caricato (con 'arrival_rate','mean_response_time', opz. 'X_max')\n",
    "\n",
    "plot_finite_response_time_banded_v3(\n",
    "    files_or_path=files,\n",
    "    analytic_df=analytic_df,\n",
    "    n_rep=5,\n",
    "    conf=0.95,\n",
    "    ci_design_effect=12.0,\n",
    "    ci_fill=True,\n",
    "    min_display_half=0.0,\n",
    "    node_order=[\"A\", \"B\", \"P\"],\n",
    "    collapse_how=\"mean\",\n",
    "    figsize=(12, 9),\n",
    "    title=\"Simulation vs Analytical — Response Time\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fa220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nodes_rt(\n",
    "    files_or_path,\n",
    "    analytic_df: pd.DataFrame,                 # <-- CSV analitico con: arrival_rate, X_max, util_A/util_B/..., ecc.\n",
    "    *,\n",
    "    nodes: tuple[str, ...] | None = None,\n",
    "    width: float = 9.5,\n",
    "    height: float = 5.2,\n",
    "    dpi: int = 130,\n",
    "    zoom_range: tuple[float, float] | None = (0.8, 1.21),\n",
    "    x_overview_cap: float = 1.6,\n",
    "    right_pad_ratio: float = 0.06,\n",
    "    y_cap_overview: float | None = None,\n",
    "    y_cap_zoom: float | None = None,\n",
    "    percentile_cap: float = 99.0,\n",
    "    per_job_nodes: set[str] = frozenset(),     # se un nodo è qui: R_job = v_i * R_visit\n",
    "    visits: dict[str, float] = None,           # visite per nodo (serve solo per la vista per-visita)\n",
    "    zoom_box_frac: float = 0.06,               # altezza del box grigio nell’overview (6%)\n",
    "    n_rep: int = 5,\n",
    "    conf: float = 0.95,\n",
    "    ci_design_effect: float = 12.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    NODES response time: overview = media simulazione; zoom = media ± CI.\n",
    "    La curva teorica per nodo i viene dal CSV analitico usando:\n",
    "      - ρ_i = util_<i>\n",
    "      - λ = arrival_rate\n",
    "      - v_i (visits) se serve la vista per-visita.\n",
    "    Formula M/M/1:\n",
    "      R_visit_i = ρ_i / (λ v_i (1-ρ_i))\n",
    "      R_job_i   = v_i * R_visit_i = ρ_i / (λ (1-ρ_i))      (indipendente da v_i)\n",
    "    \"\"\"\n",
    "    # --- setup visite ---\n",
    "    if visits is None:\n",
    "        visits = {\"A\": 3.0, \"B\": 1.0, \"P\": 1.0}\n",
    "\n",
    "    # --- carica DF simulazione ---\n",
    "    df = _ensure_df(files_or_path)  # usa utilità già definite nella cella precedente\n",
    "    df_nodes = df[df[\"vscope\"].astype(str).str.startswith(\"NODE_\")].copy()\n",
    "    if df_nodes.empty or \"mean_response_time\" not in df_nodes.columns:\n",
    "        print(\"Mancano dati NODE_*/mean_response_time.\")\n",
    "        return\n",
    "\n",
    "    # --- set nodi da plottare ---\n",
    "    detected = sorted([s.replace(\"NODE_\", \"\") for s in df_nodes[\"vscope\"].unique()])\n",
    "    if nodes is None:\n",
    "        nodes_list = detected\n",
    "    else:\n",
    "        nodes_list = [n for n in nodes if n in detected]\n",
    "    if not nodes_list:\n",
    "        print(\"Nessun nodo da plottare dopo il filtro.\")\n",
    "        return\n",
    "\n",
    "    # --- CI per nodo (simulazione) ---\n",
    "    def ci_node(n: str) -> pd.DataFrame:\n",
    "        sub = df_nodes[df_nodes[\"vscope\"] == f\"NODE_{n}\"].copy()\n",
    "        ci = _ci_half_from_df_generic(\n",
    "            sub,\n",
    "            n_rep=n_rep, conf=conf, ci_design_effect=ci_design_effect,\n",
    "            mean_col=\"mean_response_time\", std_col=\"std_response_time\",\n",
    "        )\n",
    "        return _collapse_by_lambda(ci, how=\"mean\")\n",
    "\n",
    "    agg_by_node = {n: ci_node(n) for n in nodes_list}\n",
    "\n",
    "    # --- X_sat dal CSV analitico + dati teorici per nodo dal CSV ---\n",
    "    model = analytic_df.copy()\n",
    "    if \"lambda\" in model.columns and \"arrival_rate\" not in model.columns:\n",
    "        model = model.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "    # ordina e prendi X_max (se presente)\n",
    "    model = model.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "    X_sat = None\n",
    "    if \"X_max\" in model.columns and pd.notna(model[\"X_max\"]).any():\n",
    "        try:\n",
    "            X_sat = float(model[\"X_max\"].dropna().iloc[0])\n",
    "        except Exception:\n",
    "            X_sat = None\n",
    "\n",
    "    # costruiamo una funzione teorica sui punti del CSV (niente stime interne)\n",
    "    def theory_series_for_node(n: str) -> pd.DataFrame | None:\n",
    "        col_rho = f\"util_{n}\"\n",
    "        if col_rho not in model.columns:\n",
    "            return None\n",
    "        lam = model[\"arrival_rate\"].to_numpy(float)\n",
    "        rho = model[col_rho].to_numpy(float)\n",
    "        v_i = float(visits.get(n, 1.0))\n",
    "\n",
    "        # per-visit e per-job\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            R_visit = rho / (lam * v_i * (1.0 - rho))\n",
    "            R_job   = rho / (lam * (1.0 - rho))\n",
    "        # maschera valori non fisici (rho>=1 o non finiti)\n",
    "        mask = np.isfinite(R_visit) & (rho < 1.0 - 1e-12) & np.isfinite(lam) & (lam > 0)\n",
    "        R_visit = np.where(mask, R_visit, np.nan)\n",
    "        R_job   = np.where(mask, R_job,   np.nan)\n",
    "\n",
    "        out = pd.DataFrame({\"arrival_rate\": lam})\n",
    "        out[\"R_visit\"] = R_visit\n",
    "        out[\"R_job\"]   = R_job\n",
    "        return out\n",
    "\n",
    "    theory_by_node = {n: theory_series_for_node(n) for n in nodes_list}\n",
    "\n",
    "    # --- range X (overview) ---\n",
    "    x_all = pd.concat([agg_by_node[n][\"arrival_rate\"] for n in nodes_list], ignore_index=True)\n",
    "    x_min, x_max = float(np.nanmin(x_all)), float(np.nanmax(x_all))\n",
    "    if zoom_range is None:\n",
    "        x_overview_min = x_min\n",
    "        x_target_max = x_max\n",
    "    else:\n",
    "        x_overview_min = min(x_min, zoom_range[0])\n",
    "        x_target_max = max(x_max, zoom_range[1])\n",
    "    if X_sat is not None:\n",
    "        x_target_max = max(x_target_max, X_sat * 1.02)\n",
    "    x_overview_max = min(x_target_max * (1.0 + right_pad_ratio), x_overview_cap)\n",
    "\n",
    "    # --- helper di disegno ---\n",
    "    def draw_mean(ax, g: pd.DataFrame, *, color, label):\n",
    "        x = g[\"arrival_rate\"].to_numpy(float)\n",
    "        m = g[\"mean\"].to_numpy(float)\n",
    "        ax.plot(x, m, \"o-\", linewidth=2.0, color=color, label=label, zorder=3)\n",
    "        return m\n",
    "\n",
    "    def draw_mean_ci(ax, g: pd.DataFrame, *, color, label):\n",
    "        x  = g[\"arrival_rate\"].to_numpy(float)\n",
    "        m  = g[\"mean\"].to_numpy(float)\n",
    "        lo = m - g[\"half\"].to_numpy(float)\n",
    "        hi = m + g[\"half\"].to_numpy(float)\n",
    "        ax.errorbar(x, m, yerr=[m - lo, hi - m], fmt=\"o-\", color=color,\n",
    "                    ecolor=color, elinewidth=2.0, capsize=5, alpha=0.9, linewidth=2.0,\n",
    "                    label=label, zorder=4)\n",
    "        return m, lo, hi\n",
    "\n",
    "    def auto_cap(pool):\n",
    "        vals = np.hstack([p[np.isfinite(p)] for p in pool if p is not None] or [])\n",
    "        if vals.size:\n",
    "            cap = np.nanpercentile(vals, percentile_cap) * 1.05\n",
    "            return float(cap) if np.isfinite(cap) else None\n",
    "        return None\n",
    "\n",
    "    # --- figure: overview + zoom ---\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        2, 1, figsize=(width, height * 1.35), dpi=dpi,\n",
    "        gridspec_kw={\"height_ratios\": [2, 1]}\n",
    "    )\n",
    "\n",
    "    pool_o, pool_z = [], []\n",
    "\n",
    "    for n in nodes_list:\n",
    "        col = PALETTE.get(n, \"#333333\")  # usa la tua palette se definita\n",
    "        lbl = f\"Node {n}\"\n",
    "\n",
    "        # overview → SOLO mean simulazione\n",
    "        m_o = draw_mean(ax1, agg_by_node[n], color=col, label=f\"{lbl} (mean)\")\n",
    "        pool_o.append(m_o)\n",
    "\n",
    "        # zoom → mean ± CI simulazione\n",
    "        m_z, lo_z, hi_z = draw_mean_ci(ax2, agg_by_node[n], color=col, label=f\"{lbl} (mean ± CI)\")\n",
    "        pool_z.extend([m_z, lo_z, hi_z])\n",
    "\n",
    "        # teoria dal CSV\n",
    "        th = theory_by_node[n]\n",
    "        if th is not None:\n",
    "            series = \"R_job\" if n in per_job_nodes else \"R_visit\"\n",
    "            y_over = th[(th[\"arrival_rate\"] >= x_overview_min) & (th[\"arrival_rate\"] <= x_overview_max)][series].to_numpy(float)\n",
    "            x_over = th[(th[\"arrival_rate\"] >= x_overview_min) & (th[\"arrival_rate\"] <= x_overview_max)][\"arrival_rate\"].to_numpy(float)\n",
    "            if np.isfinite(y_over).any():\n",
    "                ax1.plot(x_over, y_over, color=col, linestyle=\"--\", linewidth=1.8, alpha=0.9, label=f\"{lbl} theory\", zorder=2)\n",
    "                pool_o.append(y_over)\n",
    "\n",
    "            if zoom_range is not None:\n",
    "                maskz = (th[\"arrival_rate\"] >= zoom_range[0]) & (th[\"arrival_rate\"] <= zoom_range[1])\n",
    "                x_zoom = th.loc[maskz, \"arrival_rate\"].to_numpy(float)\n",
    "                y_zoom = th.loc[maskz, series].to_numpy(float)\n",
    "                if np.isfinite(y_zoom).any():\n",
    "                    ax2.plot(x_zoom, y_zoom, color=col, linestyle=\"--\", linewidth=1.8, alpha=0.9, label=f\"{lbl} theory\", zorder=2)\n",
    "                    pool_z.append(y_zoom)\n",
    "\n",
    "    # X_sat (se noto)\n",
    "    if X_sat is not None:\n",
    "        if x_overview_min <= X_sat <= x_overview_max:\n",
    "            ax1.axvline(X_sat, linestyle=\"--\", color=PALETTE.get(\"THEORY\", \"#1f77b4\"),\n",
    "                        alpha=0.9, linewidth=2.0, label=\"X_max\")\n",
    "        if zoom_range and (zoom_range[0] <= X_sat <= zoom_range[1]):\n",
    "            ax2.axvline(X_sat, linestyle=\"--\", color=PALETTE.get(\"THEORY\", \"#1f77b4\"),\n",
    "                        alpha=0.9, linewidth=2.0, label=\"X_max\")\n",
    "\n",
    "    # cap Y auto (se non forniti)\n",
    "    if y_cap_overview is None:\n",
    "        y_cap_overview = auto_cap(pool_o)\n",
    "    if y_cap_zoom is None:\n",
    "        y_cap_zoom = auto_cap(pool_z)\n",
    "\n",
    "    # limiti assi\n",
    "    ax1.set_xlim(x_overview_min, x_overview_max)\n",
    "    if zoom_range is not None:\n",
    "        ax2.set_xlim(*zoom_range)\n",
    "    ax1.set_ylim(bottom=0, top=y_cap_overview)\n",
    "    ax2.set_ylim(bottom=0, top=y_cap_zoom)\n",
    "\n",
    "    # box grigio “zoom” nell’overview\n",
    "    if zoom_range is not None:\n",
    "        import matplotlib.patches as patches\n",
    "        y0, y1 = ax1.get_ylim()\n",
    "        ax1.add_patch(patches.Rectangle(\n",
    "            (zoom_range[0], y0),\n",
    "            zoom_range[1] - zoom_range[0],\n",
    "            (y1 - y0) * float(zoom_box_frac),\n",
    "            facecolor=\"none\", edgecolor=\"gray\", linestyle=\"--\", linewidth=2.0, zorder=6\n",
    "        ))\n",
    "\n",
    "    # aspetto\n",
    "    ax1.set_ylabel(\"Mean Response Time (s)\")\n",
    "    ax2.set_ylabel(\"Mean Response Time (s)\")\n",
    "    ax1.set_title(f\"{TITLE_PREFIX} — NODES: overview + zoom\" if 'TITLE_PREFIX' in globals() else \"NODES: overview + zoom\")\n",
    "    if zoom_range:\n",
    "        ax2.set_title(f\"Zoom su {zoom_range[0]:.3g}–{zoom_range[1]:.3g}\")\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "    ax2.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "\n",
    "    # legende (dedup)\n",
    "    for ax in (ax1, ax2):\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        uniq = dict(zip(l, h))\n",
    "        ax.legend(uniq.values(), uniq.keys(), loc=\"upper left\", fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e26b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fai il plot\n",
    "plot_nodes_rt(\n",
    "    files_or_path=files,      # qui passi i CSV di simulazione (lista o path)\n",
    "    analytic_df=analytic_df,  # qui il CSV analitico già caricato\n",
    "    nodes=(\"A\", \"B\", \"P\"),    # opzionale: quali nodi plottare\n",
    "    n_rep=5,\n",
    "    conf=0.95,\n",
    "    zoom_range=(0.8, 1.21),   # range X per lo zoom\n",
    "    visits={\"A\": 3, \"B\": 1, \"P\": 1},   # le visite che vuoi\n",
    "    per_job_nodes=set(),      # se vuoi per-job, metti ad es. {\"A\"} ecc.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# SYSTEM THROUGHPUT — usa analitico da CSV (niente residui)\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "def _pick_xcol(df: pd.DataFrame) -> tuple[str, str]:\n",
    "    \"\"\"Sceglie la X: preferisce 'arrival_rate', altrimenti 'replica' se esiste.\"\"\"\n",
    "    if \"arrival_rate\" in df.columns and df[\"arrival_rate\"].notna().sum() >= 2:\n",
    "        return \"arrival_rate\", \"Arrival Rate (λ)\"\n",
    "    if \"replica\" in df.columns:\n",
    "        return \"replica\", \"Replica\"\n",
    "    return \"arrival_rate\", \"Arrival Rate (λ)\"\n",
    "\n",
    "def _collapse_scope_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Uniforma la colonna di scope: usa 'vscope' se presente, altrimenti 'scope'.\"\"\"\n",
    "    if \"vscope\" in df.columns:\n",
    "        return df.rename(columns={\"vscope\": \"scope\"})\n",
    "    return df\n",
    "\n",
    "def _aggregate_throughput_ci(df_overall: pd.DataFrame,\n",
    "                             xcol: str,\n",
    "                             conf: float = 0.95) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Media e IC *tra repliche* per il throughput.\n",
    "    Se per una X c'è 1 sola riga → barra nulla.\n",
    "    Ritorna colonne: [xcol, 'mean', 'ci_lo', 'ci_hi'] ordinate per X.\n",
    "    \"\"\"\n",
    "    zt = lambda R: float(student_t.ppf(0.5 + conf/2.0, max(R-1, 1)))\n",
    "    rows = []\n",
    "    for x, g in df_overall.groupby(xcol, sort=True):\n",
    "        vals = pd.to_numeric(g[\"throughput\"], errors=\"coerce\").dropna()\n",
    "        if len(vals) == 0:\n",
    "            continue\n",
    "        m = float(vals.mean())\n",
    "        if len(vals) >= 2:\n",
    "            s = float(vals.std(ddof=1))\n",
    "            half = zt(len(vals)) * s / math.sqrt(len(vals))\n",
    "            lo, hi = m - half, m + half\n",
    "        else:\n",
    "            lo = hi = m\n",
    "        rows.append({xcol: float(x), \"mean\": m, \"ci_lo\": lo, \"ci_hi\": hi})\n",
    "    return pd.DataFrame(rows).sort_values(xcol).reset_index(drop=True)\n",
    "\n",
    "def plot_system_throughput(df_all: pd.DataFrame,\n",
    "                           analytic_df: pd.DataFrame,\n",
    "                           *,\n",
    "                           width: float = 8.6,\n",
    "                           height: float = 4.6,\n",
    "                           dpi: int = 130,\n",
    "                           show_theory: bool = True,\n",
    "                           clip_at_Xsat: bool = False,\n",
    "                           ci_conf: float = 0.95):\n",
    "    \"\"\"\n",
    "    Confronto throughput complessivo:\n",
    "      - Simulazione: mean ± CI (da df_all['throughput'])\n",
    "      - Analitico:   X(λ)=λ (da analytic_df['arrival_rate']), mascherato/plateau a X_max\n",
    "    Nessun pannello dei residui.\n",
    "    \"\"\"\n",
    "    # --- prepara OVERALL (simulazione)\n",
    "    df = _collapse_scope_col(df_all.copy())\n",
    "    overall_mask = df[\"scope\"].astype(str).str.upper().eq(\"OVERALL\")\n",
    "    df_overall = df.loc[overall_mask].copy()\n",
    "    if df_overall.empty or \"throughput\" not in df_overall.columns:\n",
    "        print(\"Mancano dati OVERALL/throughput.\")\n",
    "        return\n",
    "\n",
    "    xcol, xlabel = _pick_xcol(df_overall)\n",
    "    agg = _aggregate_throughput_ci(df_overall, xcol=xcol, conf=ci_conf)\n",
    "\n",
    "    # --- modello analitico dal CSV\n",
    "    model = analytic_df.copy()\n",
    "    if \"lambda\" in model.columns and \"arrival_rate\" not in model.columns:\n",
    "        model = model.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "    X_sat = float(model[\"X_max\"].iloc[0]) if \"X_max\" in model.columns and pd.notna(model[\"X_max\"]).any() else float(\"nan\")\n",
    "    model = model.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "\n",
    "    x_theory = model[\"arrival_rate\"].to_numpy(float)\n",
    "    y_theory = x_theory.copy()  # X(λ)=λ\n",
    "    if np.isfinite(X_sat):\n",
    "        if clip_at_Xsat:\n",
    "            y_theory = np.where(x_theory <= X_sat, x_theory, X_sat)\n",
    "        else:\n",
    "            y_theory = np.where(x_theory <= X_sat, x_theory, np.nan)\n",
    "\n",
    "    # --- figura singola (niente residui)\n",
    "    fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "\n",
    "    # simulazione (mean ± CI)\n",
    "    x  = agg[xcol].to_numpy(float)\n",
    "    mu = agg[\"mean\"].to_numpy(float)\n",
    "    lo = np.where(np.isfinite(agg[\"ci_lo\"]), agg[\"ci_lo\"].to_numpy(float), mu)\n",
    "    hi = np.where(np.isfinite(agg[\"ci_hi\"]), agg[\"ci_hi\"].to_numpy(float), mu)\n",
    "\n",
    "    col_sim = (PALETTE.get(\"SIM\", \"#ff7f0e\") if 'PALETTE' in globals() else \"#ff7f0e\")\n",
    "    col_the = (PALETTE.get(\"THEORY\", \"#1f77b4\") if 'PALETTE' in globals() else \"#1f77b4\")\n",
    "\n",
    "    ax.plot(x, mu, \"o-\", linewidth=2.1, color=col_sim, label=\"Sim (mean)\")\n",
    "    ax.fill_between(x, lo, hi, alpha=0.18, linewidth=0, color=col_sim, label=f\"CI {int(ci_conf*100)}%\")\n",
    "\n",
    "    # analitico + X_max\n",
    "    if show_theory and xcol == \"arrival_rate\":\n",
    "        ax.plot(x_theory, y_theory, color=col_the, linewidth=2.0,\n",
    "                label=(\"Analytical (plateau)\" if clip_at_Xsat else \"Analytical\"))\n",
    "        if np.isfinite(X_sat):\n",
    "            ax.axvline(X_sat, linestyle=\"--\", color=col_the, alpha=0.9, linewidth=2.0,\n",
    "                       label=f\"X_max ≈ {X_sat:.3f}\")\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Throughput X (req/s)\")\n",
    "    ttl = f\"{TITLE_PREFIX} — SYSTEM: Throughput (sim vs analytical)\" if 'TITLE_PREFIX' in globals() \\\n",
    "          else \"SYSTEM: Throughput (sim vs analytical)\"\n",
    "    ax.set_title(ttl)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "\n",
    "    # legenda deduplicata\n",
    "    h, l = ax.get_legend_handles_labels()\n",
    "    uniq = dict(zip(l, h))\n",
    "    ax.legend(uniq.values(), uniq.keys(), loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# NODES THROUGHPUT — usa analitico da CSV (niente stime interne)\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "def _pick_xcol_nodes(df_nodes: pd.DataFrame) -> tuple[str, str]:\n",
    "    \"\"\"Sceglie la X: preferisce 'arrival_rate', altrimenti 'replica' se esiste.\"\"\"\n",
    "    if \"arrival_rate\" in df_nodes.columns and df_nodes[\"arrival_rate\"].notna().sum() >= 2:\n",
    "        return \"arrival_rate\", \"Arrival Rate (λ)\"\n",
    "    if \"replica\" in df_nodes.columns:\n",
    "        return \"replica\", \"Replica\"\n",
    "    return \"arrival_rate\", \"Arrival Rate (λ)\"  # tentativo di default\n",
    "\n",
    "def _scope_to_node_list(df_nodes: pd.DataFrame, wanted_nodes: tuple[str, ...] | None):\n",
    "    \"\"\"Restituisce la lista ordinata di scope 'NODE_X' filtrata su wanted_nodes se dato.\"\"\"\n",
    "    scopes_all = sorted([s for s in df_nodes[\"scope\"].dropna().unique().tolist() if str(s).startswith(\"NODE_\")])\n",
    "    if wanted_nodes is None:\n",
    "        return scopes_all\n",
    "    wanted = {f\"NODE_{n}\" for n in wanted_nodes}\n",
    "    return [s for s in scopes_all if s in wanted]\n",
    "\n",
    "def _aggregate_node_throughput_ci(df_nodes: pd.DataFrame,\n",
    "                                  scope: str,\n",
    "                                  xcol: str,\n",
    "                                  conf: float = 0.95) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Media e IC *tra repliche* per il throughput del nodo 'scope'.\n",
    "    Se per una X c'è una sola riga → barra nulla.\n",
    "    \"\"\"\n",
    "    zt = lambda R: float(student_t.ppf(0.5 + conf/2.0, max(R-1, 1)))\n",
    "    gscope = df_nodes[df_nodes[\"scope\"] == scope].copy()\n",
    "    rows = []\n",
    "    for x, g in gscope.groupby(xcol, sort=True):\n",
    "        vals = pd.to_numeric(g[\"throughput\"], errors=\"coerce\").dropna()\n",
    "        if len(vals) == 0:\n",
    "            continue\n",
    "        m = float(vals.mean())\n",
    "        if len(vals) >= 2:\n",
    "            s = float(vals.std(ddof=1))\n",
    "            half = zt(len(vals)) * s / math.sqrt(len(vals))\n",
    "            lo, hi = m - half, m + half\n",
    "        else:\n",
    "            lo = hi = m\n",
    "        rows.append({xcol: float(x), \"mean\": m, \"ci_lo\": lo, \"ci_hi\": hi})\n",
    "    return pd.DataFrame(rows).sort_values(xcol).reset_index(drop=True)\n",
    "\n",
    "def plot_nodes_throughput(df_all: pd.DataFrame,\n",
    "                          visits: dict[str, int],\n",
    "                          *,\n",
    "                          nodes: tuple[str, ...] | None = None,\n",
    "                          width: float = 9.5,\n",
    "                          height: float = 5.0,\n",
    "                          dpi: int = 130,\n",
    "                          show_theory: bool = True):\n",
    "    \"\"\"\n",
    "    Confronto throughput per-nodo (simulato mean±CI) vs analitico.\n",
    "    Teoria: X_j(λ) = V_j * λ con V_j preso dal dizionario visits.\n",
    "    \"\"\"\n",
    "    df_nodes = df_all[df_all[\"scope\"].astype(str).str.startswith(\"NODE_\")].copy()\n",
    "    if df_nodes.empty or \"throughput\" not in df_nodes.columns:\n",
    "        print(\"Mancano dati NODE_*/throughput.\"); \n",
    "        return\n",
    "\n",
    "    # nodi dinamici/filtro\n",
    "    scopes_all = _node_order(df_nodes[\"scope\"].dropna().unique().tolist())\n",
    "    if nodes is not None:\n",
    "        wanted = {f\"NODE_{n}\" for n in nodes}\n",
    "        scopes = [s for s in scopes_all if s in wanted]\n",
    "    else:\n",
    "        scopes = scopes_all\n",
    "    if not scopes:\n",
    "        print(\"Nessun nodo da plottare dopo il filtro.\"); \n",
    "        return\n",
    "\n",
    "    # Asse X\n",
    "    if \"arrival_rate\" in df_nodes.columns and df_nodes[\"arrival_rate\"].notna().sum() >= 2:\n",
    "        xcol, xlabel = \"arrival_rate\", \"Arrival Rate (λ)\"\n",
    "    else:\n",
    "        xcol, xlabel = (\"replica\", \"Replica\")\n",
    "\n",
    "    # Aggrego simulazione per nodo\n",
    "    agg_by_node = {scope: agg_ci(df_nodes[df_nodes[\"scope\"] == scope], xcol, \"throughput\")\n",
    "                   for scope in scopes}\n",
    "\n",
    "    # --- Figure ---\n",
    "    fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "\n",
    "    # Simulazione\n",
    "    scope_index = {scope: idx for idx, scope in enumerate(scopes)}\n",
    "    for scope in scopes:\n",
    "        node  = scope.replace(\"NODE_\", \"\")\n",
    "        label = _node_label(scope)\n",
    "        col   = PALETTE.get(node, f\"C{scope_index[scope] % 10}\")\n",
    "        g = agg_by_node[scope]\n",
    "\n",
    "        x  = g[xcol].to_numpy()\n",
    "        mu = g[\"mean\"].to_numpy(dtype=float)\n",
    "        lo = np.where(np.isfinite(g[\"ci_lo\"]), g[\"ci_lo\"], mu)\n",
    "        hi = np.where(np.isfinite(g[\"ci_hi\"]), g[\"ci_hi\"], mu)\n",
    "\n",
    "        ms = marker_style_for(scope_index[scope], col)\n",
    "        ax.plot(x, mu, linewidth=2.0, color=col, label=f\"{label} (sim mean)\", **ms)\n",
    "        ax.fill_between(x, lo, hi, alpha=0.16, linewidth=0, color=col, label=f\"{label} CI95%\")\n",
    "\n",
    "        # Teoria: X_j(λ) = V_j * λ\n",
    "        if show_theory and node in visits:\n",
    "            X_theory = visits[node] * x\n",
    "            ax.plot(x, X_theory, linestyle=\"--\", linewidth=1.6, color=col, alpha=0.9,\n",
    "                    label=f\"{label} analytical\")\n",
    "\n",
    "    # Stile\n",
    "    ax.set_ylabel(\"Node Throughput X_j (req/s)\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_title(f\"{TITLE_PREFIX} — NODES: Throughput (sim vs analytical)\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "\n",
    "    # legenda pulita\n",
    "    h, l = ax.get_legend_handles_labels()\n",
    "    uniq = dict(zip(l, h))\n",
    "    ax.legend(uniq.values(), uniq.keys(), loc=\"upper left\", fontsize=9, ncol=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d235342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto throughput complessivo\n",
    "# analytic_df ottenuto dal tuo CSV analitico completo\n",
    "plot_system_throughput(df_all, analytic_df, clip_at_Xsat=False, ci_conf=0.95)\n",
    "\n",
    "\n",
    "\n",
    "# definisci le visite\n",
    "visits = {\"A\": 3, \"B\": 1, \"P\": 1}\n",
    "\n",
    "# chiama la funzione\n",
    "plot_nodes_throughput(\n",
    "    df_all=df_all,       # <-- qui ci metti il DataFrame delle simulazioni (quello con scope=NODE_*)\n",
    "    visits=visits,\n",
    "    nodes=(\"A\", \"B\", \"P\"),   # opzionale: limita a questi nodi, se vuoi\n",
    "    show_theory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rt_decomposition(df_all: pd.DataFrame, percent: bool = False):\n",
    "    \"\"\"\n",
    "    Disegna la decomposizione del tempo di risposta per tutti i nodi NODE_* presenti.\n",
    "    Se percent=True, mostra le percentuali (0–100%) invece dei valori assoluti.\n",
    "    \"\"\"\n",
    "    # filtra righe dei nodi\n",
    "    dn = df_all[df_all[\"scope\"].astype(str).str.startswith(\"NODE_\")].copy()\n",
    "    if dn.empty or \"mean_response_time\" not in dn.columns:\n",
    "        print(\"[INFO] Dati insufficienti per RT decomposition.\")\n",
    "        return\n",
    "\n",
    "    # media per (λ, nodo)\n",
    "    dn = dn.groupby([\"arrival_rate\", \"scope\"], as_index=False).mean(numeric_only=True)\n",
    "\n",
    "    # pivot: righe = λ, colonne = NODE_*\n",
    "    piv = dn.pivot(index=\"arrival_rate\", columns=\"scope\", values=\"mean_response_time\").fillna(0.0)\n",
    "\n",
    "    # ordina colonne alfabeticamente per nodo (A,B,C,P,...)\n",
    "    cols = sorted(piv.columns, key=lambda s: s.replace(\"NODE_\", \"\"))\n",
    "    piv = piv[cols].sort_index()\n",
    "\n",
    "    # se percentuale, normalizza per riga\n",
    "    if percent:\n",
    "        totals = piv.sum(axis=1).replace(0, np.nan)\n",
    "        piv = piv.div(totals, axis=0) * 100.0\n",
    "\n",
    "    # etichette \"A\",\"B\",\"C\",\"P\",... e colori (se PALETTE è definita)\n",
    "    labels = [c.replace(\"NODE_\", \"\") for c in piv.columns]\n",
    "    colors = []\n",
    "    for lab in labels:\n",
    "        try:\n",
    "            colors.append(PALETTE.get(lab, None))  # usa palette se disponibile\n",
    "        except NameError:\n",
    "            colors.append(None)  # fallback: colori default di Matplotlib\n",
    "\n",
    "    # se nessun colore esplicito, lascia che Matplotlib scelga la palette\n",
    "    use_colors = None if all(c is None for c in colors) else colors\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.8, 5.0))\n",
    "    ax.stackplot(piv.index, *[piv[c].values for c in piv.columns],\n",
    "                 labels=labels, colors=use_colors, alpha=0.85)\n",
    "    ax.set_xlabel(\"Arrival Rate (λ)\")\n",
    "    ax.set_ylabel(\"Share of Response Time (%)\" if percent else \"Response Time (s)\")\n",
    "    if percent:\n",
    "        ax.set_ylim(0, 100)\n",
    "    ax.set_title(f\"{TITLE_PREFIX} — RT decomposition per nodo\" + (\" (%)\" if percent else \"\"))\n",
    "    ax.legend(loc=\"upper left\", ncol=min(4, len(labels)))\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "    plt.show()\n",
    "plot_rt_decomposition(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d69be",
   "metadata": {},
   "source": [
    "Sull’asse X hai il tasso di arrivo (λ), cioè quante richieste al secondo entrano nel sistema.\n",
    "\n",
    "Sull’asse Y hai il tempo medio di risposta complessivo, ma scomposto (empilato) per ciascun nodo.\n",
    "\n",
    "Le aree colorate mostrano quanto ciascun nodo contribuisce al tempo totale.\n",
    "\n",
    "Interpretazione della figura:\n",
    "\n",
    "La parte verde (A) è il tempo medio speso sul server A (front-end). Rimane sempre piccola.\n",
    "\n",
    "La parte viola (P) è il tempo medio sul provider esterno. È quasi costante e poco rilevante.\n",
    "\n",
    "La parte rossa (B) è il tempo medio speso sul server B (app + DB). Questa cresce rapidamente con λ e diventa dominante.\n",
    "\n",
    "In altre parole, la figura ti dice visivamente che:\n",
    "\n",
    "quando il carico è basso, il tempo totale è distribuito un po’ fra tutti i nodi,\n",
    "\n",
    "ma già per λ intorno a 0.9–1.0 il server B diventa il collo di bottiglia,\n",
    "\n",
    "e vicino a λ=1.2 quasi tutto il tempo di risposta è dovuto a B.\n",
    "\n",
    "È un modo elegante per mostrare chi sta rallentando il sistema: la crescita verticale della parte rossa significa che il collo di bottiglia si concentra lì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd23343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- pattern dinamici in base a OBJ e BASE_DIR ---\n",
    "def make_patterns(obj: int, base_dir: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Genera una lista di pattern possibili per i CSV per-seed.\n",
    "    Tenta varianti con/senza 'arrivals' e diverse separazioni per safety.\n",
    "    \"\"\"\n",
    "    base_dir = base_dir.rstrip(\"/\\\\\")\n",
    "    patterns = [\n",
    "        os.path.join(base_dir, f\"results_obj{obj}_arrivals_run*_seed*.csv\"),\n",
    "        os.path.join(base_dir, f\"results_obj{obj}_run*_seed*.csv\"),\n",
    "        os.path.join(base_dir, f\"results_obj{obj}_arrivals_*seed*.csv\"),\n",
    "        os.path.join(base_dir, f\"results_obj{obj}_*seed*.csv\"),\n",
    "    ]\n",
    "    return patterns\n",
    "\n",
    "# regex seed più permissivo: _seed42, -seed=42, _seed-42, ecc.\n",
    "_SEED_RE = re.compile(r\"[ _-]seed[=_-]?(\\d+)\", re.IGNORECASE)\n",
    "\n",
    "def _coerce_numeric(df: pd.DataFrame, exclude=(\"scope\",)):\n",
    "    \"\"\"Converte in numerico tutte le colonne tranne quelle escluse; '-' -> NaN.\"\"\"\n",
    "    out = df.replace({\"-\": np.nan}).copy()\n",
    "    for c in out.columns:\n",
    "        if c not in exclude:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "def _seed_from_name(path: str) -> int | None:\n",
    "    m = _SEED_RE.search(os.path.basename(path))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def load_arrivals_by_seed(patterns: Iterable[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carica tutti i CSV che matchano uno QUALSIASI dei pattern,\n",
    "    aggiunge colonne source/replica/seed. Se non trova nulla, stampa i pattern provati.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for p in patterns:\n",
    "        files.extend(glob.glob(p))\n",
    "    files = sorted(set(files))  # dedup\n",
    "    if not files:\n",
    "        print(\"[WARN] Nessun CSV trovato per i pattern seguenti:\")\n",
    "        for p in patterns:\n",
    "            print(\" -\", p)\n",
    "        # opzionale: lista rapida della cartella\n",
    "        base_dirs = sorted(set(os.path.dirname(p) for p in patterns))\n",
    "        for d in base_dirs:\n",
    "            try:\n",
    "                print(f\"\\nContenuto di {d}:\")\n",
    "                for name in sorted(os.listdir(d)):\n",
    "                    if name.endswith(\".csv\"):\n",
    "                        print(\"   \", name)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"(Cartella inesistente: {d})\")\n",
    "        raise FileNotFoundError(\"Nessun CSV per-seed trovato.\")\n",
    "    dfs = []\n",
    "    for i, f in enumerate(files):\n",
    "        df = pd.read_csv(f)\n",
    "        df = _coerce_numeric(df)  # numerico ovunque possibile\n",
    "        df[\"source\"]  = os.path.basename(f)\n",
    "        df[\"replica\"] = i\n",
    "        df[\"seed\"]    = _seed_from_name(f)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def per_seed_overall(df_all: pd.DataFrame) -> Dict[int, pd.DataFrame]:\n",
    "    \"\"\"{seed -> DF OVERALL (una riga per λ, media se più righe)}\"\"\"\n",
    "    df_ov = df_all[df_all[\"scope\"] == \"OVERALL\"].copy()\n",
    "    out = {}\n",
    "    for seed, g in df_ov.groupby(\"seed\"):\n",
    "        gg = g.groupby(\"arrival_rate\", as_index=False).mean(numeric_only=True)\n",
    "        gg = gg.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "        out[int(seed) if pd.notna(seed) else -1] = gg\n",
    "    return out\n",
    "\n",
    "def per_seed_nodes(df_all: pd.DataFrame) -> Dict[int, pd.DataFrame]:\n",
    "    \"\"\"{seed -> DF nodi} una riga per (λ, scope)\"\"\"\n",
    "    dn = df_all.copy()\n",
    "    dn[\"scope\"] = dn[\"scope\"].astype(str)  # safety contro NaN\n",
    "    dn = dn[dn[\"scope\"].str.startswith(\"NODE_\")]\n",
    "    out = {}\n",
    "    for seed, g in dn.groupby(\"seed\"):\n",
    "        gg = g.groupby([\"arrival_rate\", \"scope\"], as_index=False).mean(numeric_only=True)\n",
    "        gg = gg.sort_values([\"arrival_rate\", \"scope\"]).reset_index(drop=True)\n",
    "        out[int(seed) if pd.notna(seed) else -1] = gg\n",
    "    return out\n",
    "\n",
    "# ----------------------------- plotting --------------------------------\n",
    "\n",
    "from typing import Iterable, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_overall_rt_per_seed(seed_to_df: Dict[int, pd.DataFrame],\n",
    "                             title=None, ylabel=\"Mean Response Time (s)\"):\n",
    "    \"\"\"Curve OVERALL per ogni seed, con marker dinamici e colori consistenti.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7.8, 5.2))\n",
    "\n",
    "    for i, (seed, df) in enumerate(sorted(seed_to_df.items())):\n",
    "        if {\"arrival_rate\", \"mean_response_time\"}.issubset(df.columns):\n",
    "            color = f\"C{i % 10}\"                     # colori dal ciclo default di Matplotlib\n",
    "            ms = marker_style_for(i, color)          # <-- marker dinamico\n",
    "            ax.plot(df[\"arrival_rate\"], df[\"mean_response_time\"],\n",
    "                    color=color, linewidth=1.8, label=f\"seed {seed}\", **ms)\n",
    "\n",
    "    ax.set_xlabel(\"Arrival Rate (λ)\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title or f\"{TITLE_PREFIX} — Overall RT per seed\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    ax.legend(ncol=2, fontsize=9)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_node_rt_per_seed(seed_to_nodes: Dict[int, pd.DataFrame], title=None):\n",
    "    \"\"\"\n",
    "    Curve per nodo (A/B/P/...) per ciascun seed, con marker dinamici:\n",
    "    - stessa forma/riempimento per lo *stesso nodo* in tutti i seed;\n",
    "    - colori: PALETTE per i nodi noti, fallback alla palette di Matplotlib.\n",
    "    \"\"\"\n",
    "    # ordine stabile dei NODE_* presente in tutti i DF\n",
    "    all_scopes = []\n",
    "    for df in seed_to_nodes.values():\n",
    "        if \"scope\" in df.columns:\n",
    "            all_scopes.extend(df[\"scope\"].dropna().astype(str).unique().tolist())\n",
    "    scopes_sorted = sorted({s for s in all_scopes if s.startswith(\"NODE_\")})\n",
    "    scope_index  = {scope: idx for idx, scope in enumerate(scopes_sorted)}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8.6, 5.2))\n",
    "\n",
    "    for seed, df in sorted(seed_to_nodes.items()):\n",
    "        for scope, g in df.groupby(\"scope\"):\n",
    "            if not {\"arrival_rate\", \"mean_response_time\"}.issubset(g.columns):\n",
    "                continue\n",
    "            node = scope.replace(\"NODE_\", \"\")\n",
    "            idx  = scope_index.get(scope, 0)\n",
    "            color = PALETTE.get(node, f\"C{idx % 10}\")   # colore coerente per nodo\n",
    "            ms = marker_style_for(idx, color)           # <-- marker dinamico per nodo\n",
    "            label = f\"{node} — seed {seed}\"\n",
    "            ax.plot(g[\"arrival_rate\"], g[\"mean_response_time\"],\n",
    "                    color=color, linewidth=1.6, label=label, **ms)\n",
    "\n",
    "    ax.set_xlabel(\"Arrival Rate (λ)\")\n",
    "    ax.set_ylabel(\"Mean Response Time (s)\")\n",
    "    ax.set_title(title or f\"{TITLE_PREFIX} — Per-node RT per seed\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # legenda deduplicata (quando ci sono molte linee)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    uniq = dict(zip(labels, handles))\n",
    "    ax.legend(uniq.values(), uniq.keys(), ncol=2, fontsize=8)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_overall_rt_mean_ci_across_seeds(seed_to_df: Dict[int, pd.DataFrame], title=None):\n",
    "    \"\"\"Media cross-seed con CI95% riusando line_with_ci.\"\"\"\n",
    "    frames = []\n",
    "    for seed, df in seed_to_df.items():\n",
    "        if {\"arrival_rate\", \"mean_response_time\"}.issubset(df.columns):\n",
    "            frames.append(df[[\"arrival_rate\", \"mean_response_time\"]])\n",
    "    if not frames:\n",
    "        print(\"[INFO] Nessun dato OVERALL per costruire la media cross-seed.\")\n",
    "        return\n",
    "    big = pd.concat(frames, ignore_index=True)\n",
    "    line_with_ci(\n",
    "        big, x=\"arrival_rate\", y=\"mean_response_time\",\n",
    "        title=title or f\"{TITLE_PREFIX} — Overall RT (mean ± CI95%) across seeds\",\n",
    "        xlabel=\"Arrival Rate (λ)\", ylabel=\"Mean Response Time (s)\"\n",
    "    )\n",
    "\n",
    "# --------- ESEMPIO DI USO ---------\n",
    "patterns = make_patterns(OBJ, BASE_DIR)\n",
    "df_all = load_arrivals_by_seed(patterns)\n",
    "print(\"Seeds trovati:\", sorted(df_all[\"seed\"].dropna().unique().astype(int).tolist()))\n",
    "\n",
    "by_seed_overall = per_seed_overall(df_all)\n",
    "plot_overall_rt_per_seed(by_seed_overall)\n",
    "\n",
    "by_seed_nodes = per_seed_nodes(df_all)\n",
    "# plot_node_rt_per_seed(by_seed_nodes)  # scommenta se vuoi anche per nodo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lambda_col(df: pd.DataFrame) -> str | None:\n",
    "    \"\"\"Trova la colonna dell'arrival rate (robusto a maiuscole/alias).\"\"\"\n",
    "    low = {c.lower().strip(): c for c in df.columns}\n",
    "    for k in (\"arrival_rate\", \"lambda\", \"lam\"):\n",
    "        if k in low:\n",
    "            return low[k]\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- loader: lista di DF (uno per file), con seed e source ---\n",
    "def load_conv_as_list(files: List[str]) -> List[pd.DataFrame]:\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        # numeric coercion, ma NON toccare scope/metric\n",
    "        df = _coerce_numeric(df, exclude=(\"scope\", \"metric\"))\n",
    "        df[\"seed\"] = _seed_from_name(f)\n",
    "        df[\"source\"] = os.path.basename(f)\n",
    "        dfs.append(df)\n",
    "    return dfs  # <- LISTA di DataFrame (uno per file)\n",
    "\n",
    "# --- estrai OVERALL/mean_response_time per seed (dict seed -> DF ordinato per num_departures) ---\n",
    "def overall_mean_rt_by_seed(dfs: List[pd.DataFrame],\n",
    "                            arrival_rate: float | None = None,\n",
    "                            atol: float = 1e-9) -> Dict[int, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Ritorna {seed -> DF[num_departures, mean_response_time]}.\n",
    "    Se arrival_rate è dato, tiene solo le righe con quel λ (tolleranza 'atol').\n",
    "    \"\"\"\n",
    "    out: Dict[int, pd.DataFrame] = {}\n",
    "    for df in dfs:\n",
    "        d = df.copy()\n",
    "\n",
    "        # filtro per λ se richiesto\n",
    "        lam_col = _lambda_col(d)\n",
    "        if arrival_rate is not None and lam_col is not None:\n",
    "            d[lam_col] = pd.to_numeric(d[lam_col], errors=\"coerce\")\n",
    "            keep = np.isclose(d[lam_col].to_numpy(float), float(arrival_rate),\n",
    "                              rtol=0.0, atol=atol)\n",
    "            d = d[keep]\n",
    "\n",
    "        seed = int(d[\"seed\"].iloc[0]) if \"seed\" in d.columns and not d.empty else -1\n",
    "        g = d[(d[\"scope\"] == \"OVERALL\") & (d[\"metric\"] == \"mean_response_time\")].copy()\n",
    "        if g.empty:\n",
    "            continue\n",
    "        g = g.sort_values(\"num_departures\")\n",
    "        out[seed] = g[[\"num_departures\", \"value\"]].rename(\n",
    "            columns={\"value\": \"mean_response_time\"}\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- plot: tutte le curve su un grafico (opzione smoothing con media mobile) ---\n",
    "def plot_overall_conv_by_seed(seed_to_df: Dict[int, pd.DataFrame],\n",
    "                              title=None,\n",
    "                              window_ma: int | None = None,\n",
    "                              marker_size: float = 0.2,\n",
    "                              mark_every: int | None = 2000,\n",
    "                              markers: bool = True,\n",
    "                              linewidth: float = 0.2):\n",
    "    fig, ax = plt.subplots(figsize=(8.6, 5.0))\n",
    "    for i, (seed, g) in enumerate(sorted(seed_to_df.items())):\n",
    "        color = f\"C{i % 10}\"\n",
    "        ms = marker_style_for(i, color)  # hai già definito marker_style_for\n",
    "        x = g[\"num_departures\"].to_numpy()\n",
    "        y = g[\"mean_response_time\"].to_numpy(dtype=float)\n",
    "        if window_ma and window_ma > 1:\n",
    "            y = pd.Series(y).rolling(window_ma, min_periods=1).mean().to_numpy()\n",
    "        ax.plot(x, y, linewidth=1.8, color=color, label=f\"seed {seed}\", **ms)\n",
    "    ax.set_xlabel(\"num_departures\")\n",
    "    ax.set_ylabel(\"OVERALL mean_response_time (s)\")\n",
    "    ax.set_title(title or f\"{TITLE_PREFIX} — Convergenza RT medio (per seed)\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    ax.legend(ncol=2, fontsize=9)\n",
    "    plt.show()\n",
    "\n",
    "# --- plot: una figura per seed (comodo se vuoi guardarli separati) ---\n",
    "def plot_overall_conv_one_per_seed(seed_to_df: Dict[int, pd.DataFrame], window_ma: int | None = None):\n",
    "    for i, (seed, g) in enumerate(sorted(seed_to_df.items())):\n",
    "        plot_overall_conv_by_seed({seed:g},\n",
    "                                  title=f\"{TITLE_PREFIX} — OVERALL mean RT (seed {seed})\",\n",
    "                                  window_ma=window_ma)\n",
    "\n",
    "# ====== USO ======\n",
    "\n",
    "# 1) prendi i file conv (usa la tua utility già esistente)\n",
    "conv_files = find_csv_for_config(config_file, target=\"conv\")\n",
    "print(\"File conv:\", *conv_files, sep=\"\\n - \")\n",
    "\n",
    "# 2) lista di DataFrame, uno per file\n",
    "dfs_conv = load_conv_as_list(conv_files)   # <<< LISTA richiesta\n",
    "\n",
    "# 3) dict {seed -> DF OVERALL mean RT vs num_departures}\n",
    "by_seed = overall_mean_rt_by_seed(dfs_conv, arrival_rate=1.2)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Seeds trovati:\", sorted(by_seed.keys()))\n",
    "\n",
    "# 4a) grafico unico con tutte le curve (metti window_ma=5000 se vuoi smoothing visivo)\n",
    "plot_overall_conv_by_seed(by_seed, window_ma=None)\n",
    "\n",
    "# 4b) (opzionale) un grafico per seed\n",
    "# plot_overall_conv_one_per_seed(by_seed, window_ma=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdaf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _pretty_scope(s: str) -> str:\n",
    "    s = str(s)\n",
    "    if s == \"OVERALL\":\n",
    "        return \"OVERALL\"\n",
    "    if s.startswith(\"NODE_\"):\n",
    "        return f\"Server {s.replace('NODE_', '')}\"\n",
    "    return s\n",
    "\n",
    "def _scope_order(scopes):\n",
    "    scopes = [str(s) for s in scopes]\n",
    "    over = [\"OVERALL\"] if \"OVERALL\" in scopes else []\n",
    "    nodes = sorted([s for s in scopes if s != \"OVERALL\"],\n",
    "                   key=lambda x: (not x.startswith(\"NODE_\"), x))\n",
    "    return over + nodes\n",
    "\n",
    "def _normalize_scopes(names):\n",
    "    \"\"\"Permette di passare 'A' o 'NODE_A' indistintamente.\"\"\"\n",
    "    out = []\n",
    "    for n in names:\n",
    "        s = str(n)\n",
    "        if s == \"OVERALL\":\n",
    "            out.append(\"OVERALL\")\n",
    "        elif s.startswith(\"NODE_\"):\n",
    "            out.append(s)\n",
    "        else:\n",
    "            out.append(f\"NODE_{s}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def plot_metric_vertical_by_scope(\n",
    "    df: pd.DataFrame,\n",
    "    metric: str,\n",
    "    *,\n",
    "    scopes: list[str] | None = None,    # se None: tutti\n",
    "    hue: str | None = \"seed\",\n",
    "    height: float = 2.4,\n",
    "    aspect: float = 3.2,\n",
    "    markers: bool = True,\n",
    "    linewidth: float = 1.2,\n",
    "    alpha: float = 0.95,\n",
    "    palette: str | list | None = \"tab10\",\n",
    "    xmax: float | None = None,\n",
    "    xlimit_scopes: list[str] | None = None,\n",
    "    arrival_rate: float | list[float] | tuple[float, ...] | None = None,  # << NEW\n",
    "    atol: float = 1e-9,                                                    # << NEW\n",
    "):\n",
    "    \"\"\"\n",
    "    Subplot verticale (una riga per scope) della metrica scelta.\n",
    "    Se 'arrival_rate' è impostato, filtra i dati su quel λ (o su una lista di λ).\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "\n",
    "    # --- filtro λ, se richiesto ---\n",
    "    lam_col = _lambda_col(d)\n",
    "    if arrival_rate is not None and lam_col is not None:\n",
    "        d[lam_col] = pd.to_numeric(d[lam_col], errors=\"coerce\")\n",
    "        lam = d[lam_col].to_numpy(float)\n",
    "        if np.isscalar(arrival_rate):\n",
    "            keep = np.isclose(lam, float(arrival_rate), rtol=0.0, atol=atol)\n",
    "        else:\n",
    "            arr = np.asarray(list(arrival_rate), dtype=float)\n",
    "            keep = np.any(np.isclose(lam[:, None], arr[None, :], rtol=0.0, atol=atol), axis=1)\n",
    "        d = d[keep]\n",
    "\n",
    "    # --- filtro metrica ---\n",
    "    d = d[d[\"metric\"] == metric].copy()\n",
    "    if d.empty:\n",
    "        print(f\"[WARN] nessun dato per metric='{metric}' (dopo eventuale filtro λ).\")\n",
    "        return\n",
    "\n",
    "    # --- filtro scope ---\n",
    "    all_scopes = d[\"scope\"].dropna().unique().tolist()\n",
    "    row_order = _scope_order(all_scopes) if scopes is None else _scope_order(scopes)\n",
    "    d = d[d[\"scope\"].isin(row_order)]\n",
    "    if d.empty:\n",
    "        print(\"[WARN] nessun dato dopo il filtro scope.\")\n",
    "        return\n",
    "\n",
    "    # --- limite X coerente tra subplot ---\n",
    "    if xmax is None:\n",
    "        if xlimit_scopes:\n",
    "            ref_scopes = set(_normalize_scopes(xlimit_scopes))\n",
    "        else:\n",
    "            nonA = [s for s in row_order if s != \"NODE_A\"]\n",
    "            ref_scopes = set(nonA) if (\"NODE_A\" in row_order and nonA) else set(row_order)\n",
    "        xmax = float(d[d[\"scope\"].isin(ref_scopes)][\"num_departures\"].max())\n",
    "    xmin = float(d[\"num_departures\"].min())\n",
    "\n",
    "    # --- plot ---\n",
    "    sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "    use_hue = hue if (hue is not None and hue in d.columns) else None\n",
    "\n",
    "    g = sns.relplot(\n",
    "        data=d, kind=\"line\",\n",
    "        x=\"num_departures\", y=\"value\",\n",
    "        row=\"scope\", row_order=row_order,\n",
    "        hue=use_hue, palette=palette,\n",
    "        markers=markers, dashes=False,\n",
    "        linewidth=linewidth, alpha=alpha,\n",
    "        facet_kws=dict(sharex=True, sharey=False, margin_titles=False),\n",
    "        height=height, aspect=aspect,\n",
    "        estimator=None, errorbar=None, sort=True,\n",
    "    )\n",
    "\n",
    "    for ax, scope in zip(g.axes.flat, row_order):\n",
    "        ax.set_title(_pretty_scope(scope))\n",
    "        ax.set_xlabel(\"num_departures\")\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "\n",
    "    add = \"\"\n",
    "    if arrival_rate is not None:\n",
    "        add = f\" — λ={arrival_rate}\" if np.isscalar(arrival_rate) else f\" — λ∈{list(arrival_rate)}\"\n",
    "    g.figure.suptitle(f\"{TITLE_PREFIX} — Convergenza per scope — metrica: {metric}{add}\",\n",
    "                      y=1.02, fontsize=14, weight=\"bold\")\n",
    "\n",
    "    if use_hue is not None and g._legend is not None:\n",
    "        g._legend.set_title(use_hue)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f436d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _stack_conv_frames(frames: list[pd.DataFrame],\n",
    "                       seeds: list[int] | None = None) -> pd.DataFrame:\n",
    "    # includo anche la colonna di λ se esiste\n",
    "    lam_name = None\n",
    "    for df in frames:\n",
    "        if lam_name is None:\n",
    "            lam_name = _lambda_col(df)\n",
    "\n",
    "    kept_cols = [\"scope\", \"metric\", \"value\", \"num_departures\", \"seed\", \"source\"]\n",
    "    if lam_name and lam_name not in kept_cols:\n",
    "        kept_cols.append(lam_name)\n",
    "\n",
    "    buf = []\n",
    "    for i, df in enumerate(frames):\n",
    "        d = df.copy()\n",
    "        d = _coerce_numeric(d, exclude=(\"scope\", \"metric\"))\n",
    "        if \"seed\" not in d.columns or d[\"seed\"].isna().all():\n",
    "            cand = None\n",
    "            if \"source\" in d.columns and isinstance(d[\"source\"].iloc[0], str):\n",
    "                cand = _seed_from_name(d[\"source\"].iloc[0])\n",
    "            d[\"seed\"] = cand if cand is not None else i\n",
    "        d = d[[c for c in kept_cols if c in d.columns]]\n",
    "        buf.append(d)\n",
    "\n",
    "    big = pd.concat(buf, ignore_index=True)\n",
    "    if seeds is not None:\n",
    "        big = big[big[\"seed\"].isin(seeds)]\n",
    "    return big\n",
    "\n",
    "def plot_metric_vertical_by_scope_from_list(\n",
    "    dfs: List[pd.DataFrame],\n",
    "    metric: str,\n",
    "    *,\n",
    "    scopes: list[str] | None = None,\n",
    "    seeds: list[int] | None = None,\n",
    "    hue: str | None = \"seed\",\n",
    "    height: float = 2.4,\n",
    "    aspect: float = 3.2,\n",
    "    markers: bool = True,\n",
    "    linewidth: float = 1.2,\n",
    "    alpha: float = 0.95,\n",
    "    palette: str | list | None = \"tab10\",\n",
    "    xmax: float | None = None,\n",
    "    xlimit_scopes: list[str] | None = None,\n",
    "    arrival_rate: float | list[float] | tuple[float, ...] | None = None,  # << NEW\n",
    "    atol: float = 1e-9,                                                    # << NEW\n",
    "):\n",
    "    \"\"\"Versione che accetta una LISTA di DF (uno per seed/file).\"\"\"\n",
    "    d = _stack_conv_frames(dfs, seeds=seeds)\n",
    "    return plot_metric_vertical_by_scope(\n",
    "        d, metric,\n",
    "        scopes=scopes,\n",
    "        hue=hue,\n",
    "        height=height,\n",
    "        aspect=aspect,\n",
    "        markers=markers,\n",
    "        linewidth=linewidth,\n",
    "        alpha=alpha,\n",
    "        palette=palette,\n",
    "        xmax=xmax,\n",
    "        xlimit_scopes=xlimit_scopes,\n",
    "        arrival_rate=arrival_rate,   # pass-through\n",
    "        atol=atol,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2) li carico come LISTA di DF (uno per file/seed)\n",
    "dfs_conv = load_conv_as_list(conv_files)\n",
    "\"\"\"\n",
    "plot_metric_vertical_by_scope_from_list(\n",
    "    dfs_conv, \"mean_response_time\",\n",
    "    xlimit_scopes=[\"OVERALL\", \"B\", \"P\"]   # 'B' == 'NODE_B', normalizzato\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 1) λ singolo\n",
    "plot_metric_vertical_by_scope_from_list(\n",
    "    dfs_conv, \"mean_response_time\",\n",
    "    arrival_rate=1.2,\n",
    "    xlimit_scopes=[\"OVERALL\",\"A\",\"B\",\"P\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Utilizzazione (simulata vs analitica da CSV)\n",
    "# Richiede: \n",
    "#   - df_all  già caricato (load_runs(files))\n",
    "#   - analytic_df già caricato (tutto l'analitico dal CSV)\n",
    "# ===========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- check precondizioni\n",
    "if \"df_all\" not in globals():\n",
    "    raise RuntimeError(\"df_all deve essere già definito (usa le tue find_csv_for_config/load_runs).\")\n",
    "if \"analytic_df\" not in globals():\n",
    "    raise RuntimeError(\"analytic_df deve essere già definito (usa load_analytic_models_for_config o read_csv).\")\n",
    "\n",
    "# Normalizza scope\n",
    "dfu = df_all.copy()\n",
    "dfu[\"scope\"] = dfu[\"scope\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Media per (scope, λ) in caso di repliche multiple\n",
    "agg = (\n",
    "    dfu.groupby([\"scope\", \"arrival_rate\"], as_index=False)\n",
    "       .agg({\"utilization\": \"mean\", \"throughput\": \"mean\"})\n",
    ")\n",
    "\n",
    "# Nodi presenti nei dati (tutto ciò che non è OVERALL)\n",
    "nodes = sorted([s for s in agg[\"scope\"].unique() if s != \"OVERALL\"])\n",
    "if not nodes:\n",
    "    nodes = [\"NODE_A\", \"NODE_B\", \"NODE_P\"]  # fallback per layout\n",
    "\n",
    "# --- prepara analitico: colonne canonicali\n",
    "amodel = analytic_df.copy()\n",
    "if \"lambda\" in amodel.columns and \"arrival_rate\" not in amodel.columns:\n",
    "    amodel = amodel.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "# OVERALL dal CSV: usa 'utilization' se presente, altrimenti 'system_busy_prob'\n",
    "overall_anal_col = \"utilization\" if \"utilization\" in amodel.columns else \\\n",
    "                   (\"system_busy_prob\" if \"system_busy_prob\" in amodel.columns else None)\n",
    "if overall_anal_col is None:\n",
    "    raise ValueError(\"Nel CSV analitico mi aspetto 'utilization' o 'system_busy_prob' per l'OVERALL.\")\n",
    "\n",
    "# Allinea al dominio di λ comune (evita extrapolazioni)\n",
    "lam_sim_overall = agg.loc[agg[\"scope\"] == \"OVERALL\", \"arrival_rate\"].unique()\n",
    "lam_analytical  = amodel[\"arrival_rate\"].unique()\n",
    "lam_common = np.intersect1d(lam_sim_overall, lam_analytical)\n",
    "\n",
    "# Filtra simulazione e analitico alle λ comuni\n",
    "agg_common = agg[agg[\"arrival_rate\"].isin(lam_common)].copy()\n",
    "amodel_common = amodel[amodel[\"arrival_rate\"].isin(lam_common)].copy().sort_values(\"arrival_rate\")\n",
    "\n",
    "# ======================\n",
    "# 1) OVERALL: plot\n",
    "# ======================\n",
    "overall_sim = (\n",
    "    agg_common[agg_common[\"scope\"] == \"OVERALL\"]\n",
    "    .sort_values(\"arrival_rate\")[[\"arrival_rate\", \"utilization\"]]\n",
    "    .rename(columns={\"utilization\": \"util_sim\"})\n",
    ")\n",
    "\n",
    "overall_th = amodel_common[[\"arrival_rate\", overall_anal_col]].rename(\n",
    "    columns={overall_anal_col: \"util_th\"}\n",
    ")\n",
    "\n",
    "df_over_plot = overall_sim.merge(overall_th, on=\"arrival_rate\", how=\"inner\")\n",
    "\n",
    "plt.figure(figsize=(8.2, 5.0))\n",
    "plt.plot(df_over_plot[\"arrival_rate\"], df_over_plot[\"util_sim\"], \"o-\", label=\"Simulated (OVERALL)\")\n",
    "plt.plot(df_over_plot[\"arrival_rate\"], df_over_plot[\"util_th\"],  \"s--\", label=\"Analytical (OVERALL)\")\n",
    "plt.xlabel(\"Arrival rate λ\"); plt.ylabel(\"Utilization\")\n",
    "plt.title(\"OVERALL — Utilization: simulated vs analytical\")\n",
    "plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# ======================\n",
    "# 2) Per-nodo: plot\n",
    "# ======================\n",
    "# Mappa i nomi dei nodi: \"NODE_A\" -> colonna analitica \"util_A\"\n",
    "def _node_key(scope_name: str) -> str:\n",
    "    return scope_name.replace(\"NODE_\", \"\").strip()\n",
    "\n",
    "for scope in nodes:\n",
    "    node_key = _node_key(scope)\n",
    "    anal_col = f\"util_{node_key}\"\n",
    "    if anal_col not in amodel_common.columns:\n",
    "        # se manca nel CSV, salta il nodo con un avviso soft\n",
    "        print(f\"[WARN] Colonna analitica '{anal_col}' non trovata. Salto {scope}.\")\n",
    "        continue\n",
    "\n",
    "    sim_n = (\n",
    "        agg_common[agg_common[\"scope\"] == scope]\n",
    "        .sort_values(\"arrival_rate\")[[\"arrival_rate\", \"utilization\"]]\n",
    "        .rename(columns={\"utilization\": \"util_sim\"})\n",
    "    )\n",
    "    th_n = amodel_common[[\"arrival_rate\", anal_col]].rename(columns={anal_col: \"util_th\"})\n",
    "    df_n = sim_n.merge(th_n, on=\"arrival_rate\", how=\"inner\")\n",
    "\n",
    "    plt.figure(figsize=(8.2, 5.0))\n",
    "    plt.plot(df_n[\"arrival_rate\"], df_n[\"util_sim\"], \"o-\", label=f\"Simulated ({scope})\")\n",
    "    plt.plot(df_n[\"arrival_rate\"], df_n[\"util_th\"],  \"s--\", label=f\"Analytical ({scope})\")\n",
    "    plt.xlabel(\"Arrival rate λ\"); plt.ylabel(\"Utilization\")\n",
    "    plt.title(f\"{scope} — Utilization: simulated vs analytical\")\n",
    "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add81e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== helper comuni =====\n",
    "\n",
    "def _metric_ci(df_scope: pd.DataFrame, value_col: str, *, conf: float, ci_design_effect: float) -> pd.DataFrame:\n",
    "    \"\"\"CI tra repliche per una metrica generica (value_col), fallback conservativo se 1 replica.\"\"\"\n",
    "    z = _z_value(conf)\n",
    "    g = (df_scope.groupby(\"arrival_rate\")\n",
    "                 .agg(mean=(value_col,\"mean\"),\n",
    "                      std =(value_col,\"std\"),\n",
    "                      R   =(\"replica\",\"nunique\"))\n",
    "                 .reset_index()\n",
    "                 .sort_values(\"arrival_rate\"))\n",
    "    g[\"R\"] = g[\"R\"].fillna(1).astype(int)\n",
    "    half = z * g[\"std\"].to_numpy(float)\n",
    "    mask = g[\"R\"].to_numpy(int) > 1\n",
    "    half[mask]  = half[mask]  / np.sqrt(g.loc[mask, \"R\"].to_numpy(float))\n",
    "    half[~mask] = half[~mask] * np.sqrt(float(ci_design_effect))\n",
    "    g[\"half\"] = np.nan_to_num(half, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return g.rename(columns={\"arrival_rate\":\"x\"})\n",
    "\n",
    "def _shared_ylim_from_panels(series_list, pad_frac=0.05, clamp=None):\n",
    "    \"\"\"series_list = lista di array 1D con tutte le y da considerare (sim mean±half, analitico, …)\"\"\"\n",
    "    ys = np.concatenate([np.asarray(s, float).ravel() for s in series_list if s is not None])\n",
    "    ys = ys[np.isfinite(ys)]\n",
    "    if ys.size == 0:\n",
    "        return None\n",
    "    ymin, ymax = float(np.min(ys)), float(np.max(ys))\n",
    "    if clamp is not None:\n",
    "        ymin = max(clamp[0], ymin)\n",
    "        ymax = min(clamp[1], ymax)\n",
    "    if ymax <= ymin:\n",
    "        ymax = ymin + (abs(ymin) + 1e-6)\n",
    "    pad = (ymax - ymin) * pad_frac\n",
    "    return (ymin - pad, ymax + pad)\n",
    "\n",
    "def _find_analytic_col(df: pd.DataFrame, overall_aliases, node_alias_fmt_list, node_name):\n",
    "    \"\"\"Trova la colonna analitica per overall o per nodo.\"\"\"\n",
    "    if node_name is None:\n",
    "        for c in overall_aliases:\n",
    "            if c in df.columns: return c\n",
    "        return None\n",
    "    key = node_name.replace(\"NODE_\", \"\").replace(\"node_\", \"\")\n",
    "    candidates = [fmt.format(key) for fmt in node_alias_fmt_list]\n",
    "    for c in candidates:\n",
    "        if c in df.columns: return c\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d67859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_utilization_banded_csv(df_all: pd.DataFrame,\n",
    "                                analytic_df: pd.DataFrame,\n",
    "                                *,\n",
    "                                conf: float = 0.95,\n",
    "                                ci_design_effect: float = 12.0,\n",
    "                                ci_fill: bool = True,\n",
    "                                min_display_half: float = 0.0,\n",
    "                                node_order: list[str] | None = None,\n",
    "                                cols: int = 2,\n",
    "                                figsize=(12, 9),\n",
    "                                savepath: str | None = None,\n",
    "                                title: str = \"Confidence interval for utilization (sim vs analytical)\",\n",
    "                                y_range: str | tuple[float,float] = \"util\"):\n",
    "    if df_all is None or df_all.empty:\n",
    "        raise ValueError(\"df_all è vuoto o mancante.\")\n",
    "    if analytic_df is None or analytic_df.empty:\n",
    "        raise ValueError(\"analytic_df è vuoto o mancante.\")\n",
    "\n",
    "    dfu = df_all.copy()\n",
    "    dfu[\"scope\"] = dfu[\"scope\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    nodes = sorted([s for s in dfu[\"scope\"].unique() if s != \"OVERALL\"])\n",
    "    if node_order:\n",
    "        nodes = [n for n in node_order if n in nodes] + [n for n in nodes if n not in (node_order or [])]\n",
    "\n",
    "    # CI simulazione\n",
    "    ci_over  = _metric_ci(dfu[dfu[\"scope\"]==\"OVERALL\"], \"utilization\", conf=conf, ci_design_effect=ci_design_effect)\n",
    "    ci_nodes = {n: _metric_ci(dfu[dfu[\"scope\"]==n], \"utilization\", conf=conf, ci_design_effect=ci_design_effect) for n in nodes}\n",
    "\n",
    "    # modello analitico\n",
    "    amodel = analytic_df.copy()\n",
    "    if \"lambda\" in amodel.columns and \"arrival_rate\" not in amodel.columns:\n",
    "        amodel = amodel.rename(columns={\"lambda\":\"arrival_rate\"})\n",
    "    amodel = amodel.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "\n",
    "    over_col = _find_analytic_col(amodel,\n",
    "                                  overall_aliases=[\"utilization\",\"system_busy_prob\"],\n",
    "                                  node_alias_fmt_list=[], node_name=None)\n",
    "    if over_col is None:\n",
    "        raise ValueError(\"Nel CSV analitico serve 'utilization' o 'system_busy_prob' per OVERALL.\")\n",
    "\n",
    "    # usa solo λ comuni\n",
    "    lam_common = np.intersect1d(np.sort(ci_over[\"x\"]), np.sort(amodel[\"arrival_rate\"]))\n",
    "    amodel = amodel[amodel[\"arrival_rate\"].isin(lam_common)].copy()\n",
    "    ci_over  = ci_over [ci_over [\"x\"].isin(lam_common)].copy()\n",
    "    for n in list(ci_nodes.keys()):\n",
    "        ci_nodes[n] = ci_nodes[n][ci_nodes[n][\"x\"].isin(lam_common)].copy()\n",
    "\n",
    "    # layout\n",
    "    import math as _m\n",
    "    n_panels = 1 + len(nodes)\n",
    "    rows = _m.ceil(n_panels / max(1, cols))\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize, sharex=True)\n",
    "    axs = axs.flatten() if isinstance(axs, np.ndarray) else [axs]\n",
    "    fig.suptitle(title, y=0.98)\n",
    "\n",
    "    col_sim = _pal(\"SIM\", \"#1f77b4\")\n",
    "    col_the = _pal(\"THEORY\", \"#ff7f0e\")\n",
    "\n",
    "    # --- preparazione per Y condiviso\n",
    "    all_y = []\n",
    "    # overall sim\n",
    "    all_y += [ci_over[\"mean\"] - ci_over[\"half\"], ci_over[\"mean\"] + ci_over[\"half\"]]\n",
    "    # overall analytic\n",
    "    all_y += [amodel[over_col]]\n",
    "    # nodes\n",
    "    for n in nodes:\n",
    "        d = ci_nodes[n]\n",
    "        all_y += [d[\"mean\"] - d[\"half\"], d[\"mean\"] + d[\"half\"]]\n",
    "        anal_col = _find_analytic_col(amodel,\n",
    "                                      overall_aliases=[],\n",
    "                                      node_alias_fmt_list=[f\"util_{{}}\", f\"UTIL_{{}}\"],\n",
    "                                      node_name=n)\n",
    "        if anal_col is not None:\n",
    "            all_y += [amodel[anal_col]]\n",
    "\n",
    "    clamp = (0.0, 1.0) if y_range == \"util\" else None\n",
    "    shared_ylim = _shared_ylim_from_panels(all_y, pad_frac=0.06, clamp=clamp) if y_range in (\"shared_auto\",\"util\") else (y_range if isinstance(y_range, tuple) else None)\n",
    "\n",
    "    # --- OVERALL\n",
    "    ax = axs[0]\n",
    "    _draw_ci_banded(ax, x=ci_over[\"x\"], mean=ci_over[\"mean\"], half=ci_over[\"half\"],\n",
    "                    color=col_sim, label_line=\"simulation (mean)\",\n",
    "                    label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "                    min_display_half=min_display_half, ci_fill=ci_fill)\n",
    "    ax.plot(amodel[\"arrival_rate\"], amodel[over_col],\n",
    "            color=col_the, linewidth=2.2, linestyle=\"--\", marker=\"s\", markersize=4,\n",
    "            label=\"analytical model\", zorder=6)\n",
    "    ax.set_title(\"SYSTEM utilization\")\n",
    "    ax.set_xlabel(\"Lambda\"); ax.set_ylabel(\"Utilization\"); ax.legend()\n",
    "\n",
    "    # --- NODI\n",
    "    for i, n in enumerate(nodes, start=1):\n",
    "        ax = axs[i]\n",
    "        d  = ci_nodes[n]\n",
    "        _draw_ci_banded(ax, x=d[\"x\"], mean=d[\"mean\"], half=d[\"half\"],\n",
    "                        color=col_sim, label_line=\"simulation (mean)\",\n",
    "                        label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "                        min_display_half=min_display_half, ci_fill=ci_fill)\n",
    "\n",
    "        anal_col = _find_analytic_col(amodel,\n",
    "                                      overall_aliases=[],\n",
    "                                      node_alias_fmt_list=[f\"util_{{}}\", f\"UTIL_{{}}\"],\n",
    "                                      node_name=n)\n",
    "        if anal_col is not None:\n",
    "            ax.plot(amodel[\"arrival_rate\"], amodel[anal_col],\n",
    "                    color=col_the, linewidth=2.2, linestyle=\"--\", marker=\"s\", markersize=4,\n",
    "                    label=\"analytical model\", zorder=6)\n",
    "        else:\n",
    "            ax.text(0.02, 0.92, f\"[no 'util_{n[-1]}' in CSV]\", transform=ax.transAxes, fontsize=9,\n",
    "                    ha=\"left\", va=\"top\", color=\"#888\")\n",
    "\n",
    "        ax.set_title(f\"{n} utilization\")\n",
    "        ax.set_xlabel(\"Lambda\"); ax.set_ylabel(\"Utilization\")\n",
    "        ax.legend()\n",
    "\n",
    "    # assi extra off\n",
    "    for j in range(1 + len(nodes), len(axs)):\n",
    "        axs[j].set_visible(False)\n",
    "\n",
    "    # griglia + Y condiviso\n",
    "    for ax in axs:\n",
    "        if not ax.get_visible(): continue\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "        if shared_ylim is not None:\n",
    "            ax.set_ylim(*shared_ylim)\n",
    "        ax.tick_params(axis='x', which='both', labelbottom=True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, dpi=160, bbox_inches=\"tight\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utilization_banded_csv(df_all, analytic_df, y_range=\"util\", cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_throughput_banded_csv(df_all: pd.DataFrame,\n",
    "                               analytic_df: pd.DataFrame,\n",
    "                               *,\n",
    "                               conf: float = 0.95,\n",
    "                               ci_design_effect: float = 12.0,\n",
    "                               ci_fill: bool = True,\n",
    "                               min_display_half: float = 0.0,\n",
    "                               node_order: list[str] | None = None,\n",
    "                               cols: int = 2,\n",
    "                               figsize=(12, 9),\n",
    "                               savepath: str | None = None,\n",
    "                               title: str = \"Confidence interval for throughput (sim vs analytical)\",\n",
    "                               y_range: str | tuple[float,float] = \"shared_auto\"):\n",
    "    if df_all is None or df_all.empty:\n",
    "        raise ValueError(\"df_all è vuoto o mancante.\")\n",
    "    if analytic_df is None or analytic_df.empty:\n",
    "        raise ValueError(\"analytic_df è vuoto o mancante.\")\n",
    "\n",
    "    dfx = df_all.copy()\n",
    "    dfx[\"scope\"] = dfx[\"scope\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    nodes = sorted([s for s in dfx[\"scope\"].unique() if s != \"OVERALL\"])\n",
    "    if node_order:\n",
    "        nodes = [n for n in node_order if n in nodes] + [n for n in nodes if n not in (node_order or [])]\n",
    "\n",
    "    # CI simulazione\n",
    "    ci_over  = _metric_ci(dfx[dfx[\"scope\"]==\"OVERALL\"], \"throughput\", conf=conf, ci_design_effect=ci_design_effect)\n",
    "    ci_nodes = {n: _metric_ci(dfx[dfx[\"scope\"]==n], \"throughput\", conf=conf, ci_design_effect=ci_design_effect) for n in nodes}\n",
    "\n",
    "    # analitico\n",
    "    amodel = analytic_df.copy()\n",
    "    if \"lambda\" in amodel.columns and \"arrival_rate\" not in amodel.columns:\n",
    "        amodel = amodel.rename(columns={\"lambda\":\"arrival_rate\"})\n",
    "    amodel = amodel.sort_values(\"arrival_rate\").reset_index(drop=True)\n",
    "\n",
    "    over_col = _find_analytic_col(amodel,\n",
    "                                  overall_aliases=[\"throughput\",\"X_total\",\"X\",\"overall_throughput\"],\n",
    "                                  node_alias_fmt_list=[], node_name=None)\n",
    "    if over_col is None:\n",
    "        # fallback molto comune: X_overall = arrival_rate\n",
    "        amodel[\"__overall_X_fallback__\"] = amodel[\"arrival_rate\"]\n",
    "        over_col = \"__overall_X_fallback__\"\n",
    "\n",
    "    lam_common = np.intersect1d(np.sort(ci_over[\"x\"]), np.sort(amodel[\"arrival_rate\"]))\n",
    "    amodel = amodel[amodel[\"arrival_rate\"].isin(lam_common)].copy()\n",
    "    ci_over  = ci_over [ci_over [\"x\"].isin(lam_common)].copy()\n",
    "    for n in list(ci_nodes.keys()):\n",
    "        ci_nodes[n] = ci_nodes[n][ci_nodes[n][\"x\"].isin(lam_common)].copy()\n",
    "\n",
    "    # layout\n",
    "    import math as _m\n",
    "    n_panels = 1 + len(nodes)\n",
    "    rows = _m.ceil(n_panels / max(1, cols))\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize, sharex=True)\n",
    "    axs = axs.flatten() if isinstance(axs, np.ndarray) else [axs]\n",
    "    fig.suptitle(title, y=0.98)\n",
    "\n",
    "    col_sim = _pal(\"SIM\", \"#1f77b4\")\n",
    "    col_the = _pal(\"THEORY\", \"#ff7f0e\")\n",
    "\n",
    "    # Y condiviso\n",
    "    all_y = [ci_over[\"mean\"]-ci_over[\"half\"], ci_over[\"mean\"]+ci_over[\"half\"], amodel[over_col]]\n",
    "    for n in nodes:\n",
    "        d = ci_nodes[n]\n",
    "        all_y += [d[\"mean\"]-d[\"half\"], d[\"mean\"]+d[\"half\"]]\n",
    "        anal_col = _find_analytic_col(amodel,\n",
    "                                      overall_aliases=[],\n",
    "                                      node_alias_fmt_list=[f\"throughput_{{}}\", f\"X_{{}}\"],\n",
    "                                      node_name=n)\n",
    "        if anal_col is not None:\n",
    "            all_y += [amodel[anal_col]]\n",
    "    shared_ylim = _shared_ylim_from_panels(all_y, pad_frac=0.06) if y_range == \"shared_auto\" else (y_range if isinstance(y_range, tuple) else None)\n",
    "\n",
    "    # OVERALL\n",
    "    ax = axs[0]\n",
    "    _draw_ci_banded(ax, x=ci_over[\"x\"], mean=ci_over[\"mean\"], half=ci_over[\"half\"],\n",
    "                    color=col_sim, label_line=\"simulation (mean)\",\n",
    "                    label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "                    min_display_half=min_display_half, ci_fill=ci_fill)\n",
    "    ax.plot(amodel[\"arrival_rate\"], amodel[over_col],\n",
    "            color=col_the, linewidth=2.2, linestyle=\"--\", marker=\"s\", markersize=4,\n",
    "            label=\"analytical model\", zorder=6)\n",
    "    ax.set_title(\"SYSTEM throughput\")\n",
    "    ax.set_xlabel(\"Lambda\"); ax.set_ylabel(\"Throughput\"); ax.legend()\n",
    "\n",
    "    # NODI\n",
    "    for i, n in enumerate(nodes, start=1):\n",
    "        ax = axs[i]\n",
    "        d  = ci_nodes[n]\n",
    "        _draw_ci_banded(ax, x=d[\"x\"], mean=d[\"mean\"], half=d[\"half\"],\n",
    "                        color=col_sim, label_line=\"simulation (mean)\",\n",
    "                        label_band=\"simulation CI band\", label_ci=f\"CI {int(conf*100)}%\",\n",
    "                        min_display_half=min_display_half, ci_fill=ci_fill)\n",
    "\n",
    "        anal_col = _find_analytic_col(amodel,\n",
    "                                      overall_aliases=[],\n",
    "                                      node_alias_fmt_list=[f\"throughput_{{}}\", f\"X_{{}}\"],\n",
    "                                      node_name=n)\n",
    "        if anal_col is not None:\n",
    "            ax.plot(amodel[\"arrival_rate\"], amodel[anal_col],\n",
    "                    color=col_the, linewidth=2.2, linestyle=\"--\", marker=\"s\", markersize=4,\n",
    "                    label=\"analytical model\", zorder=6)\n",
    "        \n",
    "\n",
    "        ax.set_title(f\"{n} throughput\")\n",
    "        ax.set_xlabel(\"Lambda\"); ax.set_ylabel(\"Throughput\")\n",
    "        ax.legend()\n",
    "\n",
    "    for j in range(1 + len(nodes), len(axs)):\n",
    "        axs[j].set_visible(False)\n",
    "\n",
    "    for ax in axs:\n",
    "        if not ax.get_visible(): continue\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "        if shared_ylim is not None:\n",
    "            ax.set_ylim(*shared_ylim)\n",
    "        ax.tick_params(axis='x', which='both', labelbottom=True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, dpi=160, bbox_inches=\"tight\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_throughput_banded_csv(df_all, analytic_df, y_range=\"shared_auto\", cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0730c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def _ensure_conv_df(dfs_conv) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalizza input (DataFrame, lista di DF o path CSV, dict, ecc.)\n",
    "    e restituisce un unico DF ordinato che contenga almeno:\n",
    "    scope, metric, value, num_departures (+ opzionale arrival_rate, seed).\n",
    "    \"\"\"\n",
    "    if isinstance(dfs_conv, pd.DataFrame):\n",
    "        df = dfs_conv.copy()\n",
    "    elif isinstance(dfs_conv, (list, tuple)):\n",
    "        parts = []\n",
    "        for x in dfs_conv:\n",
    "            if isinstance(x, pd.DataFrame):\n",
    "                parts.append(x)\n",
    "            elif isinstance(x, (str, Path)):\n",
    "                parts.append(pd.read_csv(x))\n",
    "            elif isinstance(x, dict):\n",
    "                parts.append(pd.DataFrame([x]))\n",
    "            else:\n",
    "                parts.append(pd.DataFrame(x))\n",
    "        if not parts:\n",
    "            raise ValueError(\"dfs_conv è una lista vuota.\")\n",
    "        df = pd.concat(parts, ignore_index=True)\n",
    "    elif isinstance(dfs_conv, dict):\n",
    "        df = pd.DataFrame([dfs_conv])\n",
    "    else:\n",
    "        df = pd.DataFrame(dfs_conv)\n",
    "\n",
    "    required = {\"scope\", \"metric\", \"value\", \"num_departures\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Mancano colonne in dfs_conv: {missing}\")\n",
    "\n",
    "    # cast numerici\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "    df[\"num_departures\"] = pd.to_numeric(df[\"num_departures\"], errors=\"coerce\")\n",
    "    if \"arrival_rate\" in df.columns:\n",
    "        df[\"arrival_rate\"] = pd.to_numeric(df[\"arrival_rate\"], errors=\"coerce\")\n",
    "\n",
    "    return df.sort_values([\"scope\", \"metric\", \"num_departures\"]).reset_index(drop=True)\n",
    "\n",
    "def transient_series_from_conv(dfs_conv,\n",
    "                               scope: str,\n",
    "                               metric: str = \"mean_population\",\n",
    "                               arrival_rate: float | None = None,\n",
    "                               downsample_every: int = 1,\n",
    "                               ewma_span: int | None = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Costruisce la serie temporale t ≈ num_departures / throughput per la metrica richiesta.\n",
    "    Ritorna colonne: ['t','value','value_smooth'] ordinate per t.\n",
    "    \"\"\"\n",
    "    df = _ensure_conv_df(dfs_conv)\n",
    "\n",
    "    # filtro per λ se presente\n",
    "    if arrival_rate is not None and \"arrival_rate\" in df.columns:\n",
    "        df = df[df[\"arrival_rate\"].eq(arrival_rate)]\n",
    "\n",
    "    df_metric = df[(df[\"scope\"].eq(scope)) & (df[\"metric\"].eq(metric))][[\"num_departures\", \"value\"]].copy()\n",
    "    if df_metric.empty:\n",
    "        return pd.DataFrame(columns=[\"t\", \"value\", \"value_smooth\"])\n",
    "\n",
    "    df_thr = df[(df[\"scope\"].eq(scope)) & (df[\"metric\"].eq(\"throughput\"))][[\"num_departures\", \"value\"]].copy()\n",
    "    df_thr = df_thr.rename(columns={\"value\": \"throughput\"}).sort_values(\"num_departures\")\n",
    "\n",
    "    # allineamento tollerante per num_departures\n",
    "    df_metric = df_metric.sort_values(\"num_departures\")\n",
    "    series = pd.merge_asof(df_metric, df_thr, on=\"num_departures\", direction=\"nearest\")\n",
    "\n",
    "    # ricostruzione tempo\n",
    "    if \"throughput\" in series.columns and series[\"throughput\"].notna().any():\n",
    "        denom = series[\"throughput\"].replace(0, np.nan)\n",
    "    elif arrival_rate is not None and arrival_rate > 0:\n",
    "        denom = float(arrival_rate)\n",
    "    else:\n",
    "        # fallback: indice come tempo relativo\n",
    "        series[\"t\"] = np.arange(len(series), dtype=float)\n",
    "        series = series.dropna(subset=[\"value\"]).sort_values(\"t\")[[\"t\", \"value\"]]\n",
    "        series[\"value_smooth\"] = (\n",
    "            series[\"value\"].ewm(span=ewma_span, adjust=False).mean()\n",
    "            if ewma_span is not None and len(series) > 3 else series[\"value\"]\n",
    "        )\n",
    "        return series\n",
    "\n",
    "    series[\"t\"] = series[\"num_departures\"] / denom\n",
    "    series = series.dropna(subset=[\"t\"]).sort_values(\"t\")[[\"t\", \"value\"]]\n",
    "\n",
    "    # downsample opzionale\n",
    "    if downsample_every > 1 and len(series) > downsample_every:\n",
    "        series = series.iloc[::downsample_every, :].reset_index(drop=True)\n",
    "\n",
    "    # smoothing per il plot\n",
    "    if ewma_span is not None and len(series) > 3:\n",
    "        series[\"value_smooth\"] = series[\"value\"].ewm(span=ewma_span, adjust=False).mean()\n",
    "    else:\n",
    "        series[\"value_smooth\"] = series[\"value\"]\n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2596957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# --- helper: prendi il primo campo disponibile tra vari alias ---\n",
    "def _find_first(row, names):\n",
    "    for n in names:\n",
    "        if n in row.index:\n",
    "            try:\n",
    "                return float(row[n])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "# --- helper: N analitica per scope (OVERALL, NODE_A/B/P) ---\n",
    "def _analytic_pop_for_scope(analytic_df: pd.DataFrame, arrival_rate: float, scope: str,\n",
    "                            visits: dict[str, float] = {\"A\": 3.0, \"B\": 1.0, \"P\": 1.0}):\n",
    "    \"\"\"\n",
    "    Cerca N analitica in analytic_df. Supporta alias multipli.\n",
    "    Fallback:\n",
    "      - OVERALL: N, oppure N = λ * T_total, altrimenti somma nodi.\n",
    "      - Nodo n∈{A,B,P}: N_n, oppure N_n = X_n*T_n, oppure N_n = λ*v_n*T_n.\n",
    "    \"\"\"\n",
    "    if analytic_df is None:\n",
    "        return None\n",
    "\n",
    "    am = analytic_df.copy()\n",
    "    if \"lambda\" in am.columns and \"arrival_rate\" not in am.columns:\n",
    "        am = am.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "    rows = am.loc[np.isclose(am[\"arrival_rate\"].astype(float).to_numpy(),\n",
    "                             float(arrival_rate), atol=1e-9)]\n",
    "    if rows.empty:\n",
    "        return None\n",
    "    row = rows.iloc[0]\n",
    "\n",
    "    if scope == \"OVERALL\":\n",
    "        val = _find_first(row, [\"mean_population\", \"N\", \"N_total\", \"mean_N\", \"mean_pop\"])\n",
    "        if val is not None:\n",
    "            return val\n",
    "        Ttot = _find_first(row, [\"T_total\", \"mean_response_time\", \"response_time\", \"rt\", \"R\", \"R_total\"])\n",
    "        if Ttot is not None:\n",
    "            return float(arrival_rate) * Ttot\n",
    "        NA = _analytic_pop_for_scope(analytic_df, arrival_rate, \"NODE_A\", visits)\n",
    "        NB = _analytic_pop_for_scope(analytic_df, arrival_rate, \"NODE_B\", visits)\n",
    "        NP = _analytic_pop_for_scope(analytic_df, arrival_rate, \"NODE_P\", visits)\n",
    "        if None not in (NA, NB, NP):\n",
    "            return NA + NB + NP\n",
    "        return None\n",
    "\n",
    "    letter = scope.split(\"_\")[-1]  # \"A\",\"B\",\"P\"\n",
    "    val = _find_first(row, [f\"mean_population_{letter}\",\n",
    "                            f\"NODE_{letter}_mean_population\",\n",
    "                            f\"N_{letter}\"])\n",
    "    if val is not None:\n",
    "        return val\n",
    "\n",
    "    Tn = _find_first(row, [f\"mean_response_time_{letter}\", f\"rt_{letter}\", f\"R_{letter}\", f\"T_{letter}\"])\n",
    "    if Tn is None:\n",
    "        return None\n",
    "    Xn = _find_first(row, [f\"throughput_{letter}\", f\"X_{letter}\"])\n",
    "    if Xn is not None:\n",
    "        return Xn * Tn\n",
    "    v = visits.get(letter, 1.0)\n",
    "    return float(arrival_rate) * v * Tn\n",
    "\n",
    "\n",
    "\n",
    "def _analytic_rt_for_scope(analytic_df: pd.DataFrame, arrival_rate: float, scope: str):\n",
    "    \"\"\"\n",
    "    Estrae il tempo di risposta analitico dal DataFrame 'analytic_df' per\n",
    "    OVERALL o per i nodi A/B/P. Usa molti alias e ha fallback ragionevoli:\n",
    "      - OVERALL: prova RT diretto; poi Little N/X; poi 3*A + B + P.\n",
    "      - Nodo: prova RT diretto; poi Little N_n/X_n; poi ricavo da T_total e gli altri nodi.\n",
    "    Ritorna float oppure None se non ricavabile.\n",
    "    \"\"\"\n",
    "    if analytic_df is None:\n",
    "        return None\n",
    "\n",
    "    am = analytic_df.copy()\n",
    "    if \"lambda\" in am.columns and \"arrival_rate\" not in am.columns:\n",
    "        am = am.rename(columns={\"lambda\": \"arrival_rate\"})\n",
    "    rows = am.loc[np.isclose(am[\"arrival_rate\"].astype(float).to_numpy(),\n",
    "                             float(arrival_rate), atol=1e-9)]\n",
    "    if rows.empty:\n",
    "        return None\n",
    "    row = rows.iloc[0]\n",
    "\n",
    "    # ---- OVERALL\n",
    "    if scope == \"OVERALL\":\n",
    "        # diretto\n",
    "        val = _find_first(row, [\"mean_response_time\", \"response_time\", \"rt\", \"T_total\"])\n",
    "        if val is not None:\n",
    "            return val\n",
    "        # Little: RT = N / X\n",
    "        N = _find_first(row, [\"mean_population\", \"N\", \"N_total\", \"mean_N\", \"mean_pop\"])\n",
    "        X = _find_first(row, [\"throughput\", \"X\", \"X_total\"])\n",
    "        if N is not None and X is not None and X > 0:\n",
    "            return N / X\n",
    "        # combinazione dei nodi: T_total = 3*A + B + P\n",
    "        RA = _find_first(row, [\"mean_response_time_A\", \"rt_A\", \"R_A\", \"T_A\"])\n",
    "        RB = _find_first(row, [\"mean_response_time_B\", \"rt_B\", \"R_B\", \"T_B\"])\n",
    "        RP = _find_first(row, [\"mean_response_time_P\", \"rt_P\", \"R_P\", \"T_P\"])\n",
    "        if None not in (RA, RB, RP):\n",
    "            return 3.0 * RA + RB + RP\n",
    "        return None\n",
    "\n",
    "    # ---- Nodo (A/B/P)\n",
    "    letter = scope.split(\"_\")[-1]  # \"A\",\"B\",\"P\"\n",
    "    val = _find_first(row, [f\"mean_response_time_{letter}\",\n",
    "                            f\"NODE_{letter}_mean_response_time\",\n",
    "                            f\"rt_{letter}\", f\"R_{letter}\", f\"T_{letter}\"])\n",
    "    if val is not None:\n",
    "        return val\n",
    "\n",
    "    # Little a nodo: RT_n = N_n / X_n\n",
    "    Nn = _find_first(row, [f\"mean_population_{letter}\", f\"N_{letter}\"])\n",
    "    Xn = _find_first(row, [f\"throughput_{letter}\", f\"X_{letter}\"])\n",
    "    if Nn is not None and Xn is not None and Xn > 0:\n",
    "        return Nn / Xn\n",
    "\n",
    "    # Ricavo da totale e altri due\n",
    "    Ttot = _find_first(row, [\"T_total\", \"mean_response_time\", \"response_time\", \"rt\"])\n",
    "    RA = _find_first(row, [\"mean_response_time_A\", \"rt_A\", \"R_A\", \"T_A\"])\n",
    "    RB = _find_first(row, [\"mean_response_time_B\", \"rt_B\", \"R_B\", \"T_B\"])\n",
    "    RP = _find_first(row, [\"mean_response_time_P\", \"rt_P\", \"R_P\", \"T_P\"])\n",
    "    if Ttot is not None:\n",
    "        if letter == \"A\" and RB is not None and RP is not None:\n",
    "            return (Ttot - RB - RP) / 3.0\n",
    "        if letter == \"B\" and RA is not None and RP is not None:\n",
    "            return Ttot - 3.0 * RA - RP\n",
    "        if letter == \"P\" and RA is not None and RB is not None:\n",
    "            return Ttot - 3.0 * RA - RB\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transient_population_over_seeds(\n",
    "    dfs_conv_list,\n",
    "    scopes=(\"OVERALL\", \"NODE_A\", \"NODE_B\", \"NODE_P\"),\n",
    "    *,\n",
    "    arrival_rate: float,\n",
    "    ewma_span: int | None = 25,\n",
    "    npoints: int = 400,\n",
    "    conf: float = 0.95,\n",
    "    title_prefix=\"Transient (mean over seeds) — mean_population\",\n",
    "    analytic_df: pd.DataFrame | None = None,\n",
    "    tail_frac_for_value: float = 0.2,\n",
    "    visits: dict[str, float] = {\"A\": 3.0, \"B\": 1.0, \"P\": 1.0},\n",
    "):\n",
    "    # griglia tempo comune da OVERALL\n",
    "    series_list = []\n",
    "    for df in dfs_conv_list:\n",
    "        s = transient_series_from_conv(df, \"OVERALL\",\n",
    "                                       metric=\"mean_population\",\n",
    "                                       arrival_rate=arrival_rate,\n",
    "                                       downsample_every=5, ewma_span=ewma_span)\n",
    "        if not s.empty:\n",
    "            series_list.append(s)\n",
    "    if not series_list:\n",
    "        raise RuntimeError(\"Nessuna serie disponibile.\")\n",
    "    t_min = max(s[\"t\"].min() for s in series_list)\n",
    "    t_max = min(s[\"t\"].max() for s in series_list)\n",
    "    grid_t = np.linspace(t_min, t_max, npoints)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 7), squeeze=False)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for ax, scope in zip(axes, scopes):\n",
    "        curves = []\n",
    "        for df in dfs_conv_list:\n",
    "            s = transient_series_from_conv(df, scope,\n",
    "                                           metric=\"mean_population\",\n",
    "                                           arrival_rate=arrival_rate,\n",
    "                                           downsample_every=5, ewma_span=ewma_span)\n",
    "            if s.empty:\n",
    "                continue\n",
    "            curves.append(np.interp(grid_t, s[\"t\"], s[\"value_smooth\"]))\n",
    "        if not curves:\n",
    "            ax.set_title(f\"{scope}: nessun dato\"); ax.axis(\"off\"); continue\n",
    "\n",
    "        Y = np.vstack(curves)\n",
    "        mu = Y.mean(axis=0)\n",
    "        se = Y.std(axis=0, ddof=1) / np.sqrt(Y.shape[0])\n",
    "        z = stats.t.ppf(0.5 + conf/2.0, df=Y.shape[0]-1)\n",
    "        half = z * se\n",
    "\n",
    "        # media + banda (stile tuo)\n",
    "        ax.plot(grid_t, mu, color=\"tab:blue\", linewidth=2, label=\"mean over seeds (EWMA)\")\n",
    "        ax.fill_between(grid_t, mu-half, mu+half, color=\"tab:blue\", alpha=0.20,\n",
    "                        label=f\"CI {int(conf*100)}% (between seeds)\")\n",
    "\n",
    "        # valore di convergenza (verde)\n",
    "        k0 = max(1, int((1.0 - tail_frac_for_value) * len(mu)))\n",
    "        tail_mean = float(np.nanmean(mu[k0:])) if len(mu) - k0 >= 3 else float(np.nanmean(mu))\n",
    "        ax.axhline(tail_mean, linestyle=\"--\", color=\"tab:green\", linewidth=1.8,\n",
    "                   label=f\"converged ≈ {tail_mean:.3f}\")\n",
    "\n",
    "        # --- linea analitica anche per i nodi (arancione tratteggiata) ---\n",
    "        theor = _analytic_pop_for_scope(analytic_df, arrival_rate, scope, visits) if analytic_df is not None else None\n",
    "        if theor is not None:\n",
    "            if scope == \"OVERALL\":\n",
    "                lbl = f\"analytical (λ={arrival_rate}, N={theor:.3f})\"\n",
    "            else:\n",
    "                letter = scope.split(\"_\")[-1]\n",
    "                lbl = f\"analytical (N_{letter}={theor:.3f})\"\n",
    "            ax.axhline(theor, linestyle=\"--\", color=\"tab:orange\", linewidth=2, label=lbl)\n",
    "\n",
    "        ax.set_title(f\"{scope} — mean over seeds\")\n",
    "        ax.set_xlabel(\"Tempo simulazione (s)\")\n",
    "        ax.set_ylabel(\"Mean population\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "\n",
    "    fig.suptitle(f\"{title_prefix} (λ={arrival_rate})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transient_population_over_seeds(\n",
    "    dfs_conv_list=dfs_conv,       # lista dei conv_* per i vari seed\n",
    "    arrival_rate=1.4,\n",
    "    analytic_df=analytic_df,      # CSV analitico\n",
    "    ewma_span=25,\n",
    "    npoints=400,\n",
    "    conf=0.95,\n",
    "    tail_frac_for_value=0.2,      # media dell’ultimo 20% per la “convergenza”\n",
    "    visits={\"A\":3, \"B\":1, \"P\":1}  # se nel CSV non c’è N_A/B/P, li ricavo da λ·visits·T_n\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c61cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_transient_response_time_over_seeds(\n",
    "    dfs_conv_list,\n",
    "    scopes=(\"OVERALL\", \"NODE_A\", \"NODE_B\", \"NODE_P\"),\n",
    "    *,\n",
    "    arrival_rate: float,                 # solo per filtrare i DF\n",
    "    downsample_every: int = 5,\n",
    "    ewma_span: int | None = 25,\n",
    "    conf: float = 0.95,\n",
    "    grid_mode: str = \"intersection\",     # \"intersection\" | \"union\"\n",
    "    npoints: int = 400,                  # usato se grid_mode=\"intersection\"\n",
    "    title_prefix: str = \"Transient (mean over seeds) — mean_response_time\",\n",
    "    analytic_df: pd.DataFrame | None = None,\n",
    "    tail_frac_for_value: float = 0.2     # percentuale coda per stimare \"converged\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Stesso look&feel dei tuoi grafici:\n",
    "    - curva blu = media tra seed (EWMA)\n",
    "    - banda blu chiara = CI tra seed\n",
    "    - linea verde tratteggiata = converged ≈ (media coda)\n",
    "    - linea arancione tratteggiata = valore analitico (anche per i nodi)\n",
    "    Richiede la tua `transient_series_from_conv`.\n",
    "    \"\"\"\n",
    "    # --- griglia tempo comune ricavata da OVERALL ---\n",
    "    series_overall = []\n",
    "    for df in dfs_conv_list:\n",
    "        s = transient_series_from_conv(\n",
    "            df, \"OVERALL\",\n",
    "            metric=\"mean_response_time\",\n",
    "            arrival_rate=arrival_rate,\n",
    "            downsample_every=downsample_every,\n",
    "            ewma_span=ewma_span\n",
    "        )\n",
    "        if not s.empty:\n",
    "            series_overall.append(s)\n",
    "\n",
    "    if not series_overall:\n",
    "        raise RuntimeError(f\"Nessuna serie OVERALL disponibile a λ={arrival_rate}.\")\n",
    "\n",
    "    if grid_mode == \"union\":\n",
    "        grid_t = np.unique(np.concatenate([s[\"t\"].to_numpy() for s in series_overall]))\n",
    "    else:\n",
    "        t_min = max(s[\"t\"].min() for s in series_overall)\n",
    "        t_max = min(s[\"t\"].max() for s in series_overall)\n",
    "        grid_t = np.linspace(t_min, t_max, npoints)\n",
    "\n",
    "    # --- figure & axes (stile tuo) ---\n",
    "    nplots = len(scopes)\n",
    "    nrows = 2 if nplots > 1 else 1\n",
    "    ncols = int(np.ceil(nplots / nrows))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(12, 7), squeeze=False)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for ax, scope in zip(axes, scopes):\n",
    "        curves = []\n",
    "        for df in dfs_conv_list:\n",
    "            s = transient_series_from_conv(\n",
    "                df, scope,\n",
    "                metric=\"mean_response_time\",\n",
    "                arrival_rate=arrival_rate,\n",
    "                downsample_every=downsample_every,\n",
    "                ewma_span=ewma_span\n",
    "            )\n",
    "            if s.empty:\n",
    "                continue\n",
    "            y = np.interp(grid_t, s[\"t\"], s[\"value_smooth\"])\n",
    "            curves.append(y)\n",
    "\n",
    "        if not curves:\n",
    "            ax.set_title(f\"{scope}: nessun dato\"); ax.axis(\"off\"); continue\n",
    "\n",
    "        Y = np.vstack(curves)  # (n_seed, n_points)\n",
    "        mu = np.nanmean(Y, axis=0)\n",
    "        se = np.nanstd(Y, axis=0, ddof=1) / np.sqrt(Y.shape[0])\n",
    "        z  = stats.t.ppf(0.5 + conf/2.0, df=max(1, Y.shape[0]-1))\n",
    "        half = z * se\n",
    "\n",
    "        # --- stile tuo: blu + banda blu chiara ---\n",
    "        ax.plot(grid_t, mu, color=\"tab:blue\", linewidth=2, label=\"mean over seeds (EWMA)\")\n",
    "        ax.fill_between(grid_t, mu-half, mu+half, color=\"tab:blue\", alpha=0.20,\n",
    "                        label=f\"CI {int(conf*100)}% (between seeds)\")\n",
    "\n",
    "        # --- valore di convergenza (media coda) in verde ---\n",
    "        k0 = max(1, int((1.0 - tail_frac_for_value) * len(mu)))\n",
    "        tail_mean = float(np.nanmean(mu[k0:])) if len(mu) - k0 >= 3 else float(np.nanmean(mu))\n",
    "        ax.axhline(tail_mean, linestyle=\"--\", color=\"tab:green\", linewidth=1.8,\n",
    "                   label=f\"converged ≈ {tail_mean:.3f}s\")\n",
    "\n",
    "        # --- baseline analitica anche per i nodi (arancione) ---\n",
    "        theor = _analytic_rt_for_scope(analytic_df, arrival_rate, scope) if analytic_df is not None else None\n",
    "        if theor is not None:\n",
    "            if scope == \"OVERALL\":\n",
    "                lbl = f\"analytical (λ={arrival_rate}, RT={theor:.3f}s)\"\n",
    "            else:\n",
    "                letter = scope.split(\"_\")[-1]\n",
    "                lbl = f\"analytical (RT_{letter}={theor:.3f}s)\"\n",
    "            ax.axhline(theor, linestyle=\"--\", color=\"tab:orange\", linewidth=2, label=lbl)\n",
    "\n",
    "        ax.set_title(f\"{scope} — mean over seeds\")\n",
    "        ax.set_xlabel(\"Tempo simulazione (s)\")\n",
    "        ax.set_ylabel(\"Mean response time (s)\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "\n",
    "    fig.suptitle(f\"{title_prefix} (λ={arrival_rate})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transient_response_time_over_seeds(\n",
    "    dfs_conv_list=dfs_conv,   # lista dei conv_* (uno per seed)\n",
    "    arrival_rate=1.4,\n",
    "    analytic_df=analytic_df,  # per la linea teorica su OVERALL\n",
    "    ewma_span=25,\n",
    "    downsample_every=5,\n",
    "    conf=0.95,\n",
    "    grid_mode=\"intersection\"  # oppure \"union\" se vuoi includere tutte le code\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- serie (usa la tua colonna 'time') ----------\n",
    "def _series_rt_from_conv(df, scope, *, arrival_rate=None, t_max=None, downsample_every=1, ewma_span=7, align_zero=True):\n",
    "    dd = df[(df[\"scope\"]==scope) & (df[\"metric\"]==\"mean_response_time\")].copy()\n",
    "    if arrival_rate is not None and \"arrival_rate\" in dd.columns:\n",
    "        dd = dd[dd[\"arrival_rate\"].astype(float).eq(float(arrival_rate))]\n",
    "    if dd.empty:\n",
    "        return None, None\n",
    "\n",
    "    dd = dd.sort_values(\"time\")\n",
    "    t = dd[\"time\"].astype(float).to_numpy()\n",
    "    y = dd[\"value\"].astype(float).to_numpy()\n",
    "\n",
    "    if align_zero:\n",
    "        t = t - t.min()\n",
    "\n",
    "    if t_max is not None:\n",
    "        ok = t <= float(t_max)\n",
    "        t, y = t[ok], y[ok]\n",
    "\n",
    "    if downsample_every > 1 and len(y) > downsample_every:\n",
    "        t = t[::downsample_every]; y = y[::downsample_every]\n",
    "\n",
    "    if ewma_span and len(y) > 3:\n",
    "        y = pd.Series(y).ewm(span=ewma_span, adjust=False).mean().to_numpy()\n",
    "\n",
    "    return t, y\n",
    "\n",
    "# ---------- plot in stile \"paper\" ----------\n",
    "def plot_transient_rt_paper_style(\n",
    "    dfs_conv_list,                      # lista di DataFrame conv (uno per seed)\n",
    "    *,\n",
    "    arrival_rate: float,\n",
    "    scopes=(\"NODE_A\",\"NODE_B\",\"NODE_P\",\"OVERALL\"),\n",
    "    t_max: float = 65.0,                # finestra mostrata (s)\n",
    "    downsample_every: int = 1,          # 1 = nessun downsample\n",
    "    ewma_span: int = 7,                 # smoothing leggero\n",
    "    analytic_df: pd.DataFrame | None = None,\n",
    "    suptitle: str = \"Response time of transient state\"\n",
    "):\n",
    "    # layout 2×2\n",
    "    titles_map = {\"NODE_A\":\"A\", \"NODE_B\":\"B\", \"NODE_P\":\"P\", \"OVERALL\":\"SYSTEM\"}\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 7), squeeze=False)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for ax, scope in zip(axes, scopes):\n",
    "        plotted = False\n",
    "        for i, df in enumerate(dfs_conv_list):\n",
    "            seed_label = \"-\"\n",
    "            if \"seed\" in df.columns and not df[\"seed\"].isna().all():\n",
    "                s0 = str(df[\"seed\"].dropna().iloc[0])\n",
    "                seed_label = s0 if not s0.isdigit() else str(int(float(s0)))\n",
    "\n",
    "            t, y = _series_rt_from_conv(\n",
    "                df, scope,\n",
    "                arrival_rate=arrival_rate,\n",
    "                t_max=t_max,\n",
    "                downsample_every=downsample_every,\n",
    "                ewma_span=ewma_span,\n",
    "                align_zero=True\n",
    "            )\n",
    "            if t is None: \n",
    "                continue\n",
    "\n",
    "            markevery = max(1, len(t)//30)\n",
    "            ax.plot(t, y, linewidth=1.8, marker=\"o\", markersize=3.5, markevery=markevery,\n",
    "                    label=f\"seed = {seed_label}\")\n",
    "            plotted = True\n",
    "\n",
    "        # linea analitica (rossa tratteggiata) se disponibile\n",
    "        if analytic_df is not None:\n",
    "            theor = _analytic_rt_for_scope(analytic_df, arrival_rate, scope)\n",
    "            if theor is not None:\n",
    "                ax.axhline(theor, linestyle=\"--\", color=\"tab:red\", linewidth=2,\n",
    "                           label=(f\"analytical (λ={arrival_rate}, RT={theor:.3f})\"\n",
    "                                  if scope==\"OVERALL\" else f\"analytical (RT={theor:.3f})\"))\n",
    "\n",
    "        ax.set_title(titles_map.get(scope, scope))\n",
    "        ax.set_xlim(0, t_max)\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Mean response time (s)\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if plotted:\n",
    "            ax.legend(fontsize=9)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"nessun dato\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "    fig.suptitle(suptitle)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e93742",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transient_rt_paper_style(\n",
    "    dfs_conv_list=dfs_conv,\n",
    "    arrival_rate=1.4,\n",
    "    scopes=(\"OVERALL\", \"NODE_A\", \"NODE_P\", \"NODE_B\"),  # TL=SYSTEM, TR=A, BL=P, BR=B\n",
    "    t_max=65,\n",
    "    downsample_every=1,\n",
    "    ewma_span=7,\n",
    "    analytic_df=analytic_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c794753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_mean_rt_by_seed_single_line.py\n",
    "# Requisiti: pandas, matplotlib, numpy\n",
    "# pip install pandas matplotlib\n",
    "\n",
    "import re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\".output_simulation\")\n",
    "SMOOTH = True        # True: interpola su griglia fine; False: solo i punti unici (senza marker)\n",
    "GRID_POINTS = 200    # risoluzione della griglia per l'interpolazione\n",
    "\n",
    "files = sorted(glob.glob(str(DATA_DIR / \"*.csv\")))\n",
    "if not files:\n",
    "    raise SystemExit(f\"Nessun CSV trovato in {DATA_DIR.resolve()}\")\n",
    "\n",
    "seed_re = re.compile(r\"seed(\\d+)\")\n",
    "prob_re = re.compile(r\"prob([0-9\\.eE+-]+)\")\n",
    "\n",
    "def parse_seed_prob(fname: str):\n",
    "    s = seed_re.search(fname)\n",
    "    p = prob_re.search(fname)\n",
    "    if not (s and p):\n",
    "        raise ValueError(f\"Impossibile estrarre seed/prob da: {fname}\")\n",
    "    return int(s.group(1)), float(p.group(1))\n",
    "\n",
    "def extract_mean_rt(df: pd.DataFrame) -> float:\n",
    "    # --- 1) preferisci sempre OVERALL ---\n",
    "    if \"scope\" in df.columns:\n",
    "        over = df[df[\"scope\"].astype(str).str.upper() == \"OVERALL\"]\n",
    "        if not over.empty:\n",
    "            df = over  # usa solo le righe OVERALL\n",
    "\n",
    "    # --- 2) colonna esatta: mean_response_time ---\n",
    "    if \"mean_response_time\" in df.columns:\n",
    "        ser = pd.to_numeric(df[\"mean_response_time\"], errors=\"coerce\")\n",
    "        if ser.notna().any():\n",
    "            return float(ser.dropna().mean())\n",
    "\n",
    "    # --- 3) fallback robusti (nomi leggermente diversi) ---\n",
    "    cols  = list(df.columns)\n",
    "    lcols = [str(c).lower().strip() for c in cols]\n",
    "    preferiti = [\n",
    "        r\"^mean[_ ]response[_ ]time$\",\n",
    "        r\"^avg[_ ]response[_ ]time$\",\n",
    "        r\"^mean[_ ]rt$\",\n",
    "        r\"^response[_ ]time$\",\n",
    "    ]\n",
    "    for pat in preferiti:\n",
    "        for i, c in enumerate(lcols):\n",
    "            if re.search(pat, c):\n",
    "                ser = pd.to_numeric(df[cols[i]], errors=\"coerce\")\n",
    "                if ser.notna().any():\n",
    "                    return float(ser.dropna().mean())\n",
    "\n",
    "    # --- 4) ultimo tentativo: prima colonna che parla di response/rt ---\n",
    "    for i, c in enumerate(lcols):\n",
    "        if any(k in c for k in [\"response\", \"resp_time\", \"resp time\", \"rt\", \"r_time\"]):\n",
    "            ser = pd.to_numeric(df[cols[i]], errors=\"coerce\")\n",
    "            if ser.notna().any():\n",
    "                return float(ser.dropna().mean())\n",
    "\n",
    "    raise ValueError(\"Colonna per Mean Response Time non trovata.\")\n",
    "\n",
    "\n",
    "rows = []\n",
    "for f in files:\n",
    "    try:\n",
    "        seed, prob = parse_seed_prob(Path(f).name)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {f}: {e}\"); continue\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "        except Exception:\n",
    "            df = pd.read_csv(f, sep=';')\n",
    "        mrt = extract_mean_rt(df)\n",
    "        rows.append((seed, round(prob, 3), mrt))\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {f}: {e}\")\n",
    "\n",
    "if not rows:\n",
    "    raise SystemExit(\"Nessun dato utile estratto dai CSV.\")\n",
    "\n",
    "data = pd.DataFrame(rows, columns=[\"seed\", \"prob\", \"mean_rt\"])\n",
    "\n",
    "# 1) Collassa repliche allo stesso p: un solo valore medio per seed,p\n",
    "agg = (data.groupby([\"seed\", \"prob\"], as_index=False)[\"mean_rt\"].mean()\n",
    "            .sort_values([\"seed\",\"prob\"]))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for seed, g in agg.groupby(\"seed\"):\n",
    "    g = g.sort_values(\"prob\")\n",
    "    x = g[\"prob\"].to_numpy()\n",
    "    y = g[\"mean_rt\"].to_numpy()\n",
    "\n",
    "    if SMOOTH and len(x) >= 2:\n",
    "        # interpola su una griglia fine per una curva unica “liscia”\n",
    "        x_grid = np.linspace(x.min(), x.max(), GRID_POINTS)\n",
    "        y_grid = np.interp(x_grid, x, y)\n",
    "        plt.plot(x_grid, y_grid, linewidth=2, label=f\"seed {seed}\")\n",
    "    else:\n",
    "        # nessun marker, solo linea unica sui p disponibili\n",
    "        plt.plot(x, y, linewidth=2, label=f\"seed {seed}\")\n",
    "\n",
    "plt.xlabel(\"Probability p\")\n",
    "plt.yscale(\"log\")   \n",
    "plt.ylabel(\"Mean Response Time\")\n",
    "plt.title(\"Mean Response Time vs p per seed\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title=\"Seeds\", ncol=2, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# (opzionale) stampa tabellina riassuntiva\n",
    "summary = (data\n",
    "           .sort_values([\"seed\",\"prob\"])\n",
    "           .pivot_table(index=\"prob\", columns=\"seed\", values=\"mean_rt\", aggfunc=\"mean\"))\n",
    "print(\"\\nTabella (Mean RT per p, colonne=seed):\")\n",
    "print(summary.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01236a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requisiti: pandas, matplotlib, numpy\n",
    "# pip install pandas matplotlib\n",
    "\n",
    "import re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------\n",
    "# Impostazioni di I/O dei CSV\n",
    "# -------------------------------\n",
    "DATA_DIR = Path(\".output_simulation\")\n",
    "files = sorted(glob.glob(str(DATA_DIR / \"*.csv\")))\n",
    "if not files:\n",
    "    raise SystemExit(f\"Nessun CSV trovato in {DATA_DIR.resolve()}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Regex per seed e probabilità p\n",
    "# -------------------------------\n",
    "seed_re = re.compile(r\"seed(\\d+)\")\n",
    "prob_re = re.compile(r\"prob([0-9\\.eE+-]+)\")\n",
    "\n",
    "def parse_seed_prob(fname: str):\n",
    "    \"\"\"Estrae (seed, prob) dal nome file, es. ...seed7...prob0.35....csv\"\"\"\n",
    "    s = seed_re.search(fname)\n",
    "    p = prob_re.search(fname)\n",
    "    if not (s and p):\n",
    "        raise ValueError(f\"Impossibile estrarre seed/prob da: {fname}\")\n",
    "    return int(s.group(1)), float(p.group(1))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Estrazione robusta delle metriche da ciascun CSV\n",
    "# ---------------------------------------------------\n",
    "def prefer_overall(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Se presente la colonna 'scope', filtra 'OVERALL' altrimenti lascia invariato.\"\"\"\n",
    "    if \"scope\" in df.columns:\n",
    "        over = df[df[\"scope\"].astype(str).str.upper() == \"OVERALL\"]\n",
    "        if not over.empty:\n",
    "            return over\n",
    "    return df\n",
    "\n",
    "def extract_metric(df: pd.DataFrame, target: str, patterns=None, keywords=None) -> float:\n",
    "    \"\"\"\n",
    "    Estrae una metrica come media numerica della/e colonna/e corrispondente/i.\n",
    "    - target: nome canonico (es. 'mean_response_time', 'throughput', 'utilization')\n",
    "    - patterns: lista di regex per nomi quasi-esatti da preferire\n",
    "    - keywords: lista di parole chiave per fallback (match contenuto nel nome colonna)\n",
    "    \"\"\"\n",
    "    df = prefer_overall(df)\n",
    "    cols  = list(df.columns)\n",
    "    lcols = [str(c).lower().strip() for c in cols]\n",
    "\n",
    "    # 1) colonna esatta\n",
    "    if target in df.columns:\n",
    "        ser = pd.to_numeric(df[target], errors=\"coerce\")\n",
    "        if ser.notna().any():\n",
    "            return float(ser.dropna().mean())\n",
    "\n",
    "    # 2) pattern preferiti\n",
    "    if patterns:\n",
    "        for pat in patterns:\n",
    "            for i, c in enumerate(lcols):\n",
    "                if re.search(pat, c):\n",
    "                    ser = pd.to_numeric(df[cols[i]], errors=\"coerce\")\n",
    "                    if ser.notna().any():\n",
    "                        return float(ser.dropna().mean())\n",
    "\n",
    "    # 3) fallback su keywords\n",
    "    if keywords:\n",
    "        for i, c in enumerate(lcols):\n",
    "            if any(k in c for k in keywords):\n",
    "                ser = pd.to_numeric(df[cols[i]], errors=\"coerce\")\n",
    "                if ser.notna().any():\n",
    "                    return float(ser.dropna().mean())\n",
    "\n",
    "    raise ValueError(f\"Colonna per '{target}' non trovata.\")\n",
    "\n",
    "# Mantengo la tua logica per il Mean RT (con preferenze di nomi più ricche)\n",
    "def extract_mean_rt(df: pd.DataFrame) -> float:\n",
    "    df = prefer_overall(df)\n",
    "    if \"mean_response_time\" in df.columns:\n",
    "        ser = pd.to_numeric(df[\"mean_response_time\"], errors=\"coerce\")\n",
    "        if ser.notna().any():\n",
    "            return float(ser.dropna().mean())\n",
    "    cols  = list(df.columns)\n",
    "    lcols = [str(c).lower().strip() for c in cols]\n",
    "    preferiti = [\n",
    "        r\"^mean[_ ]response[_ ]time$\",\n",
    "        r\"^avg[_ ]response[_ ]time$\",\n",
    "        r\"^mean[_ ]rt$\",\n",
    "        r\"^response[_ ]time$\",\n",
    "    ]\n",
    "    for pat in preferiti:\n",
    "        for i, c in enumerate(lcols):\n",
    "            if re.search(pat, c):\n",
    "                ser = pd.to_numeric(df[cols[i]], errors=\"coerce\")\n",
    "                if ser.notna().any():\n",
    "                    return float(ser.dropna().mean())\n",
    "    for i, c in enumerate(lcols):\n",
    "        if any(k in c for k in [\"response\", \"resp_time\", \"resp time\", \"rt\", \"r_time\"]):\n",
    "            ser = pd.to_numeric(df[cols[i]], errors=\"coerce\")\n",
    "            if ser.notna().any():\n",
    "                return float(ser.dropna().mean())\n",
    "    raise ValueError(\"Colonna per Mean Response Time non trovata.\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Tabella t-critici per CI 95% (n -> t_{0.975, df=n-1})\n",
    "# ---------------------------------------------------\n",
    "_TCRIT_95 = {\n",
    "    2: 12.706, 3: 4.303, 4: 3.182, 5: 2.776, 6: 2.571, 7: 2.447, 8: 2.365, 9: 2.306,\n",
    "    10: 2.262, 11: 2.228, 12: 2.201, 13: 2.179, 14: 2.160, 15: 2.145, 16: 2.131,\n",
    "    17: 2.120, 18: 2.110, 19: 2.101, 20: 2.086, 21: 2.080, 22: 2.074, 23: 2.069,\n",
    "    24: 2.064, 25: 2.060, 26: 2.056, 27: 2.052, 28: 2.048, 29: 2.045, 30: 2.042\n",
    "}\n",
    "\n",
    "def t_crit(n: int) -> float:\n",
    "    \"\"\"Ritorna t-critico a 95% per n campioni (df = n-1).\"\"\"\n",
    "    if n <= 1:\n",
    "        return float(\"inf\")\n",
    "    if n in _TCRIT_95:\n",
    "        return _TCRIT_95[n]\n",
    "    if n < 30:\n",
    "        below = max(k for k in _TCRIT_95 if k < n)\n",
    "        above = min(k for k in _TCRIT_95 if k > n)\n",
    "        w = (n - below) / (above - below)\n",
    "        return _TCRIT_95[below] * (1 - w) + _TCRIT_95[above] * w\n",
    "    return 1.96  # approssimazione normale per n grandi\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Caricamento CSV e raccolta righe (seed, p) -> metriche\n",
    "# ---------------------------------------------------\n",
    "rows = []\n",
    "for f in files:\n",
    "    try:\n",
    "        seed, prob = parse_seed_prob(Path(f).name)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip nome] {f}: {e}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "        except Exception:\n",
    "            df = pd.read_csv(f, sep=';')\n",
    "\n",
    "        # Mean RT (tua logica robusta)\n",
    "        mrt = extract_mean_rt(df)\n",
    "\n",
    "        # Throughput (preferisce 'throughput' oppure sinonimi)\n",
    "        thr = extract_metric(\n",
    "            df,\n",
    "            target=\"throughput\",\n",
    "            patterns=[r\"^throughput$\", r\"^thr$\"],\n",
    "            keywords=[\"throughput\", \"thr\", \"tp\", \"x\"]\n",
    "        )\n",
    "\n",
    "        # Utilization (preferisce 'utilization' oppure sinonimi)\n",
    "        util = extract_metric(\n",
    "            df,\n",
    "            target=\"utilization\",\n",
    "            patterns=[r\"^utilization$\", r\"^rho$\", r\"^util$\"],\n",
    "            keywords=[\"utilization\", \"util\", \"rho\", \"usage\"]\n",
    "        )\n",
    "\n",
    "        rows.append((round(prob, 3), seed, mrt, thr, util))\n",
    "    except Exception as e:\n",
    "        print(f\"[skip dati] {f}: {e}\")\n",
    "\n",
    "if not rows:\n",
    "    raise SystemExit(\"Nessun dato utile estratto dai CSV.\")\n",
    "\n",
    "data = pd.DataFrame(rows, columns=[\"prob\", \"seed\", \"mean_rt\", \"throughput\", \"utilization\"])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Funzione per sintetizzare CI 95% per una metrica\n",
    "# ---------------------------------------------------\n",
    "def make_summary(df: pd.DataFrame, metric: str) -> pd.DataFrame:\n",
    "    \"\"\"Calcola n, mean, std, sem, tcrit e halfwidth per la metrica indicata, raggruppando per p.\"\"\"\n",
    "    summary = (df\n",
    "               .groupby(\"prob\")\n",
    "               .agg(n=(metric, \"count\"),\n",
    "                    mean=(metric, \"mean\"),\n",
    "                    std=(metric, \"std\"))\n",
    "               .reset_index())\n",
    "    summary[\"sem\"] = summary[\"std\"] / np.sqrt(summary[\"n\"])\n",
    "    summary[\"tcrit\"] = summary[\"n\"].apply(t_crit)\n",
    "    summary[\"halfwidth\"] = summary[\"tcrit\"] * summary[\"sem\"]\n",
    "    summary = summary.sort_values(\"prob\")\n",
    "    return summary\n",
    "\n",
    "sum_rt   = make_summary(data, \"mean_rt\")\n",
    "sum_thr  = make_summary(data, \"throughput\")\n",
    "sum_util = make_summary(data, \"utilization\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Plot: Mean RT con CI 95%\n",
    "# ---------------------------------------------------\n",
    "plt.figure(figsize=(9,5))\n",
    "x = sum_rt[\"prob\"].to_numpy()\n",
    "m = sum_rt[\"mean\"].to_numpy()\n",
    "h = sum_rt[\"halfwidth\"].to_numpy()\n",
    "plt.plot(x, m, linewidth=2, label=\"Mean across seeds\")\n",
    "plt.fill_between(x, m - h, m + h, alpha=0.25, label=\"95% CI\")\n",
    "\n",
    "plt.xlabel(\"Probability p\")\n",
    "plt.ylabel(\"Mean Response Time\")\n",
    "plt.yscale(\"log\")   \n",
    "plt.title(\"Mean Response Time vs p con CI 95% (tra seed)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Plot: Throughput con CI 95%\n",
    "# ---------------------------------------------------\n",
    "plt.figure(figsize=(9,5))\n",
    "x = sum_thr[\"prob\"].to_numpy()\n",
    "m = sum_thr[\"mean\"].to_numpy()\n",
    "h = sum_thr[\"halfwidth\"].to_numpy()\n",
    "plt.plot(x, m, linewidth=2, label=\"Mean across seeds\")\n",
    "plt.fill_between(x, m - h, m + h, alpha=0.25, label=\"95% CI\")\n",
    "plt.xlabel(\"Probability p\")\n",
    "plt.ylabel(\"Throughput\")\n",
    "plt.title(\"Throughput vs p con CI 95% (tra seed)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Plot: Utilization con CI 95%\n",
    "# ---------------------------------------------------\n",
    "plt.figure(figsize=(9,5))\n",
    "x = sum_util[\"prob\"].to_numpy()\n",
    "m = sum_util[\"mean\"].to_numpy()\n",
    "h = sum_util[\"halfwidth\"].to_numpy()\n",
    "plt.plot(x, m, linewidth=2, label=\"Mean across seeds\")\n",
    "plt.fill_between(x, m - h, m + h, alpha=0.25, label=\"95% CI\")\n",
    "plt.xlabel(\"Probability p\")\n",
    "plt.ylabel(\"Utilization\")\n",
    "plt.title(\"Utilization vs p con CI 95% (tra seed)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Stampa tabelle riassuntive\n",
    "# ---------------------------------------------------\n",
    "pd.options.display.float_format = lambda v: f\"{v:.4f}\"\n",
    "print(\"\\nRiassunto Mean RT (p, n, mean, CI±):\")\n",
    "print(sum_rt[[\"prob\",\"n\",\"mean\",\"halfwidth\"]].to_string(index=False))\n",
    "\n",
    "print(\"\\nRiassunto Throughput (p, n, mean, CI±):\")\n",
    "print(sum_thr[[\"prob\",\"n\",\"mean\",\"halfwidth\"]].to_string(index=False))\n",
    "\n",
    "print(\"\\nRiassunto Utilization (p, n, mean, CI±):\")\n",
    "print(sum_util[[\"prob\",\"n\",\"mean\",\"halfwidth\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Response time vs tempo di servizio di B (media sui seed) ===\n",
    "# - Cerca in .output_simulation/**/ i file con pattern \"..._serviceX_...csv\"\n",
    "# - Estrae X dal nome e lo arrotonda a 2 decimali per gestire casi tipo 0.6000000000000001\n",
    "# - Legge dai CSV la riga con scope desiderato (OVERALL o NODE_B)\n",
    "# - Aggrega i mean_response_time sui seed e plottizza la media per ogni X\n",
    "# - Salva anche un CSV con i risultati aggregati\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Parametri utente ---------------------------------------------------------\n",
    "root_dir = \".output_simulation\"     # cartella radice da cui cercare i CSV\n",
    "scope = \"NODE_B\"                   # \"OVERALL\" per sistema intero, \"NODE_B\" per il solo B\n",
    "metric = \"utilization\"       # metrica da aggregare (qui: tempo di risposta medio)\n",
    "service_min, service_max, step = 0.40, 0.80, 0.05   # range dei tempi di servizio da considerare\n",
    "\n",
    "# --- Utility: estrai valore \"serviceX\" dal nome file --------------------------\n",
    "service_re = re.compile(r\"service([0-9]+(?:\\.[0-9]+)?)\")\n",
    "\n",
    "def extract_service_value(path: str):\n",
    "    \"\"\"\n",
    "    Estrae il valore X da un nome che contiene 'serviceX'.\n",
    "    Ritorna float oppure None se non trovato o invalido.\n",
    "    \"\"\"\n",
    "    m = service_re.search(os.path.basename(path))\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# --- Scansione file -----------------------------------------------------------\n",
    "all_csv = glob.glob(os.path.join(root_dir, \"**\", \"*.csv\"), recursive=True)\n",
    "# Teniamo solo file che contengono 'service' nel nome (evita per_job_times, ecc.)\n",
    "candidate_csv = [p for p in all_csv if \"service\" in os.path.basename(p)]\n",
    "\n",
    "# --- Aggregazione per tempo di servizio --------------------------------------\n",
    "agg = defaultdict(list)  # service_time_rounded -> lista di metriche (una per seed/file)\n",
    "kept_files = 0\n",
    "\n",
    "for path in candidate_csv:\n",
    "    s_val = extract_service_value(path)\n",
    "    if s_val is None:\n",
    "        continue\n",
    "    # filtro per range richiesto\n",
    "    if not (service_min - 1e-9 <= s_val <= service_max + 1e-9):\n",
    "        continue\n",
    "\n",
    "    # arrotondo a due decimali per stabilizzare valori tipo 0.6000000000000001\n",
    "    s_key = round(s_val, 2)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        # cerco la riga con lo scope desiderato\n",
    "        row = df.loc[df[\"scope\"] == scope]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        value = float(row.iloc[0][metric])\n",
    "        if math.isnan(value):\n",
    "            continue\n",
    "        agg[s_key].append(value)\n",
    "        kept_files += 1\n",
    "    except Exception as e:\n",
    "        # se un file è malformato, lo saltiamo in silenzio\n",
    "        pass\n",
    "\n",
    "# --- Prepara dati ordinati e calcola medie -----------------------------------\n",
    "xs, means, counts = [], [], []\n",
    "for s in np.arange(service_min, service_max + 1e-9, step):\n",
    "    s = round(float(s), 2)\n",
    "    vals = agg.get(s, [])\n",
    "    if vals:\n",
    "        xs.append(s)\n",
    "        means.append(statistics.fmean(vals))\n",
    "        counts.append(len(vals))\n",
    "    else:\n",
    "        # se mancano file per un certo service time, lo lasciamo fuori dalla curva\n",
    "        # (in alternativa si potrebbe mettere NaN per mantenere la griglia completa)\n",
    "        continue\n",
    "\n",
    "# --- Report rapido sui conteggi trovati --------------------------------------\n",
    "summary = pd.DataFrame({\"service_time\": xs, \"mean_\"+metric: means, \"n_files\": counts})\n",
    "\n",
    "print(f\"File considerati: {kept_files}\")\n",
    "display(summary)\n",
    "\n",
    "# --- Plot ---------------------------------------------------------------------\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(xs, means, marker=\"o\")  # linea unica: media sui seed per ciascun tempo di servizio\n",
    "plt.xlabel(\"Tempo di servizio B\")\n",
    "plt.ylabel(f\"{metric.replace('_', ' ').title()} ({scope})\")\n",
    "plt.title(f\"Andamento {metric.replace('_', ' ')} vs tempo di servizio di B ({scope})\")\n",
    "\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "# Soglia di saturazione\n",
    "plt.axhline(1.0, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "\n",
    "# xticks a passo 0.05\n",
    "xticks = np.round(np.arange(service_min, service_max + 1e-9, step), 2)\n",
    "plt.xticks(xticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Response time vs tempo di servizio di B (media sui seed) ===\n",
    "# - Cerca in .output_simulation/**/ i file con pattern \"..._serviceX_...csv\"\n",
    "# - Estrae X dal nome e lo arrotonda a 2 decimali per gestire casi tipo 0.6000000000000001\n",
    "# - Legge dai CSV la riga con scope desiderato (OVERALL o NODE_B)\n",
    "# - Aggrega i mean_response_time sui seed e plottizza la media per ogni X\n",
    "# - Salva anche un CSV con i risultati aggregati\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Parametri utente ---------------------------------------------------------\n",
    "root_dir = \".output_simulation\"     # cartella radice da cui cercare i CSV\n",
    "scope = \"NODE_B\"                   # \"OVERALL\" per sistema intero, \"NODE_B\" per il solo B\n",
    "metric = \"throughput\"       # metrica da aggregare (qui: tempo di risposta medio)\n",
    "service_min, service_max, step = 0.40, 0.80, 0.05   # range dei tempi di servizio da considerare\n",
    "\n",
    "# --- Utility: estrai valore \"serviceX\" dal nome file --------------------------\n",
    "service_re = re.compile(r\"service([0-9]+(?:\\.[0-9]+)?)\")\n",
    "\n",
    "def extract_service_value(path: str):\n",
    "    \"\"\"\n",
    "    Estrae il valore X da un nome che contiene 'serviceX'.\n",
    "    Ritorna float oppure None se non trovato o invalido.\n",
    "    \"\"\"\n",
    "    m = service_re.search(os.path.basename(path))\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# --- Scansione file -----------------------------------------------------------\n",
    "all_csv = glob.glob(os.path.join(root_dir, \"**\", \"*.csv\"), recursive=True)\n",
    "# Teniamo solo file che contengono 'service' nel nome (evita per_job_times, ecc.)\n",
    "candidate_csv = [p for p in all_csv if \"service\" in os.path.basename(p)]\n",
    "\n",
    "# --- Aggregazione per tempo di servizio --------------------------------------\n",
    "agg = defaultdict(list)  # service_time_rounded -> lista di metriche (una per seed/file)\n",
    "kept_files = 0\n",
    "\n",
    "for path in candidate_csv:\n",
    "    s_val = extract_service_value(path)\n",
    "    if s_val is None:\n",
    "        continue\n",
    "    # filtro per range richiesto\n",
    "    if not (service_min - 1e-9 <= s_val <= service_max + 1e-9):\n",
    "        continue\n",
    "\n",
    "    # arrotondo a due decimali per stabilizzare valori tipo 0.6000000000000001\n",
    "    s_key = round(s_val, 2)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        # cerco la riga con lo scope desiderato\n",
    "        row = df.loc[df[\"scope\"] == scope]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        value = float(row.iloc[0][metric])\n",
    "        if math.isnan(value):\n",
    "            continue\n",
    "        agg[s_key].append(value)\n",
    "        kept_files += 1\n",
    "    except Exception as e:\n",
    "        # se un file è malformato, lo saltiamo in silenzio\n",
    "        pass\n",
    "\n",
    "# --- Prepara dati ordinati e calcola medie -----------------------------------\n",
    "xs, means, counts = [], [], []\n",
    "for s in np.arange(service_min, service_max + 1e-9, step):\n",
    "    s = round(float(s), 2)\n",
    "    vals = agg.get(s, [])\n",
    "    if vals:\n",
    "        xs.append(s)\n",
    "        means.append(statistics.fmean(vals))\n",
    "        counts.append(len(vals))\n",
    "    else:\n",
    "        # se mancano file per un certo service time, lo lasciamo fuori dalla curva\n",
    "        # (in alternativa si potrebbe mettere NaN per mantenere la griglia completa)\n",
    "        continue\n",
    "\n",
    "# --- Report rapido sui conteggi trovati --------------------------------------\n",
    "summary = pd.DataFrame({\"service_time\": xs, \"mean_\"+metric: means, \"n_files\": counts})\n",
    "\n",
    "print(f\"File considerati: {kept_files}\")\n",
    "display(summary)\n",
    "# Soglia di saturazione\n",
    "\n",
    "# --- Plot ---------------------------------------------------------------------\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(xs, means, marker=\"o\")  # linea unica: media sui seed per ciascun tempo di servizio\n",
    "plt.xlabel(\"Tempo di servizio B\")\n",
    "plt.ylabel(f\"{metric.replace('_', ' ').title()} ({scope})\")\n",
    "plt.title(f\"Andamento {metric.replace('_', ' ')} vs tempo di servizio di B ({scope})\")\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# xticks a passo 0.05\n",
    "xticks = np.round(np.arange(service_min, service_max + 1e-9, step), 2)\n",
    "plt.xticks(xticks)\n",
    "# Soglia di saturazione\n",
    "plt.axhline(1.4, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78955a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Utilization di B vs Lambda (IC 95%) ===================\n",
    "# - Scansiona .output_simulation/** per CSV che nel nome contengono \"service\"\n",
    "# - Per ogni file:\n",
    "#     * Estrae il tempo di servizio (serviceX) dal nome file\n",
    "#     * Legge TUTTE le righe con scope == \"NODE_B\"\n",
    "#     * Per ciascuna riga, prende arrival_rate (λ) e utilization\n",
    "# - Aggrega per (service_B, λ) su tutti i seed/files\n",
    "# - Calcola media e IC 95% e produce il grafico (una linea per ogni service_B)\n",
    "# - Salva anche una tabella aggregata\n",
    "\n",
    "import os, re, glob, math, statistics\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------- Parametri ----------------------------------------\n",
    "root_dir = \".output_simulation\"     # cartella radice\n",
    "scope = \"NODE_B\"                    # lavoriamo sul nodo B\n",
    "service_min, service_max, step = 0.40, 0.80, 0.05   # service time B da plottare\n",
    "lambda_step_for_ticks = 0.05        # passo dei tick su asse X\n",
    "title = \"Confidence interval for B average utilization\"\n",
    "y_label = \"Avg utilization in B\"\n",
    "x_label = \"Lambda\"\n",
    "\n",
    "# --------------------- Utility: parsing e statistica -------------------------\n",
    "_service_re = re.compile(r\"service([0-9]+(?:\\.[0-9]+)?)\")\n",
    "\n",
    "def extract_service_value(path: str):\n",
    "    \"\"\"Estrae il valore float X dal nome file se contiene 'serviceX', altrimenti None.\"\"\"\n",
    "    m = _service_re.search(os.path.basename(path))\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def t_critical_95(n: int) -> float:\n",
    "    \"\"\"Fattore t per IC 95% con n osservazioni (df=n-1). Tabella per df<=30, altrimenti 1.96.\"\"\"\n",
    "    df = n - 1\n",
    "    table = {\n",
    "        1:12.706, 2:4.303, 3:3.182, 4:2.776, 5:2.571, 6:2.447, 7:2.365, 8:2.306,\n",
    "        9:2.262, 10:2.228, 11:2.201, 12:2.179, 13:2.160, 14:2.145, 15:2.131,\n",
    "        16:2.120, 17:2.110, 18:2.101, 19:2.093, 20:2.086, 21:2.080, 22:2.074,\n",
    "        23:2.069, 24:2.064, 25:2.060, 26:2.056, 27:2.052, 28:2.048, 29:2.045,\n",
    "        30:2.042\n",
    "    }\n",
    "    if df <= 0:\n",
    "        return float(\"nan\")\n",
    "    return table.get(df, 1.96)\n",
    "\n",
    "# ---------------------- Raccolta dati da tutti i CSV -------------------------\n",
    "# data[service_B][lambda] -> lista di utilizations (uno per seed/file)\n",
    "data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "all_csv = glob.glob(os.path.join(root_dir, \"**\", \"*.csv\"), recursive=True)\n",
    "# Filtra file pertinenti; escludi eventuali CSV aggregati/di output per evitare ricicli\n",
    "candidate_csv = [\n",
    "    p for p in all_csv\n",
    "    if \"service\" in os.path.basename(p)\n",
    "    and not os.path.basename(p).startswith((\"per_job_times\", \"analytic_sweep\", \"ci_utilization_B_vs_lambda\"))\n",
    "]\n",
    "\n",
    "files_read = 0\n",
    "rows_used = 0\n",
    "\n",
    "for path in candidate_csv:\n",
    "    s_val = extract_service_value(path)\n",
    "    if s_val is None:\n",
    "        continue\n",
    "    # filtra per intervallo richiesto e stabilizza il key\n",
    "    if not (service_min - 1e-9 <= s_val <= service_max + 1e-9):\n",
    "        continue\n",
    "    s_key = round(s_val, 2)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        sub = df.loc[df[\"scope\"] == scope, [\"arrival_rate\", \"utilization\"]]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        for _, r in sub.iterrows():\n",
    "            lam = float(r[\"arrival_rate\"])\n",
    "            util = float(r[\"utilization\"])\n",
    "            if math.isnan(lam) or math.isnan(util):\n",
    "                continue\n",
    "            lam_key = round(lam, 2)   # stabilizza λ per il raggruppamento\n",
    "            data[s_key][lam_key].append(util)\n",
    "            rows_used += 1\n",
    "        files_read += 1\n",
    "    except Exception:\n",
    "        # file malformato: salta\n",
    "        pass\n",
    "\n",
    "if files_read == 0 or rows_used == 0:\n",
    "    raise RuntimeError(\"Nessun dato utile trovato. Controlla i percorsi/nomi dei file in .output_simulation.\")\n",
    "\n",
    "# ---------------------- Aggregazione (media + IC 95%) ------------------------\n",
    "records = []\n",
    "for s_key, lam_map in data.items():\n",
    "    for lam_key, vals in lam_map.items():\n",
    "        if not vals:\n",
    "            continue\n",
    "        n = len(vals)\n",
    "        mean = statistics.fmean(vals)\n",
    "        if n >= 2:\n",
    "            s = statistics.stdev(vals)\n",
    "            ci = t_critical_95(n) * (s / math.sqrt(n))\n",
    "        else:\n",
    "            ci = float(\"nan\")\n",
    "        records.append({\n",
    "            \"service_B\": s_key,\n",
    "            \"lambda\": lam_key,\n",
    "            \"mean_utilization\": mean,\n",
    "            \"ci95\": ci,\n",
    "            \"n\": n\n",
    "        })\n",
    "\n",
    "agg_df = pd.DataFrame.from_records(records)\n",
    "if agg_df.empty:\n",
    "    raise RuntimeError(\"Aggregazione vuota: verifica che i CSV contengano scope=NODE_B.\")\n",
    "\n",
    "# Salva tabella aggregata (ordinata)\n",
    "agg_df = agg_df.sort_values([\"service_B\", \"lambda\"])\n",
    "\n",
    "# ----------------------------- Grafico ---------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Soglia di saturazione\n",
    "plt.axhline(1.0, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "\n",
    "# Una linea per ogni tempo di servizio\n",
    "for s_key in sorted(agg_df[\"service_B\"].unique()):\n",
    "    sub = agg_df[agg_df[\"service_B\"] == s_key].sort_values(\"lambda\")\n",
    "    x = sub[\"lambda\"].to_list()\n",
    "    y = sub[\"mean_utilization\"].to_list()\n",
    "    yerr = sub[\"ci95\"].to_list()\n",
    "    plt.errorbar(x, y, yerr=yerr, marker=\"o\", capsize=3, label=f\"simulation: avg service for B = {s_key}\")\n",
    "\n",
    "plt.title(title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Tick dell’asse X allineati ai tuoi λ (0.50 → 1.45 con passo 0.05)\n",
    "lam_min = min(agg_df[\"lambda\"].min(), 0.50)\n",
    "lam_max = max(agg_df[\"lambda\"].max(), 1.45)\n",
    "xticks = np.round(np.arange(round(lam_min, 2), round(lam_max + 1e-9, 2) + 0.001, lambda_step_for_ticks), 2)\n",
    "plt.xticks(xticks)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =================== Utilization di B vs Lambda (IC 95%) ===================\n",
    "# - Scansiona .output_simulation/** per CSV che nel nome contengono \"service\"\n",
    "# - Per ogni file:\n",
    "#     * Estrae il tempo di servizio (serviceX) dal nome file\n",
    "#     * Legge TUTTE le righe con scope == \"NODE_B\"\n",
    "#     * Per ciascuna riga, prende arrival_rate (λ) e utilization\n",
    "# - Aggrega per (service_B, λ) su tutti i seed/files\n",
    "# - Calcola media e IC 95% e produce il grafico (una linea per ogni service_B)\n",
    "# - Salva anche una tabella aggregata\n",
    "\n",
    "import os, re, glob, math, statistics\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------- Parametri ----------------------------------------\n",
    "root_dir = \".output_simulation\"     # cartella radice\n",
    "scope = \"NODE_B\"                    # lavoriamo sul nodo B\n",
    "service_min, service_max, step = 0.40, 0.80, 0.05   # service time B da plottare\n",
    "lambda_step_for_ticks = 0.05        # passo dei tick su asse X\n",
    "title = \"Confidence interval for B average throughput\"\n",
    "y_label = \"Avg throughput in B\"\n",
    "x_label = \"Lambda\"\n",
    "\n",
    "# --------------------- Utility: parsing e statistica -------------------------\n",
    "_service_re = re.compile(r\"service([0-9]+(?:\\.[0-9]+)?)\")\n",
    "\n",
    "def extract_service_value(path: str):\n",
    "    \"\"\"Estrae il valore float X dal nome file se contiene 'serviceX', altrimenti None.\"\"\"\n",
    "    m = _service_re.search(os.path.basename(path))\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def t_critical_95(n: int) -> float:\n",
    "    \"\"\"Fattore t per IC 95% con n osservazioni (df=n-1). Tabella per df<=30, altrimenti 1.96.\"\"\"\n",
    "    df = n - 1\n",
    "    table = {\n",
    "        1:12.706, 2:4.303, 3:3.182, 4:2.776, 5:2.571, 6:2.447, 7:2.365, 8:2.306,\n",
    "        9:2.262, 10:2.228, 11:2.201, 12:2.179, 13:2.160, 14:2.145, 15:2.131,\n",
    "        16:2.120, 17:2.110, 18:2.101, 19:2.093, 20:2.086, 21:2.080, 22:2.074,\n",
    "        23:2.069, 24:2.064, 25:2.060, 26:2.056, 27:2.052, 28:2.048, 29:2.045,\n",
    "        30:2.042\n",
    "    }\n",
    "    if df <= 0:\n",
    "        return float(\"nan\")\n",
    "    return table.get(df, 1.96)\n",
    "\n",
    "# ---------------------- Raccolta dati da tutti i CSV -------------------------\n",
    "# data[service_B][lambda] -> lista di utilizations (uno per seed/file)\n",
    "data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "all_csv = glob.glob(os.path.join(root_dir, \"**\", \"*.csv\"), recursive=True)\n",
    "# Filtra file pertinenti; escludi eventuali CSV aggregati/di output per evitare ricicli\n",
    "candidate_csv = [\n",
    "    p for p in all_csv\n",
    "    if \"service\" in os.path.basename(p)\n",
    "    and not os.path.basename(p).startswith((\"per_job_times\", \"analytic_sweep\", \"ci_utilization_B_vs_lambda\"))\n",
    "]\n",
    "\n",
    "files_read = 0\n",
    "rows_used = 0\n",
    "\n",
    "for path in candidate_csv:\n",
    "    s_val = extract_service_value(path)\n",
    "    if s_val is None:\n",
    "        continue\n",
    "    # filtra per intervallo richiesto e stabilizza il key\n",
    "    if not (service_min - 1e-9 <= s_val <= service_max + 1e-9):\n",
    "        continue\n",
    "    s_key = round(s_val, 2)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        sub = df.loc[df[\"scope\"] == scope, [\"arrival_rate\", \"throughput\"]]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        for _, r in sub.iterrows():\n",
    "            lam = float(r[\"arrival_rate\"])\n",
    "            util = float(r[\"throughput\"])\n",
    "            if math.isnan(lam) or math.isnan(util):\n",
    "                continue\n",
    "            lam_key = round(lam, 2)   # stabilizza λ per il raggruppamento\n",
    "            data[s_key][lam_key].append(util)\n",
    "            rows_used += 1\n",
    "        files_read += 1\n",
    "    except Exception:\n",
    "        # file malformato: salta\n",
    "        pass\n",
    "\n",
    "if files_read == 0 or rows_used == 0:\n",
    "    raise RuntimeError(\"Nessun dato utile trovato. Controlla i percorsi/nomi dei file in .output_simulation.\")\n",
    "\n",
    "# ---------------------- Aggregazione (media + IC 95%) ------------------------\n",
    "records = []\n",
    "for s_key, lam_map in data.items():\n",
    "    for lam_key, vals in lam_map.items():\n",
    "        if not vals:\n",
    "            continue\n",
    "        n = len(vals)\n",
    "        mean = statistics.fmean(vals)\n",
    "        if n >= 2:\n",
    "            s = statistics.stdev(vals)\n",
    "            ci = t_critical_95(n) * (s / math.sqrt(n))\n",
    "        else:\n",
    "            ci = float(\"nan\")\n",
    "        records.append({\n",
    "            \"service_B\": s_key,\n",
    "            \"lambda\": lam_key,\n",
    "            \"mean_throughput\": mean,\n",
    "            \"ci95\": ci,\n",
    "            \"n\": n\n",
    "        })\n",
    "\n",
    "agg_df = pd.DataFrame.from_records(records)\n",
    "if agg_df.empty:\n",
    "    raise RuntimeError(\"Aggregazione vuota: verifica che i CSV contengano scope=NODE_B.\")\n",
    "\n",
    "# Salva tabella aggregata (ordinata)\n",
    "agg_df = agg_df.sort_values([\"service_B\", \"lambda\"])\n",
    "\n",
    "# ----------------------------- Grafico ---------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Soglia di saturazione\n",
    "plt.axhline(1.4, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "\n",
    "# Una linea per ogni tempo di servizio\n",
    "for s_key in sorted(agg_df[\"service_B\"].unique()):\n",
    "    sub = agg_df[agg_df[\"service_B\"] == s_key].sort_values(\"lambda\")\n",
    "    x = sub[\"lambda\"].to_list()\n",
    "    y = sub[\"mean_throughput\"].to_list()\n",
    "    yerr = sub[\"ci95\"].to_list()\n",
    "    plt.errorbar(x, y, yerr=yerr, marker=\"o\", capsize=3, label=f\"simulation: avg service for B = {s_key}\")\n",
    "\n",
    "plt.title(title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Tick dell’asse X allineati ai tuoi λ (0.50 → 1.45 con passo 0.05)\n",
    "lam_min = min(agg_df[\"lambda\"].min(), 0.50)\n",
    "lam_max = max(agg_df[\"lambda\"].max(), 1.4)\n",
    "xticks = np.round(np.arange(round(lam_min, 2), round(lam_max + 1e-9, 2) + 0.001, lambda_step_for_ticks), 2)\n",
    "plt.xticks(xticks)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4450c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
